{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv666HsTi/0n4EzJzWUWlC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsangrebecca/BloomTech/blob/main/Sprint9/S9M1_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWr1mgF7904t"
      },
      "outputs": [],
      "source": [
        "\"\"\"Part 2:\n",
        "The exercise of writing these functions in Part 2 is helpful practice in learning how to geenrate random values.\n",
        "The data structure of having tuples inside of a list is one that we'll see multiple times throughout Unit 3\n",
        "so it's helpful to get familiar with it and to also be able to simulate our own versions of lists of tuples with fake data in them.\"\"\"\n",
        "# to follow pep 8 guidelines, we need to include doc strings '''xxx'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# df = pd.DataFrame({'a': [1,2,3], 'b': [4,5,6]})\n",
        "\n",
        "# print(df.head())\n",
        "\n",
        "adj = ['badass', 'delirious', 'mindnumbing', 'nuclear']\n",
        "nou = ['butt', 'bread', 'sloth', 'fart', 'face']\n",
        "\n",
        "def random_phrase():\n",
        "    \"\"\"Randomly select an adjective from a list of adjectives, a noun from a list of nouns,\n",
        "    then concatenate them returning them as a single string\"\"\"\n",
        "    # random.choice returns 1 elements, random.sample can return more than 1!\n",
        "    random_adjective = random.choice(adj)\n",
        "\n",
        "    # random_noun = np.random.choice(nouns) # if we don't import random\n",
        "    # OR\n",
        "    # random_index = random.randint(0, len(nouns)-1)\n",
        "    # random_noun = nouns[random_index]\n",
        "    # OR\n",
        "    # random_noun = random.sample(nouns, 1)[0] # return a list so we need to index[0] to choose the string\n",
        "    random_noun = random.choice(nou)\n",
        "\n",
        "    # return f\"{random_adjective} {random_noun}\"\n",
        "    # OR\n",
        "    return random_adjective + ' ' + random_noun\n",
        "\n",
        "def random_float(min_val, max_val):\n",
        "    \"\"\"Returns a random float uniformly distributed between some min and max values.\"\"\"\n",
        "    return random.uniform(min_val, max_val)\n",
        "\n",
        "def random_bowling_score():\n",
        "    return random.randint(0, 300)\n",
        "\n",
        "def random_rating_1dec(min_val, max_val):\n",
        "    return round(random.uniform(min_val, max_val), 1)\n",
        "\n",
        "def silly_tuple():  # that contains all 3 smaller functions\n",
        "    # random_string = random_phrase(adj, nou)\n",
        "    # rating = random_rating_1dec(1, 5)\n",
        "    # bowling_score = random_bowling_score(0,300)\n",
        "    return (random_phrase(), random_rating_1dec(1,5), random_bowling_score())\n",
        "\n",
        "# list filled with silly tuples of a certain number\n",
        "def silly_tuple_list(num_tuples):\n",
        "\n",
        "    result = []\n",
        "    for _ in range(num_tuples):\n",
        "        result.append(silly_tuple())\n",
        "    return result\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(random_phrase())\n",
        "    print(random_float(1, 100))\n",
        "    print(random_bowling_score())\n",
        "    print(random_rating_1dec(1,5))\n",
        "    print(silly_tuple())\n",
        "    print(silly_tuple_list(3))\n",
        "\n",
        "\"\"\"Part 3:\n",
        "Part 3 is a practice in writing functions that might truly be useful within a published Python package. We're writing functions that\n",
        "we could theoretically import into other projects to help us do our work.\n",
        "\n",
        "Remeber that it's only required that you implement 1 of the functions from part 3.\"\"\"\n",
        "\n",
        "# PART 3 FUNCTIONS ===========================================================================================================\n",
        "\n",
        "# create a random dataframe\n",
        "test_df = pd.DataFrame(np.array([[1,2,3], [4,5,6], [7,8,9]])) # these are the rows\n",
        "null_df = pd.DataFrame(np.array([[1,2,np.nan], [4,5,np.nan], [7,8,9]]))\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------\n",
        "# check a dataframe for nulls and return the number of missing values\n",
        "def null_count(df):\n",
        "    '''Check a dataframe for nulls and return the number of missing values.'''\n",
        "    return df.isnull().sum().sum()  # 1st .sum() is to sum up by the column, 2nd sum is sum up the columns\n",
        "null_count(test_df)\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------------------\n",
        "# train test split\n",
        "# Frac is the percent of data to set aside for training.\n",
        "def train_test_split(df, frac=0.8):\n",
        "    '''Create a train/test split function for a dataframe and returns both the training and testing sets\n",
        "    '''\n",
        "    # if the train test data split is not time-sensitive, we should shuffle them, otherwise, turn the shuffle off\n",
        "    shuffled_df = df.sample(frac=1, random_state=42)\n",
        "\n",
        "    # index to split the df\n",
        "    split_index = int(frac * len(df))\n",
        "\n",
        "    train_set = shuffled_df.iloc[:split_index] # everything up till the index. If time-sensitive, use df not shuffled_df\n",
        "    test_set = shuffled_df.iloc[split_index:] # everything after the index\n",
        "    return train_set, test_set\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------\n",
        "# mix everything up in a dataframe with a random seed for reproducible randomization\n",
        "def randomize(df, seed):\n",
        "    \"\"\"Develop a randomization function that randomizes all of a dataframes cells then returns that randomized dataframe\n",
        "    \"\"\"\n",
        "    return df.sample(frac=1.0, random_state=seed)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------\n",
        "# split addresses into cities, states and zip codes\n",
        "address_df = pd.DataFrame({'address':['890 Jennifer Brooks\\nNorth Janet, WY 23785',\n",
        "                                      '8394 Kim Meadow\\nDarrenville, AK 27389',\n",
        "                                      '379 Cain Plaza\\nJosephburgh, WY 06332',\n",
        "                                      '5303 Tina Hill\\nAudreychester, VA 97036']}) # a single column dataframe\n",
        "\n",
        "def addy_split(addy_series):\n",
        "    \"\"\"\n",
        "    Split addresses into 3 columns (df['city], df['state'], and df['zip']).\n",
        "    You can use regexes to detect the format and pull out important pieces.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    city_list = []\n",
        "    state_list = []\n",
        "    zip_list = []\n",
        "\n",
        "    for addy in addy_series:\n",
        "        # break up the address into strings\n",
        "        second_half = addy.split('\\n')[1] # grab the 2nd item after the split which contains the city, state and zip code\n",
        "        city = second_half.split(',')[0]\n",
        "        state = second_half.split(' ')[-2]\n",
        "        zip = second_half.split(' ')[-1]\n",
        "\n",
        "        # add the strings to the lists\n",
        "        city_list.append(city)\n",
        "        state_list.append(state)\n",
        "        zip_list.append(zip)\n",
        "\n",
        "    # add the lists as new columns on the df\n",
        "    df['city'] = city_list\n",
        "    df['state'] = state_list\n",
        "    df['zip'] = zip_list\n",
        "\n",
        "    return df\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------------------------\n",
        "# Turn abbreviations to state names spelled out\n",
        "state_dict = {\n",
        "        'AK': 'Alaska',\n",
        "        'AL': 'Alabama',\n",
        "        'AR': 'Arkansas',\n",
        "        'AS': 'American Samoa',\n",
        "        'AZ': 'Arizona',\n",
        "        'CA': 'California',\n",
        "        'CO': 'Colorado',\n",
        "        'CT': 'Connecticut',\n",
        "        'DC': 'District of Columbia',\n",
        "        'DE': 'Delaware',\n",
        "        'FL': 'Florida',\n",
        "        'GA': 'Georgia',\n",
        "        'GU': 'Guam',\n",
        "        'HI': 'Hawaii',\n",
        "        'IA': 'Iowa',\n",
        "        'ID': 'Idaho',\n",
        "        'IL': 'Illinois',\n",
        "        'IN': 'Indiana',\n",
        "        'KS': 'Kansas',\n",
        "        'KY': 'Kentucky',\n",
        "        'LA': 'Louisiana',\n",
        "        'MA': 'Massachusetts',\n",
        "        'MD': 'Maryland',\n",
        "        'ME': 'Maine',\n",
        "        'MI': 'Michigan',\n",
        "        'MN': 'Minnesota',\n",
        "        'MO': 'Missouri',\n",
        "        'MP': 'Northern Mariana Islands',\n",
        "        'MS': 'Mississippi',\n",
        "        'MT': 'Montana',\n",
        "        'NA': 'National',\n",
        "        'NC': 'North Carolina',\n",
        "        'ND': 'North Dakota',\n",
        "        'NE': 'Nebraska',\n",
        "        'NH': 'New Hampshire',\n",
        "        'NJ': 'New Jersey',\n",
        "        'NM': 'New Mexico',\n",
        "        'NV': 'Nevada',\n",
        "        'NY': 'New York',\n",
        "        'OH': 'Ohio',\n",
        "        'OK': 'Oklahoma',\n",
        "        'OR': 'Oregon',\n",
        "        'PA': 'Pennsylvania',\n",
        "        'PR': 'Puerto Rico',\n",
        "        'RI': 'Rhode Island',\n",
        "        'SC': 'South Carolina',\n",
        "        'SD': 'South Dakota',\n",
        "        'TN': 'Tennessee',\n",
        "        'TX': 'Texas',\n",
        "        'UT': 'Utah',\n",
        "        'VA': 'Virginia',\n",
        "        'VI': 'Virgin Islands',\n",
        "        'VT': 'Vermont',\n",
        "        'WA': 'Washington',\n",
        "        'WI': 'Wisconsin',\n",
        "        'WV': 'West Virginia',\n",
        "        'WY': 'Wyoming'\n",
        "}\n",
        "\n",
        "# extract the state column in the addy dataframe\n",
        "addy_states = addy_split(address_df['address'])['state'] # 1st part is the new df we created with 3 columns of city, state and zip, and we're calling the state column\n",
        "\n",
        "def abbr_2_st(state_series, abbr_2_st=True): # toggle between name to abbrev and abbrev to name based on Boolean\n",
        "    \"\"\"\n",
        "    Return a new column with the full name from a state abbreviation column eg input of FL will return Florida\n",
        "    \"\"\"\n",
        "    # functions within a function\n",
        "    def abbrev_replace(abbrev):\n",
        "        return state_dict[abbrev]  # go to dictionary to get the state name\n",
        "    def state_replace(state_name): # do the opposite\n",
        "        reverse_state_dict = dict((v, k) for k, v in state_dict.items()) # swapping key values pairs in dict\n",
        "        return reverse_state_dict[state_name]\n",
        "\n",
        "    if abbr_2_st:\n",
        "        return state_series.apply(abbrev_replace) # go to the column and apply that function row by row\n",
        "    else:\n",
        "        return state_series.apply(state_replace)\n",
        "\n",
        "# to test the reverse we need a column of state names\n",
        "full_state_names_column = abbr_2_st(addy_states)\n",
        "#---------------------------------------------------------------------------------------------------------------------------------\n",
        "# take a list and df and turn list into a series as a new column in the df\n",
        "def list_2_series(list_2_series, df):\n",
        "    \"\"\"\n",
        "    Single function to take a list and dataframe, turn it into a series and add it to a dataframe as a new column.\n",
        "    \"\"\"\n",
        "    new_column = pd.Series(list_2_series)\n",
        "    return pd.concat([df, new_column], axis=1) # specify axis to make sure it's column not row\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------------------------\n",
        "outlier_df = pd.DataFrame(\n",
        "    {'a': [1,2,3,4,5,6],\n",
        "     'b': [4,5,6,7,8,9],\n",
        "     'c': [7,1000,9,10,11,12]})\n",
        "\n",
        "def rm_outliers(df): # according to 1.5 interquartile rule\n",
        "    \"\"\"\n",
        "    A 1.5*interquartile range outlier detection/removal function that gets rid of outlying rows\n",
        "    and returns the outlier-cleaned dataframe.\n",
        "    \"\"\"\n",
        "    cleaned_df = pd.DataFrame()\n",
        "    for (columnName, columnData) in df.iteritems():\n",
        "        Q1 = columnData.quantile(0.25)\n",
        "        Q3 = columnData.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5*IQR\n",
        "        upper_bound = Q3 + 1.5*IQR\n",
        "        # print(lower_bound, upper_bound)\n",
        "\n",
        "        mask = columnData.between(lower_bound, upper_bound, inclusive='both')\n",
        "        cleaned = columnData.loc[mask]\n",
        "        # print(columnName, cleaned)\n",
        "        cleaned_df[columnName] = cleaned\n",
        "    return cleaned_df\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "dates_column = pd.Series(['01/13/2016', '02/14/2017', '03/15/2018', '04/16/2019'])\n",
        "def split_dates(date_series):\n",
        "    \"\"\"\n",
        "    Function to split dates of forma 'MM/DD/YYYY' into multiple columns\n",
        "    (df['month'], df['day'], df['year']) then return the same dataframe with those additional columns\"\"\"\n",
        "    # assume it's MM/DD/YYYY\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    month_list = []\n",
        "    day_list = []\n",
        "    year_list = []\n",
        "\n",
        "    for date in date_series:\n",
        "        month_list.append(date.split('/')[0])\n",
        "        day_list.append(date.split('/')[1])\n",
        "        year_list.append(date.split('/')[2])\n",
        "\n",
        "    df['month'] = month_list\n",
        "    df['day'] = day_list\n",
        "    df['year'] = year_list\n",
        "\n",
        "    return df\n",
        "\n",
        "#=============================================================================================================================\n",
        "# section below only for printing outcomes when run as scripts but not run as modules\n",
        "if __name__ == '__main__':\n",
        "    print(null_count(null_df))\n",
        "    print(train_test_split(test_df))\n",
        "    print(randomize(test_df, 10))\n",
        "    print(addy_split(address_df['address']))\n",
        "    print(abbr_2_st(addy_states))\n",
        "    print(abbr_2_st(full_state_names_column, abbr_2_st=False))\n",
        "    print(list_2_series([10,11,12], test_df))\n",
        "    print(rm_outliers(outlier_df))\n",
        "    print(split_dates(dates_column))"
      ]
    }
  ]
}