{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsangrebecca/BloomTech/blob/main/Sprint7/Module3/DS_233_guided_project_BaggingVsBoosting_GB_XGBModel_FeatureImportanceWithDifferentTechniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ha9OWxf0jw"
      },
      "source": [
        "## BloomTech Data Science\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Permutation & Boosting\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUmaaCmCprYw"
      },
      "source": [
        "# Downloading the Tanzania Waterpump Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkdEatMkUKa1"
      },
      "source": [
        "Make sure  you only use the dataset that is available through the **DS** **Kaggle Competition**. DO NOT USE any other Tanzania waterpump datasets that you might find online.\n",
        "\n",
        "There are two ways you can get the dataset. Make sure you have joined the competition first!:\n",
        "\n",
        "1. You can download the dataset directly by accessing the challenge and the files through the Kaggle Competition URL on Canvas (make sure you have joined the competition!)\n",
        "\n",
        "2. Use the Kaggle API using the code in the following cells. This article provides helpful information on how to fetch your Kaggle Dataset into Google Colab using the Kaggle API.\n",
        "\n",
        "> https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6TZ5nDFYkCa"
      },
      "source": [
        "# Using Kaggle API to download datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2e6fPUATxLZ",
        "outputId": "8099bdf3-dfcb-4976-f065-581bf483fd26"
      },
      "source": [
        "# mounting your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYSpUv9uYBAo",
        "outputId": "3d6b9a89-96ef-4c3e-b4b2-1adc1e7a3e35"
      },
      "source": [
        "#change your working directory, if you want to or have already saved your kaggle dataset on google drive.\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "# update it to your folder location on drive that contains the dataset and/or kaggle API token json file."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXChvgdZYb_t"
      },
      "source": [
        "# Download your Kaggle Dataset, if you haven't already done so.\n",
        "# import os\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# !kaggle competitions download -c bloomtech-water-pump-challenge # double check if this command corresponds with the one given in Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB84qgRRYdDF"
      },
      "source": [
        "# Unzip your Kaggle dataset, if you haven't already done so.\n",
        "# !unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eag2zYiQYf6q",
        "outputId": "7245f6d5-1841-4d8a-d7fb-b84710a7eae9"
      },
      "source": [
        "# List all files in your Kaggle folder on your google drive.\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission.csv  test_features.csv  train_features.csv  train_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKGp79CErOo-"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXNKAp0MFnXW"
      },
      "source": [
        "%%capture\n",
        "!pip install category_encoders==2.*"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLiyUNS0Sy-i",
        "ExecuteTime": {
          "end_time": "2023-07-07T14:15:45.558935Z",
          "start_time": "2023-07-07T14:15:43.661363Z"
        }
      },
      "source": [
        "# data analysis and wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# encoders\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Bagged Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# NEW IMPORTS!!!!\n",
        "# Boosted Models\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Permutation Importance\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# for displaying images and html\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "LRzsNZZXw6mx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfhziD2Wn_iO"
      },
      "source": [
        "# Wrangle Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AomWBQncSy-j"
      },
      "source": [
        "We'll go back to Tanzania Waterpumps for this lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import test_features.csv, train_features.csv and train_labels.csv, 3 files, from Sprint 6 folder."
      ],
      "metadata": {
        "id": "K7TIXStkHI_J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-TExplb_Slf"
      },
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "    if tv_path:\n",
        "        df = pd.merge(pd.read_csv(fm_path, parse_dates=['date_recorded'], na_values=[-2e-08, 0]),\n",
        "                         pd.read_csv(tv_path)).set_index('date_recorded')\n",
        "\n",
        "    else:\n",
        "        df = pd.read_csv(fm_path, parse_dates=['date_recorded']).set_index('date_recorded')\n",
        "\n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because of the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year',\n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        df[col] = df[col].replace(0, np.nan)\n",
        "        df[col+'_MISSING'] = df[col].isnull()\n",
        "\n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    df = df.drop(columns=duplicates)\n",
        "\n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    df = df.drop(columns=unusable_variance)\n",
        "\n",
        "    # Extract components from date_recorded\n",
        "    df['year_recorded'] = df.index.year\n",
        "    df['month_recorded'] = df.index.month\n",
        "    df['day_recorded'] = df.index.day\n",
        "\n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    df['pump_age'] = df['year_recorded'] - df['construction_year']\n",
        "    df['years_MISSING'] = df['pump_age'].isnull()\n",
        "\n",
        "    # return the wrangled dataframe\n",
        "    return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ik6YLCOSy-j"
      },
      "source": [
        "fm_path = 'train_features.csv'\n",
        "tv_path = 'train_labels.csv'\n",
        "\n",
        "df = wrangle(fm_path, tv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSCa9nPnSy-k"
      },
      "source": [
        "# Split data into feature and target\n",
        "target = 'status_group'\n",
        "X, y = df.drop(columns = target), df[target]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYLn6NLESy-k"
      },
      "source": [
        "# Split data into train, validation and test sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxOEAYnUSy-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a884ef-7ec8-42cd-ebe7-50605744b769"
      },
      "source": [
        "# Baseline Metric\n",
        "print('The baseline accuracy is ', y_train.value_counts(normalize=True).max())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The baseline accuracy is  0.5425489938182296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdQArUyM2eDG",
        "outputId": "324db365-a9ff-49b8-effe-5b37d745aa2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date_recorded\n",
              "2011-07-27             non functional\n",
              "2013-02-13                 functional\n",
              "2013-01-19             non functional\n",
              "2013-09-03             non functional\n",
              "2011-07-14    functional needs repair\n",
              "                       ...           \n",
              "2011-08-03                 functional\n",
              "2011-07-16                 functional\n",
              "2011-03-09                 functional\n",
              "2011-02-20                 functional\n",
              "2011-03-19                 functional\n",
              "Name: status_group, Length: 38015, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3jiNoOEgIbi"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagged model - Random Forest"
      ],
      "metadata": {
        "id": "8B-KdTE-Xp5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A weak model is just a decision tree that works slightly beter than the baseline accuracy.\n",
        "- Random forest is one of the ensembling technique using bagging, we have other techniques like boosting\n",
        "  - Bootstrap - sampling with replacement\n",
        "  - Bagging - collective voting or bootstrap aggregation, a type of non-sequential learning method\n",
        "  - it goes through bootstrap sampling, building the trees on a random set of features, aggregating the results.\n",
        "  - In a classification model, the majority voting will be the final result.\n",
        "  - In a regression model, the average prediction will be the final result.\n",
        "  - We build trees parallel to each other, because each tree is independent of each other"
      ],
      "metadata": {
        "id": "PUCrz9okQufZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model\n",
        "\n",
        "model_rf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1,n_estimators=75)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "model_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "9ttetGUElX8-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "b2ec020c-5868-453b-9c9b-e8a99b500565"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'installer', 'wpt_name',\n",
              "                                      'basin', 'subvillage', 'region', 'lga',\n",
              "                                      'ward', 'public_meeting',\n",
              "                                      'scheme_management', 'scheme_name',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'management_group', 'payment',\n",
              "                                      'water_quality', 'quality_group',\n",
              "                                      'quantity', 'source',...\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                                         {'col': 'waterpoint_type_group',\n",
              "                                          'data_type': dtype('O'),\n",
              "                                          'mapping': hand pump             1\n",
              "communal standpipe    2\n",
              "improved spring       3\n",
              "other                 4\n",
              "cattle trough         5\n",
              "dam                   6\n",
              "NaN                  -2\n",
              "dtype: int64}])),\n",
              "                ('simpleimputer', SimpleImputer(strategy='median')),\n",
              "                ('randomforestclassifier',\n",
              "                 RandomForestClassifier(n_estimators=75, n_jobs=-1,\n",
              "                                        random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ordinalencoder&#x27;,\n",
              "                 OrdinalEncoder(cols=[&#x27;funder&#x27;, &#x27;installer&#x27;, &#x27;wpt_name&#x27;,\n",
              "                                      &#x27;basin&#x27;, &#x27;subvillage&#x27;, &#x27;region&#x27;, &#x27;lga&#x27;,\n",
              "                                      &#x27;ward&#x27;, &#x27;public_meeting&#x27;,\n",
              "                                      &#x27;scheme_management&#x27;, &#x27;scheme_name&#x27;,\n",
              "                                      &#x27;permit&#x27;, &#x27;extraction_type&#x27;,\n",
              "                                      &#x27;extraction_type_group&#x27;,\n",
              "                                      &#x27;extraction_type_class&#x27;, &#x27;management&#x27;,\n",
              "                                      &#x27;management_group&#x27;, &#x27;payment&#x27;,\n",
              "                                      &#x27;water_quality&#x27;, &#x27;quality_group&#x27;,\n",
              "                                      &#x27;quantity&#x27;, &#x27;source&#x27;,...\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                                         {&#x27;col&#x27;: &#x27;waterpoint_type_group&#x27;,\n",
              "                                          &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
              "                                          &#x27;mapping&#x27;: hand pump             1\n",
              "communal standpipe    2\n",
              "improved spring       3\n",
              "other                 4\n",
              "cattle trough         5\n",
              "dam                   6\n",
              "NaN                  -2\n",
              "dtype: int64}])),\n",
              "                (&#x27;simpleimputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                (&#x27;randomforestclassifier&#x27;,\n",
              "                 RandomForestClassifier(n_estimators=75, n_jobs=-1,\n",
              "                                        random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ordinalencoder&#x27;,\n",
              "                 OrdinalEncoder(cols=[&#x27;funder&#x27;, &#x27;installer&#x27;, &#x27;wpt_name&#x27;,\n",
              "                                      &#x27;basin&#x27;, &#x27;subvillage&#x27;, &#x27;region&#x27;, &#x27;lga&#x27;,\n",
              "                                      &#x27;ward&#x27;, &#x27;public_meeting&#x27;,\n",
              "                                      &#x27;scheme_management&#x27;, &#x27;scheme_name&#x27;,\n",
              "                                      &#x27;permit&#x27;, &#x27;extraction_type&#x27;,\n",
              "                                      &#x27;extraction_type_group&#x27;,\n",
              "                                      &#x27;extraction_type_class&#x27;, &#x27;management&#x27;,\n",
              "                                      &#x27;management_group&#x27;, &#x27;payment&#x27;,\n",
              "                                      &#x27;water_quality&#x27;, &#x27;quality_group&#x27;,\n",
              "                                      &#x27;quantity&#x27;, &#x27;source&#x27;,...\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                                         {&#x27;col&#x27;: &#x27;waterpoint_type_group&#x27;,\n",
              "                                          &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
              "                                          &#x27;mapping&#x27;: hand pump             1\n",
              "communal standpipe    2\n",
              "improved spring       3\n",
              "other                 4\n",
              "cattle trough         5\n",
              "dam                   6\n",
              "NaN                  -2\n",
              "dtype: int64}])),\n",
              "                (&#x27;simpleimputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                (&#x27;randomforestclassifier&#x27;,\n",
              "                 RandomForestClassifier(n_estimators=75, n_jobs=-1,\n",
              "                                        random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(cols=[&#x27;funder&#x27;, &#x27;installer&#x27;, &#x27;wpt_name&#x27;, &#x27;basin&#x27;, &#x27;subvillage&#x27;,\n",
              "                     &#x27;region&#x27;, &#x27;lga&#x27;, &#x27;ward&#x27;, &#x27;public_meeting&#x27;,\n",
              "                     &#x27;scheme_management&#x27;, &#x27;scheme_name&#x27;, &#x27;permit&#x27;,\n",
              "                     &#x27;extraction_type&#x27;, &#x27;extraction_type_group&#x27;,\n",
              "                     &#x27;extraction_type_class&#x27;, &#x27;management&#x27;, &#x27;management_group&#x27;,\n",
              "                     &#x27;payment&#x27;, &#x27;water_quality&#x27;, &#x27;quality_group&#x27;, &#x27;quantity&#x27;,\n",
              "                     &#x27;source&#x27;, &#x27;source_type&#x27;, &#x27;source_class&#x27;, &#x27;wate...\n",
              "                         &#x27;mapping&#x27;: groundwater    1\n",
              "surface        2\n",
              "unknown        3\n",
              "NaN           -2\n",
              "dtype: int64},\n",
              "                        {&#x27;col&#x27;: &#x27;waterpoint_type&#x27;, &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
              "                         &#x27;mapping&#x27;: hand pump                      1\n",
              "communal standpipe             2\n",
              "communal standpipe multiple    3\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                        {&#x27;col&#x27;: &#x27;waterpoint_type_group&#x27;,\n",
              "                         &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
              "                         &#x27;mapping&#x27;: hand pump             1\n",
              "communal standpipe    2\n",
              "improved spring       3\n",
              "other                 4\n",
              "cattle trough         5\n",
              "dam                   6\n",
              "NaN                  -2\n",
              "dtype: int64}])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=75, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boosted Model\n",
        "### Gradient Boosted Model"
      ],
      "metadata": {
        "id": "WLZsFfzoXuhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting\n",
        "- boosting is different from bootstrapping\n",
        "- The trees grow sequentially aka model builds trees one after another, improving upon itself after each iteration\n",
        "- each tree is grown using info from the previously grown trees, we build trees one after the other.\n",
        "- we build the model on the entire training set, no longer have to take a random subset\n",
        "- Sequential modeling:\n",
        "1. One tree is built, then all the points that were misclassified by the first tree are focused on, and their weight is increased for the next iteration. The algorithm learns from the previous mistakes.\n",
        "2. Subsequent tree focuses on these misclassified examples, you slowly learn from the previous mistakes\n",
        "3. Final prediction is nothing but the weighted majority vote or the weighted median in case of regression"
      ],
      "metadata": {
        "id": "9yb2-E2VSm6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosted Model\n",
        "model_gb = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    GradientBoostingClassifier(random_state=42, n_estimators=75)\n",
        ")\n",
        "\n",
        "model_gb.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "5nGicyaLlX3V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "899a2182-9ad2-4a79-e8fe-f3e60b95abce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'installer', 'wpt_name',\n",
              "                                      'basin', 'subvillage', 'region', 'lga',\n",
              "                                      'ward', 'public_meeting',\n",
              "                                      'scheme_management', 'scheme_name',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'management_group', 'payment',\n",
              "                                      'water_quality', 'quality_group',\n",
              "                                      'quantity', 'source',...\n",
              "communal standpipe multiple    3\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                                         {'col': 'waterpoint_type_group',\n",
              "                                          'data_type': dtype('O'),\n",
              "                                          'mapping': hand pump             1\n",
              "communal standpipe    2\n",
              "improved spring       3\n",
              "other                 4\n",
              "cattle trough         5\n",
              "dam                   6\n",
              "NaN                  -2\n",
              "dtype: int64}])),\n",
              "                ('simpleimputer', SimpleImputer()),\n",
              "                ('gradientboostingclassifier',\n",
              "                 GradientBoostingClassifier(n_estimators=75, random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ordinalencoder&#x27;,\n",
              "                 OrdinalEncoder(cols=[&#x27;funder&#x27;, &#x27;installer&#x27;, &#x27;wpt_name&#x27;,\n",
              "                                      &#x27;basin&#x27;, &#x27;subvillage&#x27;, &#x27;region&#x27;, &#x27;lga&#x27;,\n",
              "                                      &#x27;ward&#x27;, &#x27;public_meeting&#x27;,\n",
              "                                      &#x27;scheme_management&#x27;, &#x27;scheme_name&#x27;,\n",
              "                                      &#x27;permit&#x27;, &#x27;extraction_type&#x27;,\n",
              "                                      &#x27;extraction_type_group&#x27;,\n",
              "                                      &#x27;extraction_type_class&#x27;, &#x27;management&#x27;,\n",
              "                                      &#x27;management_group&#x27;, &#x27;payment&#x27;,\n",
              "                                      &#x27;water_quality&#x27;, &#x27;quality_group&#x27;,\n",
              "                                      &#x27;quantity&#x27;, &#x27;source&#x27;,...\n",
              "communal standpipe multiple    3\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                                         {&#x27;col&#x27;: &#x27;waterpoint_type_group&#x27;,\n",
              "                                          &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
              "                                          &#x27;mapping&#x27;: hand pump             1\n",
              "communal standpipe    2\n",
              "improved spring       3\n",
              "other                 4\n",
              "cattle trough         5\n",
              "dam                   6\n",
              "NaN                  -2\n",
              "dtype: int64}])),\n",
              "                (&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
              "                (&#x27;gradientboostingclassifier&#x27;,\n",
              "                 GradientBoostingClassifier(n_estimators=75, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ordinalencoder&#x27;,\n",
              "                 OrdinalEncoder(cols=[&#x27;funder&#x27;, &#x27;installer&#x27;, &#x27;wpt_name&#x27;,\n",
              "                                      &#x27;basin&#x27;, &#x27;subvillage&#x27;, &#x27;region&#x27;, &#x27;lga&#x27;,\n",
              "                                      &#x27;ward&#x27;, &#x27;public_meeting&#x27;,\n",
              "                                      &#x27;scheme_management&#x27;, &#x27;scheme_name&#x27;,\n",
              "                                      &#x27;permit&#x27;, &#x27;extraction_type&#x27;,\n",
              "                                      &#x27;extraction_type_group&#x27;,\n",
              "                                      &#x27;extraction_type_class&#x27;, &#x27;management&#x27;,\n",
              "                                      &#x27;management_group&#x27;, &#x27;payment&#x27;,\n",
              "                                      &#x27;water_quality&#x27;, &#x27;quality_group&#x27;,\n",
              "                                      &#x27;quantity&#x27;, &#x27;source&#x27;,...\n",
              "communal standpipe multiple    3\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                                         {&#x27;col&#x27;: &#x27;waterpoint_type_group&#x27;,\n",
              "                                          &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
              "                                          &#x27;mapping&#x27;: hand pump             1\n",
              "communal standpipe    2\n",
              "improved spring       3\n",
              "other                 4\n",
              "cattle trough         5\n",
              "dam                   6\n",
              "NaN                  -2\n",
              "dtype: int64}])),\n",
              "                (&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
              "                (&#x27;gradientboostingclassifier&#x27;,\n",
              "                 GradientBoostingClassifier(n_estimators=75, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(cols=[&#x27;funder&#x27;, &#x27;installer&#x27;, &#x27;wpt_name&#x27;, &#x27;basin&#x27;, &#x27;subvillage&#x27;,\n",
              "                     &#x27;region&#x27;, &#x27;lga&#x27;, &#x27;ward&#x27;, &#x27;public_meeting&#x27;,\n",
              "                     &#x27;scheme_management&#x27;, &#x27;scheme_name&#x27;, &#x27;permit&#x27;,\n",
              "                     &#x27;extraction_type&#x27;, &#x27;extraction_type_group&#x27;,\n",
              "                     &#x27;extraction_type_class&#x27;, &#x27;management&#x27;, &#x27;management_group&#x27;,\n",
              "                     &#x27;payment&#x27;, &#x27;water_quality&#x27;, &#x27;quality_group&#x27;, &#x27;quantity&#x27;,\n",
              "                     &#x27;source&#x27;, &#x27;source_type&#x27;, &#x27;source_class&#x27;, &#x27;wate...\n",
              "                         &#x27;mapping&#x27;: groundwater    1\n",
              "surface        2\n",
              "unknown        3\n",
              "NaN           -2\n",
              "dtype: int64},\n",
              "                        {&#x27;col&#x27;: &#x27;waterpoint_type&#x27;, &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
              "                         &#x27;mapping&#x27;: hand pump                      1\n",
              "communal standpipe             2\n",
              "communal standpipe multiple    3\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                        {&#x27;col&#x27;: &#x27;waterpoint_type_group&#x27;,\n",
              "                         &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
              "                         &#x27;mapping&#x27;: hand pump             1\n",
              "communal standpipe    2\n",
              "improved spring       3\n",
              "other                 4\n",
              "cattle trough         5\n",
              "dam                   6\n",
              "NaN                  -2\n",
              "dtype: int64}])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=75, random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- some hyperparameters include max_depth, n_estimators aka number of trees, learning rate\n",
        "- Learning Rate = we can choose how much each tree is gonna contribute toward the learning of the model\n",
        "- There's a tradeoff between learning rate and number of trees I wanna build.\n",
        "- Max depth ensures that samples are not memorized and overfitting does not happen.\n",
        "\n",
        "PROS for using Boosted Models\n",
        "- Gradient boosted models are more sensitive than random forest in hyperparameter tuning. If we were to take a boosted and a bagged model out of the box, boosted model won't work as well right away, but it can beneift a lot from hyperparameter tuning.\n",
        "\n",
        "CONS:\n",
        "- time-consuming, building one tree at a time, also need to remember the results from the previous tree\n",
        "- focus a lot on misclassified data, imagine if we have a lot of outliers or noise. So, doesn't work well with data with a lot of outliers"
      ],
      "metadata": {
        "id": "-_0WPEb1Vsdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extreme Gradient Boosted (XGB) Model"
      ],
      "metadata": {
        "id": "y17_AZzOX6ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- increase speed and performance while having regularization parameters to prevent overfitting\n",
        "- remember regularization is to shrink the coefficients to bring them to a much lower value such as in Ridge Regression\n",
        "\n",
        "PROS:\n",
        "- speed\n",
        "- lower variance because of the regularization parameter\n",
        "\n",
        "CONS:\n",
        "- hard to understand\n",
        "- complex because a lot of hyperparameters to tune"
      ],
      "metadata": {
        "id": "BgxFE7njYIyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB Model\n",
        "model_xgb = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    XGBClassifier(random_state=42, n_estimators=75, n_jobs=-1)\n",
        ")\n",
        "# even tho this is a sequential model (not parallel like RF), we still have ability to implement parallelization with n_jobs in some other aspects of training besides sequential building of tree\n",
        "# model_xgb.fit(X_train, y_train);\n"
      ],
      "metadata": {
        "id": "G9jhk-ylPJ8-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "OveqQyMxaAtF",
        "outputId": "e5497a29-5ae0-4b10-f52d-033f2f5bbcce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-78cb06123804>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1465\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m             ):\n\u001b[0;32m-> 1467\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1468\u001b[0m                     \u001b[0;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;34mf\"Expected: {expected_classes}, got {classes}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['functional' 'functional needs repair' 'non functional']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfmiBiimgIbj"
      },
      "source": [
        "# Check Metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Accuracy', model_rf.score(X_train, y_train))\n",
        "print('Validation Accuracy', model_rf.score(X_val, y_val))\n",
        "# RF will perform the best out of the box without any tuning"
      ],
      "metadata": {
        "id": "9r2ePpByPSZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2565709-497f-4f5c-9084-54014922c651"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy 0.9999210837827174\n",
            "Validation Accuracy 0.8041877104377104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8lB4z5l_eml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25e139a-3a58-4fb3-8567-0edee82f59de"
      },
      "source": [
        "print('Training Accuracy', model_gb.score(X_train, y_train))\n",
        "print('Validation Accuracy', model_gb.score(X_val, y_val))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy 0.7537287912666053\n",
            "Validation Accuracy 0.7432659932659933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmLrHQlMSy-m"
      },
      "source": [
        "print('Training Accuracy', model_xgb.score(X_train, y_train))\n",
        "print('Validation Accuracy', model_xgb.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7-ml6BhRRf"
      },
      "source": [
        "### Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djCjZ5WBgIbk"
      },
      "source": [
        "# Tuning / Communication\n",
        "\n",
        "- How can we determine or communicate which features are most important to our model when making predictions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvFQRNbSTwle"
      },
      "source": [
        "**Option 1:** Grab feature importances from our pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is local and there is global feature importance\n",
        "  - Global feature importances measure the importance of the feature for the entire model\n",
        "  - Local feature importance measures the importance of the feature for one specific observation or sample"
      ],
      "metadata": {
        "id": "oNdE0NRHLAc9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgTWgFV6MaTW"
      },
      "source": [
        "importances = model_xgb.named_steps['xgbclassifier'].feature_importances_\n",
        "feature_names = X_train.columns\n",
        "feat_imp = pd.Series(data=importances, index=feature_names).sort_values()\n",
        "\n",
        "feat_imp.tail(10).plot(kind='barh')\n",
        "plt.xlabel('Gini Importance') # Gini is the probability of misclassifying data\n",
        "                              # the more the impurity decreases, the more important that feature towards the predictions\n",
        "plt.ylabel('Feature')\n",
        "\n",
        "# the plot shows that x-axis with Gini importance and y-axis with features. The most important feature quantity.\n",
        "# problem of misleading info esp. if I have high cardinality, inflate importance, or when we have correlated features\n",
        "# quick and easy but not the best one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN3aL3FeT-fC"
      },
      "source": [
        "**Option 2:** Drop-column Importance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- use the process of elimination and re-training\n",
        "- we take one feature and remove it, and check the accuracy again. If the accuracy drops then that means it's important\n",
        "- time-consuming, have to re-train the model"
      ],
      "metadata": {
        "id": "-cfIskcyN-HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_column = 'quantity'"
      ],
      "metadata": {
        "id": "bo-aZhrYmdL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB model with everything, don't need to re-run\n",
        "model_with_col = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(n_estimators=75,\n",
        "                  random_state=42,\n",
        "                  n_jobs=-1,)\n",
        ")\n",
        "\n",
        "model_with_col.fit(X_train, y_train)\n",
        "\n",
        "print(f'Validation Accuracy w/ \"{selected_column}\" included:', model_with_col.score(X_val, y_val))\n",
        "\n",
        "# validation accuracy with the quantity column included is 0.7377"
      ],
      "metadata": {
        "id": "eohb8YLqmdDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB model except one selected column, need to re-train model every time when we select a new column to test\n",
        "model_without_col = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(n_estimators=75,\n",
        "                  random_state=42,\n",
        "                  n_jobs=-1,)\n",
        ")\n",
        "\n",
        "model_without_col.fit(X_train.drop(columns=selected_column), y_train)\n",
        "\n",
        "\n",
        "print(f'Validation Accuracy w/ \"{selected_column}\" excluded:', model_without_col.score(X_val.drop(columns=selected_column), y_val))\n",
        "\n",
        "# validation accuracy with quantity column excluded is 0.7057\n",
        "# it has dropped when quantity column is missing, that means quantity is important in the model"
      ],
      "metadata": {
        "id": "bda1KdZZmcqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ya23IUpmcjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLhviblHgIbn"
      },
      "source": [
        "**Option 3:** Permutation Importance\n",
        "\n",
        "![](https://i.imgur.com/h17tMUU.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- very similar to drop column importance method but takes much less time\n",
        "- train the model with all the features, then select one feature to measure the importance, then measure the performance of my validation set with the selected feature shuffled\n",
        "- rearrangement in a random process, if accuracy drops by a lot after shuffling, that means the feature is important\n",
        "- we corrupt the X_val column and then we test it, so it's less intensive\n",
        "- PROS: we don't have to re-train the model many times."
      ],
      "metadata": {
        "id": "TUZcfrnlQNt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We can do it by hand"
      ],
      "metadata": {
        "id": "KBJrMINSSbyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By hand\n",
        "\n",
        "# Step 1: Choose my feature\n",
        "column_to_permute = 'quantity'\n",
        "\n",
        "# Step 2: Train model w/ ALL features\n",
        "model_to_permute = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(n_estimators=75,\n",
        "                  random_state=42,\n",
        "                  n_jobs=-1,)\n",
        ")\n",
        "\n",
        "model_to_permute.fit(X_train, y_train);"
      ],
      "metadata": {
        "id": "NESnUf2WQQTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Evaluate model using VALIDATION DATA.\n",
        "print('Validation Accuracy', model_to_permute.score(X_val, y_val))\n",
        "\n",
        "# validation accuracy is 0.7377"
      ],
      "metadata": {
        "id": "4ux4hkWWQQJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: In VALIDATION DATA, permute the feature we're evaluating\n",
        "X_val_perm = X_val.copy() # make a copy before shuffling the data\n",
        "X_val_perm[column_to_permute] = np.random.permutation(X_val_perm[column_to_permute]) # save as a new column\n",
        "# it's a random process so every run will give a diff permutation"
      ],
      "metadata": {
        "id": "h1hPgbaHQaF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Calculate our error metric with the permuted data\n",
        "print('Validation Accuracy', model_to_permute.score(X_val_perm, y_val)) # remember the permutated data, not the original X_val\n",
        "# we got accuracy score of 0.6443\n",
        "# accuracy decreases, which means quantity column is important feature to consider"
      ],
      "metadata": {
        "id": "I2Q-EQZMQeFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Or we can get it automated with sklearn"
      ],
      "metadata": {
        "id": "kfAleYzGShCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Automated using sklearn\n",
        "\n",
        "perm_imp = permutation_importance(model_to_permute, X_val, y_val, random_state=42)\n",
        "# it will return a dictionary, takes time to calculate because it needs to shuffle everything in dataset more than once, shuffling times by default is 5 or you can use n_repeats=5 or other number\n",
        "# 2D array of permutation importances of all the columns, also mean and std of importances of every feature also calculated from the 5 shuffles\n",
        "# dictionary has 5 columns, each column is the importances for each shuffle, each row is an importance of a feature"
      ],
      "metadata": {
        "id": "w2qYc0aAP9pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWrWCtO4P9mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grabbing all the mean and std and save it to a dataframe\n",
        "\n",
        "# create a dictionary with 2 columns of data, imp_mean and imp_std\n",
        "data_perm = {'imp_mean':perm_imp['importances_mean'],\n",
        "             'imp_std':perm_imp['importances_std']}\n",
        "\n",
        "# then we just add index= to label each row of data\n",
        "df_perm = pd.DataFrame(data_perm, index=X_val.columns).sort_values('imp_mean')"
      ],
      "metadata": {
        "id": "ocMn9FFDP-AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_perm\n",
        "# row names are all the features\n",
        "# column names are imp_mean and imp_std\n",
        "# if there are values close to 0, that means it's not that important"
      ],
      "metadata": {
        "id": "MfRMVXpFP_uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting top 10 features\n",
        "df_perm['imp_mean'].tail(10).plot(kind='barh')\n",
        "\n",
        "# horizontal bar graph with quantity the longest, followed by waterpoint_type and payment\n",
        "\n",
        "# we can also look at the most unimportant features - e.g. ones with negative values and the ones close to 0"
      ],
      "metadata": {
        "id": "pOt63i7vQEoC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}