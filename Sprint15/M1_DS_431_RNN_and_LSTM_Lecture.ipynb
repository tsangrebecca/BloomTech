{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsangrebecca/BloomTech/blob/main/Sprint15/M1_DS_431_RNN_and_LSTM_Lecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsrwhKw4ohgW"
      },
      "source": [
        "# 1. Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) -- Prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et2y0gP7IM19"
      },
      "source": [
        "\n",
        "\n",
        "![](https://wiki.tum.de/download/attachments/22578349/GATES.gif?version=1&modificationDate=1486083227237&api=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BOMScPtIM1-"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe How Neural Networks are used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Implement LSTM models for a text classification problem and a text generation problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IizNKWLomoA"
      },
      "source": [
        "-----\n",
        "## Overview\n",
        "\n",
        "### Let's start with sequences\n",
        "\n",
        "A sequence is a collection of numbers, taking into account their order; repetition is allowed.\n",
        "\n",
        "Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list and is different from `[1, 2, -1, 2]`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "## 1.1 Recursion (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW6xwTptbDjx"
      },
      "source": [
        "\n",
        "A recursive function is a function that can call itself!<br><br>\n",
        "For a recursive function to be defined, there must be a _base case_ that the function eventually reaches by repeatedly calling itself.<br><br>\n",
        "\n",
        "###1.1.1 The factorial function\n",
        "A simple example of recursion is the _factorial_ function, <br>\n",
        "denoted by the character $!$ following a non-negative integer<br><br>\n",
        "$n! \\equiv n\\cdot (n-1) \\cdot (n-2) \\cdot \\ldots \\cdot  1$ <br><br>\n",
        "and $0! \\equiv  1$,<br><br>\n",
        "where $\\equiv$ means \"is defined as\"<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVaPpQdkbB3p"
      },
      "outputs": [],
      "source": [
        "def factorial(n):\n",
        "  if(n==0 or n==1):\n",
        "    return 1 #base case\n",
        "  elif(n>1):\n",
        "    return n*factorial(n-1) # recursion formula"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap93tVqvdGKF"
      },
      "source": [
        "5! = 5 x 4 x 3 x 2 x 1 =120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH3AUX27rsZo",
        "outputId": "c18ba22c-9a29-40d1-b294-0198cb0b27ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "factorial(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX_WLYHrIM1_"
      },
      "source": [
        "###1.1.2 The Fibonacci Sequence\n",
        "\n",
        "Before we dive into the inner workings of an LSTM model, let's try to understand and appreciate **recursion** in sequences. <br>A **recursive sequence** is a sequence in which the next number can be computed from one or more of the previous numbers via a [**recurrence relation**](https://en.wikipedia.org/wiki/Recurrence_relation). Recursion occurs in both pure mathematics and in the physical world in which we find ourselves embedded. <br><br>\n",
        "The root word is **recur**, which means \"to occur repeatedly\". Given a few consecutive values, the rest of a recursive sequence can be generated by repeatedly applying its recursion relation!\n",
        "\n",
        "\n",
        "As usual, we attempt to understand a concept from at least 3 different perspectives:\n",
        "- Algebraic\n",
        "- Geometric\n",
        "- Coding an example\n",
        "\n",
        "A famous example of a recursive sequence in mathematics is the [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number). Fibonacci was an Italian mathematician, who wrote about these numbers in **The Book of Calculation**, in 1202 AD. Although the sequence is named after him, it was known long before his time in India.\n",
        "\n",
        "The Fibonacci numbers are an infinite sequence of integers, beginning with $[0, 1]$ in which the $ith$ number (for $i>1$) is the sum of the two previous numbers.\n",
        "\n",
        "Here is the algorithm for generating the numbers in the Fibonacci sequence:\n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$\n",
        "\n",
        "You need a **base case** $F_0=0$ and $F_1=1$ to get the sequence started.\n",
        "\n",
        "Starting from the base case, the recursion relation generates the entire sequence:\n",
        "\n",
        "$F_0=0,~~  F_1=1 $<br><br>\n",
        "\n",
        "$F_2 = F_{1} + F_{0} ~=~ 1 + 0 ~=~ 1$<br><br>\n",
        "\n",
        "Then\n",
        "\n",
        "$F_3 = F_{2} + F_{1} ~=~ 1 + 1 ~=~ 2$<br><br>\n",
        "\n",
        "Then\n",
        "\n",
        "$F_4 = F_{3} + F_{2} ~=~ 2 + 1 ~=~ 3$<br><br>\n",
        "\n",
        "Then\n",
        "\n",
        "$F_5 = F_{4} + F_{3} ~=~ 3 + 2 ~=~ 5$<br><br>\n",
        "\n",
        "etc.\n",
        "\n",
        "Get the idea?\n",
        "\n",
        "Now you try: what are $F_{6}$ and $F_{7}$?\n",
        "\n",
        "#### ##Your answer here\n",
        "5 + 3 = 8\n",
        "\n",
        "8 + 5 = 13\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpoASUlBvhEK"
      },
      "source": [
        "### 1.1.3 The Fibonacci Sequence in Nature\n",
        "Before coding up the Fibonacci sequence, let's take a moment to appreciate<br>\n",
        "its beauty, and how important and ubiquitous it is in nature!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCO2jNOjuH03"
      },
      "source": [
        "#### **Contruction of the [\"Golden Spiral\"](https://en.wikipedia.org/wiki/Golden_spiral)**\n",
        "![](http://www.davidbeahm.com/wp-content/uploads/2011/11/fibonacci-1024x637.jpg)\n",
        "\n",
        "#### **Snail Shells**\n",
        "![](https://i.pinimg.com/originals/32/d7/47/32d747bea24f4756dc4c5ffe61b36efd.jpg)\n",
        "\n",
        "#### **The Mona Lisa**\n",
        "![](https://i.pinimg.com/originals/f2/cb/34/f2cb3452dd774bab87bbee2b8a77d4bb.png)\n",
        "\n",
        "#### **A Spiral Galaxy**\n",
        "![](https://f4.bcbits.com/img/a3628582449_10.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-HQ2GEp9uB7"
      },
      "source": [
        "#### **Take Away:**\n",
        "- There are often surprising connections between mathematics and physical phenomena\n",
        "- The world contains many examples of recursive sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObIXp1Wh9uB7"
      },
      "source": [
        "### 1.1.4 Coding the Fibonacci Sequence using a recursive function\n",
        "*This is a standard problem that often comes up in interviews for software engineering jobs!*<br>\n",
        "\n",
        "Recall: A recursive function is a function that can call itself.<br>\n",
        "For a recursive function to be defined, there must be a _base case_ that the function eventually reaches by repeatedly calling itself.<br>\n",
        "\n",
        "For the Fibonacci sequence, the _base case_ is<br><br>\n",
        "$$F_0=0 ~\\text{and}~ F_1=1$$<br><br>\n",
        "Again, here is the algorithm for the Fibonacci numbers.  \n",
        "\n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$<br>\n",
        "\n",
        "So we want a recursive function that, given an integer $n$ computes the $nth$ Fibonacci number by repeatedly calling itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9DS5sFTX9uB8"
      },
      "outputs": [],
      "source": [
        "def fibo(n):\n",
        "    \"\"\"\n",
        "    Calculate and return the next number in the Fibonacci sequence\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    n: int or float\n",
        "        The nth number in the sequence (think of it as an index for a list)\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    F_n: the next number in the sequence generated from the previous two numbers in the sequence\n",
        "    \"\"\"\n",
        "\n",
        "    if n <= 1: # this is the base case\n",
        "        F_n = n\n",
        "    elif n > 1: # this is the recursive case, where the function calls itself!\n",
        "        F_n = fibo(n-1) + fibo(n-2)\n",
        "    return F_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-J9V1xC9uB-",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b31ecb0aaf3ace76",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "b7d6bdb4-f3b2-4db2-d573-d541aa3f24c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Using our recursive function, generate the first 10 values of the Fibonacci Sequence\n",
        "###BEGIN SOLUTION\n",
        "[fibo(n) for n in range(10)]\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gomC-EGf9wK6",
        "outputId": "b8435c10-3042-41d4-a8e2-3dadc1358a0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6765"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "fibo(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VSGduuZpymbD"
      },
      "outputs": [],
      "source": [
        "# 5! = 5*4*3*2*1 =  5*4! --> n! = n*(n-1)!\n",
        "\n",
        "\n",
        "def factorial(n):\n",
        "  if n==1:\n",
        "    return 1 #base case\n",
        "  else:\n",
        "    return n*factorial(n-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPQASrwt9uB_"
      },
      "source": [
        "**Take Away:**\n",
        "\n",
        "Recursive algorithms have as input their previous output. <br>\n",
        "In other words, the output at time step $t - 1$, becomes the input for the following time step $t$.<br><br>\n",
        "This key idea of recursion underlies the construction of a Recurrent Neural Networks (RNNs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-zlyhan9uCA"
      },
      "source": [
        "-----\n",
        "\n",
        "## 1.2 Introduction to Recursive Neural Networks (RNNs)\n",
        "\n",
        "\n",
        "Now that we've gained insight into the recursion process, we can build on <br>\n",
        "our intuition to help us understand how RNNs and LSTMs work.\n",
        "\n",
        "Recurrent Neural Networks (RNNs) have a recursive loop in their architecture. The RNN model was first formulated in the original [backpropagation paper](https://chsasank.com/classic_papers/learning-representations-back-propogating-errors.html#) by Rumelhart et al. in 1986, based on the standard Fully-Connected Feed-Forward (FCFF) model:\n",
        "\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "The hidden state $\\textbf{h}$ has the same dimensionality as the input vector $\\textbf{x}$ and is updated at each time step $t$, according to _two inputs_: $x_t$ **and** the previous hidden state $h_{t-1}$. Since for the first input $x_{0}$, the previous hidden state is undefined, it is often initialized to all zeros.  <br><br>\n",
        "\n",
        "**The key to the RNN is the recursive use of the _hidden state_ to learn and carry forward information about all the _previous_ elements of the input sequence.**\n",
        "\n",
        "In principle, this \"memory\" feature of the RNN is an exciting concept that holds the promise to go beyond \"bag-of-words\" models in NLP to be able to encode contextual meaning of sequences of words in documents. However, the practical limitations of RNNs has prevented them from fully delivering on this promise. <br><br>\n",
        "\n",
        "RNNs\n",
        "- don't have long-term memory capacity, so cannot learn from input sequences longer than a few dozen elements long\n",
        "- suffer from the [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).<br><br>\n",
        "\n",
        "To mitigate against these limitations, Hochreiter and Schmidhuber invented the [LSTM model](https://papers.nips.cc/paper/1215-lstm-can-solve-hard-long-time-lag-problems.pdf) in 1996.<br><br>\n",
        "The LSTM model abandons the FCFF architecture in favor of the following architecture:\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "Wow! There's a lot going on here, isn't there? <br>\n",
        "In the next section, we'll break down the LSTM model bit-by-bit so, we can understand a bird's eye view of what is happening."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M49uor5E9uCB"
      },
      "source": [
        "_____\n",
        "\n",
        "\n",
        "## 1.3 Overview of the LSTM (Long Short Term Memory)\n",
        "\n",
        "For this course we will regard the LSTM as a black box, which functions as souped-up, more powerful version of the RNN. You will be responsible for being able to implement and use the LSTM models. Understanding how LSTMs work under the hood is optional, depending on your curiosity and interest.\n",
        "\n",
        "### 1.3.1 The \"vanishing gradient\" problem.  \n",
        "\n",
        "RNNs and LSTMs, like other neural networks we've encountered, are trained using backpropagation with some form of gradient descent. For an \"unrolled\" RNN (or LSTM), backpropagation has to go back through the entire time sequence of states, which is why it's called BPTT (backpropagation through time). If a gradient \"vanishes\", i.e. becomes close to zero somewhere along the line, the parameter updates also \"vanish\", and network training slows down and grinds to a halt because the parameters are becoming vanishingly small. _This is the \"vanishing gradient problem\", which LSTMs were invented to solve_. LSTMs are superior to RNNs because they can remember longer sequences and do not suffer from vanishing gradients.\n",
        "\n",
        "[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah presents a beautifully clear and concise explanation of the model's architecture and the mathematics (mostly matrix multiplication) behind it. This article will serve as our main resource for understanding how LSTMs work.\n",
        "\n",
        "Below are the equations for each of the gates in the LSTM architecture that are explained in the article.\n",
        "\n",
        "Although, you will not be held responsible for the equations in any quiz, module assignment, or Sprint Challenge - it is still instructive to have a look at the machinery inside the black box.\n",
        "\n",
        "First thing to notice is that each gate equation (not the cell states) has the form of a perceptron.\n",
        "\n",
        "Remember the perceptron? It's the fundamental building block of neural networks - it's not going away!\n",
        "\n",
        "Once you understand that, it will hopefully become gradually clear that each gate is a perceptron with a different job to do.\n",
        "\n",
        "That's it.\n",
        "\n",
        "It's just 4 perceptrons, each with a different job to do.\n",
        "\n",
        "Fortunately, you already know about perceptrons (you built one from scratch in `Sprint 2 Module 1`).\n",
        "\n",
        "____\n",
        "\n",
        "### 1.3.2 LSTM Gates\n",
        "\n",
        "#### Forget Gate\n",
        "This neuron's job is to use the current input to learn what information the cell state should forget regarding long-term dependencies.\n",
        "\n",
        "The output from the forget gate $f_t$ is used to scale the old cell state\n",
        "\n",
        "- If $f_t$ is closer to $0.0$, then less information from the previous cell state is retained.\n",
        "- If $f_t$ is closer to $1.0$, then more information from the previous cell state is retained.\n",
        "\n",
        "$$f_t = \\sigma(W_f \\cdot [h_{t-1},x_t]~+~b_f)$$\n",
        "\n",
        "#### Input Gate\n",
        "This neuron's job is to use the current input to learn what new information to include in the cell state.\n",
        "\n",
        "\n",
        "$$i_t = \\sigma(W_i \\cdot [h_{t-1},x_t]~+~b_i)$$\n",
        "\n",
        "#### Candidate Cell State\n",
        "This neuron's job is to use the current input to create a candidate cell state.\n",
        "\n",
        "This new candidate cell state will be used to update the model's final cell state.\n",
        "\n",
        "$$\\tilde{C}_t = \\text{tanh}(W_C \\cdot [h_{t-1},x_t]~+~b_C)$$\n",
        "\n",
        "#### New Cell State\n",
        "This is where the candidate and old cell state are combined to create a new cell state.\n",
        "\n",
        "This is also where the output of the input gate $i_t$ is used to scaled the candidate cell state.\n",
        "- If $i_t$ is closer to $0.0$, then less information from the candidate cell state is retained\n",
        "- If $i_t$ is closer to $1.0$, then more information from the candidate cell state is retained.\n",
        "\n",
        "Finally, you form a linear combination of the cell state $C_{t-1}$ from the previous time step with the candidate cell state $\\tilde{C}_{t}$ from the current time step to form the model's new cell state $C_{t}$ of the model.\n",
        "\n",
        "The cell state $C_t$ will be passed into the next training step and used to update the cell  and hidden states for the next step.\n",
        "\n",
        "$$C_t = f_t*C_{t-1} + i_t*\\tilde{C}_t$$\n",
        "\n",
        "#### Output Gate\n",
        "This is where the actual output of the model is calculated.\n",
        "\n",
        "This neuron's job is to take the current input and make a prediction.\n",
        "\n",
        "$$o_t = \\sigma(W_o \\cdot [h_{t-1},x_t]~+~b_o)$$\n",
        "\n",
        "Next, the cell state is used to inform the final prediction.\n",
        "\n",
        "Recall that $o_t$ is the output of a sigmoid activation function, so its value is somewhere between 0 and 1.\n",
        "\n",
        "$o_t$ is used to scale $\\text{tanh}(C_t)$, which contains the current cell state. <br><br>\n",
        "The model's final output is\n",
        "$$h_t = o_t*\\text{tanh}(C_t)$$<br><br>\n",
        "\n",
        "Recall that the tanh activation maps numbers on the real line to numbers on the interval $[-1,1]$.<br>\n",
        "So the presence of the factor $\\text{tanh}(C_t)$ makes it possible to have positive **or  negative** values for the model's final output. <br>\n",
        "Sigmoids don't allow for the possibility of negative values, but tanh does.\n",
        "\n",
        "\n",
        "The article denotes the model's pre-scaled output as $o_t$ and the final output as $h_t$. <br>\n",
        "To be clear, $h_t$ is the model's final prediction, while  $o_t$ is an intermediate step. <br>\n",
        "We are familiar with the notation $y$ to denote a model's prediction instead of using $h$. <br>\n",
        "In the LSTM, they both mean the same thing - the model's final prediction.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgvXhCKV9uCB"
      },
      "source": [
        "_________\n",
        "\n",
        "##1.4 Applications of LSTMs\n",
        "\n",
        "So why are LSTMs cool?\n",
        "\n",
        "One compelling application is **language modeling** - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous blog post by Andrej Karpathy on this topic, worth reading.<br><br>\n",
        "\n",
        "A language model is simply a model that, given some text, predicts the most likely next word, or character.<br><br>\n",
        "Language models are essentially self-supervised -- the \"label\" or \"target\" for any text string is the next word (or character). <br>\n",
        "The data set already has the answers!\n",
        "\n",
        "Another interesting application of LSTMs is to text classification problems such as the sentiment classification problem we encountered in Unit 4, Sprint 1. Since LSTMs can learn contextual information about sequences of words, they can learn for example, that \"the service is not so great\" does not indicate a positive sentiment.\n",
        "\n",
        "For our purposes, we'll use TensorFlow and Keras to train LSTMs with text data.\n",
        "\n",
        "Resources:\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "\n",
        "Note: These days, [Transformer models](https://jalammar.github.io/illustrated-transformer/) surpass LSTMs for most Natural Language Processing tasks. Interestingly, people have recently adapted Transformers -- which were developed to solve text NLP problems --- to work with Computer Vision tasks, and their performance now rivals that of Convolutional Neural Networks (which we'll introduce in the next Module)! So if you're interested in learning about state of the art NLP models, your next step is Transformers. The [Free Hugging Face Transformers Course](https://huggingface.co/course/chapter1) is a great resource.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSytcRhoIM2A"
      },
      "source": [
        "# 2. Sentiment Classification with RNN/LSTM -- Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "_____________\n",
        "\n",
        "RNNs and LSTMs are great for modeling any kind of data that comes in ordered sequences. <br>\n",
        "There are an astonishing variety of sequences in our world, such as\n",
        "* words in a document\n",
        "* musical notes or chords in a song\n",
        "* sounds in an audio recording\n",
        "* daily stock prices\n",
        "* DNA base pairs\n",
        "* medical sensor time series data, such as voltage measurements in an EKG\n",
        "* etc.!<br>\n",
        "\n",
        "Can you think of other examples of sequence data?<br>\n",
        "\n",
        "To illustrate the power of Neural Networks for modeling sequences,<br>\n",
        "we'll focus on text data, and apply LSTMs to a simple sentiment classification task.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESoxKIrKkd_w"
      },
      "source": [
        "The [Internet Movie Database (IMDb)](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data) is a database of movie reviews in text format, along with the sentiment label(positive or negative), coresponding to each review.\n",
        "\n",
        "The movie review labels are binary:\n",
        "* $1 \\rightarrow$ the review expresses positive sentiment\n",
        "* $0 \\rightarrow$ the review expresses negative sentiment\n",
        "\n",
        "In this exercise, we will train a **sentiment classification** model that can predict from the text whether a movie review is \"thumbs-up\" or \"thumbs-down\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ti23G0gRe3kr"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt77ZoUo9uCD",
        "outputId": "22fd46e1-274a-4322-a903-be6d5ce0dff8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ]
        }
      ],
      "source": [
        "# load in dataset\n",
        "\n",
        "# maximum number of words in vocab\n",
        "max_features = 20000\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68GZlbBc3B_u"
      },
      "source": [
        "#### What does the IMDb data look like?\n",
        "The data is a list of reviews<br>\n",
        "Each review has been transformed to a list of numerical word encodings.<br>\n",
        "Each review may have a different number of words.<br>\n",
        "The number of words in our vocabulary is 20000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE0AUO-Lz5c6",
        "outputId": "275bb913-d26f-4c7b-8a20-82b2f37abb15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(25000,)\n",
            "<class 'list'>\n",
            "218\n",
            "145\n"
          ]
        }
      ],
      "source": [
        "print(type(x_train))\n",
        "print(x_train.shape)\n",
        "print(type(x_train[0]))\n",
        "print(len(x_train[0]))\n",
        "print(len(x_train[101]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one review has 218 words, the other has only 145 words"
      ],
      "metadata": {
        "id": "_x_EnZg7KVLY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train # each number represents one word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__arTfwAKEcG",
        "outputId": "b599f999-3c4a-4e2d-b61b-8739d585680d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 2]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfJW79LhngHr"
      },
      "source": [
        "Here are the first 80 word indexes for the (numerically encoded) first review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg1Ydf44DIVI",
        "outputId": "f00d6932-b7d7-4766-f8c8-370ba6a5eeae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x_train[0][:20] # first 20 words of the first review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73hiyEIh0rat"
      },
      "source": [
        "### What's are the lengths of the longest and shortest reviews in the training set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AmL0E8RhSVtL"
      },
      "outputs": [],
      "source": [
        "review_lengths = [len(x_train[i]) for i in range(len(x_train))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "O2EZdLW5SfAP",
        "outputId": "3266f1d0-33b4-42d9-ac75-9f86207eec47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.hist(review_lengths);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8tSZcLO0YcF",
        "outputId": "4bb12ffc-511f-439e-a1c3-b287d685f0b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "longest review is 2494 words\n",
            "shortest review is 11 words\n",
            "median review length 178.0 words\n"
          ]
        }
      ],
      "source": [
        "print(f'longest review is { np.max( review_lengths ) } words')\n",
        "print(f'shortest review is { np.min( review_lengths ) } words')\n",
        "print(f'median review length { np.median( review_lengths ) } words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcVrMKe1k5UI"
      },
      "source": [
        "### Truncating and padding the reviews to the same length\n",
        "We will standardize the length of our movie reviews to `maxlen = 80` words<br>\n",
        "The `pad_sequences` method from `tensorflow.keras.preprocessing.sequence` <br>\n",
        "provides a convenient way to accomplish this task\n",
        "* Reviews longer than `maxlen` will be **truncated** to the first `maxlen` words\n",
        "* Reviews shorter than `maxlen` will be **padded** with zeros at the beginning to increase their length to `maxlen`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0awRJCnIM2G",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fb23c1d7d1168a73",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "7732599e-7892-45fd-a3e2-d9a526af5622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pad or truncate sequences to a length of 80\n",
            "x_train shape:  (25000, 80)\n",
            "x_test shape:  (25000, 80)\n"
          ]
        }
      ],
      "source": [
        "maxlen = 80\n",
        "print(f'Pad or truncate sequences to a length of {maxlen}')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen,padding='pre',truncating = 'post')\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen, padding='pre',truncating = 'post')\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z78PHr5yFOeB"
      },
      "source": [
        "#### each review is truncated to the first 80 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrwFDoliEJMd",
        "outputId": "5acea7c4-9eea-49f2-f4bd-609b1ff4b14f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458,\n",
              "       4468,   66, 3941,    4,  173,   36,  256,    5,   25,  100,   43,\n",
              "        838,  112,   50,  670,    2,    9,   35,  480,  284,    5,  150,\n",
              "          4,  172,  112,  167,    2,  336,  385,   39,    4,  172, 4536,\n",
              "       1111,   17,  546,   38,   13,  447,    4,  192,   50,   16,    6,\n",
              "        147, 2025,   19,   14,   22,    4, 1920, 4613,  469,    4,   22,\n",
              "         71,   87,   12,   16,   43,  530,   38,   76,   15,   13, 1247,\n",
              "          4,   22,   17], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WeUXgQF2uht"
      },
      "source": [
        "#### The \"labels\" (or \"targets\") are classes -- 0 for negative reviews and 1 for positive reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1GFlKzck5zW",
        "outputId": "dd7f3068-aac2-4f79-cddb-9cbb8032810c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "np.unique(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZFdt-TB9uCF"
      },
      "source": [
        "### Build a LSTM language model with 1 hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD_NjHw-pcJS",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9c285c5d84213905",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "70122095-ce3a-40c8-a02c-dda5a9438f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2691713 (10.27 MB)\n",
            "Trainable params: 2691713 (10.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# build a 1 layer LSTM language model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# specify learning rate and optimizer\n",
        "opt = Adam(learning_rate=1.e-7)\n",
        "\n",
        "# as usual, we begin to build our model by instantiating a Sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "# adding an Embedding layer, works with NLP, input limited to 80 words/features, output is limited to multiplier of 2 as usual\n",
        "model.add(Embedding(input_dim=max_features, output_dim=128))\n",
        "\n",
        "# hidden layer 1, not a dense layer, but a LST layer\n",
        "model.add(LSTM(128, return_sequences=False)) # only include return sequences in the first set. Return sequences will be recursive throughout the values up until the very end\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1, activation='sigmoid')) # output value is 0 or 1\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 million params means 2 million connections"
      ],
      "metadata": {
        "id": "BncJdtcINnvR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJCNhjvB7LX4"
      },
      "source": [
        "Each numerical word index has dimension of 20,000 when one-hot-encoded.<br>\n",
        "The embedding layer has no bias, and produces a 128 dimensional embedding vector for each word. There are 20,000 inputs and 128 outputs, so the number of weights is 20,000 * 128 = 2,560,000 weights,<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dioHuVz-jObs"
      },
      "source": [
        "### Use a learning rate schedule [callback](https://) to find the best learning rate!\n",
        "Note that for this part, we don't need to pass the `test` data to the `fit` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63yPeX0VhXp-",
        "outputId": "117000c4-6cba-4e59-fd01-cdaaf437e0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 26s 29ms/step - loss: 0.6930 - accuracy: 0.5157 - lr: 1.0000e-05\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6212 - accuracy: 0.6452 - lr: 3.1623e-05\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4233 - accuracy: 0.8128 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3472 - accuracy: 0.8566 - lr: 3.1623e-04\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3409 - accuracy: 0.8572 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3676 - accuracy: 0.8448 - lr: 0.0032\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4247 - accuracy: 0.8094 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4493 - accuracy: 0.7992 - lr: 0.0316\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8951 - accuracy: 0.5274 - lr: 0.1000\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3843 - accuracy: 0.5011 - lr: 0.3162\n",
            "CPU times: user 1min 33s, sys: 4.76 s, total: 1min 38s\n",
            "Wall time: 2min 23s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# about 5 or 6 sec per epoch on Colab GPU\n",
        "# specify batch size\n",
        "batch_size = 32\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "     lambda epoch: 1e-5 * 10**(epoch/2))\n",
        "results_one_layer = model.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=10, callbacks=[lr_schedule])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuU0hmobsfUX"
      },
      "source": [
        "Backing off by by a factor of 10 from where the loss surface is unstable, we choose 1.e-4 as the best learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "yVpTOFgAiXBN",
        "outputId": "a9ac0de8-78ff-409c-c06c-676138489b82"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.semilogx(results_one_layer.history[\"lr\"], results_one_layer.history[\"loss\"])\n",
        "plt.axis([1e-5, 1e-1, 0, 1])\n",
        "plt.xlabel('learning rate')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kREzYX8sL7G"
      },
      "source": [
        "Build the LSTM with the learning rate set to 1.e-4 (that's the only difference from previous model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUGjJpuxjxNY",
        "outputId": "3c41a14b-0d00-4c39-f397-951800fc8a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2691713 (10.27 MB)\n",
            "Trainable params: 2691713 (10.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# build a 1 layer LSTM language model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# specify learning rate and optimizer\n",
        "opt = Adam(learning_rate=1.e-4)\n",
        "\n",
        "###BEING SOLUTION\n",
        "# as usual, we begin to build our model by instantiating a Sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "# we are explicitly declaring the dimension of the input layer here by adding an Embedding object\n",
        "# this is for the one-hot encoding of the numerical indices\n",
        "model.add(Embedding(max_features, 128))\n",
        "\n",
        "# hidden layer 1\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrY7mat_sZaF"
      },
      "source": [
        "Fit the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQAKkBGd9uCF",
        "outputId": "df847174-20c5-493c-ec3a-0ca3a7dad358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 8s 134ms/step - loss: 0.6926 - accuracy: 0.5348 - val_loss: 0.6919 - val_accuracy: 0.5633\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 5s 109ms/step - loss: 0.6717 - accuracy: 0.6390 - val_loss: 0.6029 - val_accuracy: 0.6708\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 4s 90ms/step - loss: 0.5220 - accuracy: 0.7434 - val_loss: 0.5086 - val_accuracy: 0.7518\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 4s 80ms/step - loss: 0.4094 - accuracy: 0.8209 - val_loss: 0.4894 - val_accuracy: 0.7690\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.3319 - accuracy: 0.8670 - val_loss: 0.4877 - val_accuracy: 0.7773\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 3s 65ms/step - loss: 0.2760 - accuracy: 0.8948 - val_loss: 0.4694 - val_accuracy: 0.7844\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 0.2341 - accuracy: 0.9143 - val_loss: 0.5497 - val_accuracy: 0.7739\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 3s 59ms/step - loss: 0.1976 - accuracy: 0.9292 - val_loss: 0.5766 - val_accuracy: 0.7652\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 3s 64ms/step - loss: 0.1673 - accuracy: 0.9418 - val_loss: 0.6707 - val_accuracy: 0.7570\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 0.1418 - accuracy: 0.9546 - val_loss: 0.7771 - val_accuracy: 0.7536\n",
            "CPU times: user 36 s, sys: 976 ms, total: 37 s\n",
            "Wall time: 39.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# number of epochs\n",
        "n_epochs = 10\n",
        "batch_size = 512\n",
        "\n",
        "results_one_layer = model.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=n_epochs,\n",
        "                      validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZQj7QXr9uCG"
      },
      "source": [
        "### Build a 1 hidden layer Bidirectional LSTM language model\n",
        "\n",
        "A Bidirectional LSTM, or biLSTM, is a sequence processing model that consists of two LSTMs: **one taking the input in a forward direction**, and **the other in a backwards direction**. BiLSTMs effectively increase the amount of information available to the network, improving the context available to the algorithm (e.g. knowing what words immediately follow and precede a word in a sentence).\n",
        "\n",
        "![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKyGb4TzIM2O",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-706b7be103484984",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "546564e0-abde-4a7b-addb-f8bfb27a1d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 256)               263168    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2823425 (10.77 MB)\n",
            "Trainable params: 2823425 (10.77 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# build a 1 layer Bidirectional LSTM language model\n",
        "# EXACTLY THE SAME EXCEPT IN THE HIDDEN LAYER IT'S BIDRECTIONAL.\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "# as usual, we begin to build our model by instantiating a Sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# input layer 1\n",
        "# we are explicitly declaring the input layer here by adding an Embedding object\n",
        "model.add(Embedding(max_features, 128))\n",
        "\n",
        "# hidden layer 1\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E-lL5kB9uCH",
        "outputId": "d089bd61-812c-463e-b7fe-b5dda3b21394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 11s 162ms/step - loss: 0.5428 - accuracy: 0.7093 - val_loss: 0.4435 - val_accuracy: 0.7969\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 5s 100ms/step - loss: 0.3014 - accuracy: 0.8763 - val_loss: 0.4614 - val_accuracy: 0.7958\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 6s 115ms/step - loss: 0.2076 - accuracy: 0.9214 - val_loss: 0.5368 - val_accuracy: 0.7741\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 5s 99ms/step - loss: 0.1472 - accuracy: 0.9475 - val_loss: 0.6756 - val_accuracy: 0.7735\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 4s 83ms/step - loss: 0.0969 - accuracy: 0.9660 - val_loss: 0.7598 - val_accuracy: 0.7591\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 4s 88ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.9091 - val_accuracy: 0.7648\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 3s 70ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 1.2443 - val_accuracy: 0.7447\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 3s 67ms/step - loss: 0.0423 - accuracy: 0.9862 - val_loss: 1.2299 - val_accuracy: 0.7534\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 4s 86ms/step - loss: 0.0439 - accuracy: 0.9847 - val_loss: 1.0729 - val_accuracy: 0.7594\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 1.3459 - val_accuracy: 0.7504\n",
            "CPU times: user 43.7 s, sys: 1.31 s, total: 45 s\n",
            "Wall time: 1min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "results_biLSTM = model.fit(x_train, y_train,\n",
        "                      batch_size=512,\n",
        "                      epochs=n_epochs,\n",
        "                      validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "RZx3Zs7tIM2Q",
        "outputId": "4aceabfa-e4b5-46b2-94c4-3e3f1a4594c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot training & validation loss values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_list = np.arange(1,n_epochs+1)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.grid()\n",
        "plt.xticks(epoch_list)\n",
        "# results for 1-layer lstm model\n",
        "plt.plot(epoch_list, results_one_layer.history['loss'], \"--\", label=\"1 layer LSTM Train\")\n",
        "plt.plot(epoch_list, results_one_layer.history['val_loss'], \"--\", label = \"1 layer LSTM Test\")\n",
        "\n",
        "# results for bi-lstm model\n",
        "plt.plot(epoch_list, results_biLSTM.history['loss'], label=\"1 layer biLSTM Train \")\n",
        "plt.plot(epoch_list, results_biLSTM.history['val_loss'], label = \"1 layer biLSTM Test\")\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Ps3CauIM2S"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pETWPIe362y"
      },
      "source": [
        "--------\n",
        "# 3. LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeG4BPnJ9uCI"
      },
      "source": [
        "Using sequential models to generate text data is an application of recursive deep learning models. A couple of applications are [**chat bots**](https://hackernoon.com/deep-learning-chatbot-everything-you-need-to-know-r11jm30bc) and language translators such as [**google translate**](https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html).\n",
        "\n",
        "In order to properly build a chat bot or translater you need to use multiple lstm models in an encoder & decoder framework known as a [**sequence 2 sequence model**](https://keras.io/examples/nlp/lstm_seq2seq/) .\n",
        "\n",
        "\n",
        "![](https://jeddy92.github.io/images/ts_intro/seq2seq_lang.png)\n",
        "\n",
        "Also, now a days, using a standard LSTM isn't enough. You also have to use a version of lstm seq2seq models known as [**transformers**](https://towardsdatascience.com/transformers-141e32e69591). Transformers give seq2seq models the capacity to pay attention to specific portions of the input sequence, the most relevent portion in order to make a prediction. Yes, that's right, humanity has figured out how to convert attention into an algorithm. Next stop, self-awareness!\n",
        "\n",
        "The above mentions of sequence 2 sequence models and transformers are for a larger contextual understanding of the landscape of language models and how LSTMs fit into this landscape. Although **we will cover the encoder/decoder framework in a future lesson, transformers are outside the scope of Unit 4**. However, once you learn about LSTMs and encoder/decoder frameworks, you will have all necessary information to then go on and learn about transformers on your own. At that point, the only really new bit you'll be learning is the [**attention mechanism**](https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f).\n",
        "\n",
        "\n",
        "As a first pass at text generation, we'll stick to standard LSTM models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK-GrUGvIM2T"
      },
      "source": [
        "-----\n",
        "# Text Generation using LSTMs\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. <br>\n",
        "For this exercise, we'll use BBC news articles from the [newspaper](https://github.com/codelucas/newspaper/)  database.\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q64qHEYIIM2U",
        "outputId": "0f083029-5669-48a7-d0a6-aa75c16f2d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-14 01:29:37--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6666 (6.5K) [text/plain]\n",
            "Saving to: ‘data_cleaning_toolkit_class.py’\n",
            "\n",
            "\r          data_clea   0%[                    ]       0  --.-KB/s               \rdata_cleaning_toolk 100%[===================>]   6.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-14 01:29:37 (86.2 MB/s) - ‘data_cleaning_toolkit_class.py’ saved [6666/6666]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# import a custom text data preparation class\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py\n",
        "from data_cleaning_toolkit_class import data_cleaning_toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MxcXsdsSIM2W",
        "outputId": "8aa2145f-56d3-4456-e50f-e517a7e205b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "10   Russian President Vladimir Putin speaks at a s...\n",
              "100  “The Queen’s Speech” is designed to acknowledg...\n",
              "101  Like an aging rock star, the president is now ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c67d6a0-4c46-4760-a671-ea67068bc728\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>“The Queen’s Speech” is designed to acknowledg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Like an aging rock star, the president is now ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c67d6a0-4c46-4760-a671-ea67068bc728')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c67d6a0-4c46-4760-a671-ea67068bc728 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c67d6a0-4c46-4760-a671-ea67068bc728');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8dc37989-fe83-4887-8351-578d2f6b79de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8dc37989-fe83-4887-8351-578d2f6b79de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8dc37989-fe83-4887-8351-578d2f6b79de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 136,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 126,\n        \"samples\": [\n          \"\\u201cPhillips may want us to think he\\u2019s giving us a movie all about the emptiness of our culture \\u2014 but really, he\\u2019s offering a prime example of it,\\u201d Zacharek wrote. Phillips, who is best known for directing raunchy, comedic bromances like \\u201cThe Hangover\\u201d franchise and \\u201cStarsky & Hutch,\\u201d presents Fleck as a man beset by misfortunes, from unrequited love to Gotham City budget cuts that block access to his psychiatric meds. In \\u201cJoker,\\u201d Zacharek says Phillips wants viewers to pity Fleck because \\u201che just hasn\\u2019t had enough love,\\u201d but what he\\u2019s done is create a protagonist who could become the \\u201cpatron saint of incels.\\u201d\",\n          \"\\u201cAs you can see, my tweets are pretty passionate,\\u201d Spanbauer, who uses a different name online, said in an interview, adding that she doesn\\u2019t specifically wish anyone physical harm. \\u201cIt hits very close to home for me. What the Democrats are doing to our president, to the office and to the people of this country is disgusting.\\u201d\\n\\nAD\\n\\nAs Trump and his allies have aimed increasingly caustic language at Schiff in recent days, the attacks have been echoed by supporters on social media who often take the message a step further \\u2014 invoking physical violence against one of the most prominent Democrats overseeing the inquiry that now threatens Trump\\u2019s presidency.\\n\\nAD\\n\\nThe chain reaction represents a new test of the power of weaponized language to inspire physical violence. Over the summer, Trump faced criticism for employing anti-immigrant rhetoric that was parroted by the man accused of fatally shooting22 people at a Walmart in El Paso in August. In the fall of 2018, an avid Trump supporter mailed pipe bombs to prominent Democrats.\\n\\nWhat many of the violent, anti-Schiff messages have in common is the inspiration they appear to draw from the president\\u2019s words, or from the words of his associates and allies in Congress and conservative media.\\n\\nAD\\n\\nA tweet from Rudolph W. Giuliani, Trump\\u2019s personal lawyer, arguing that Schiff should be \\u201csuspended\\u201d was reposted by a user with nearly 50,000 followers who envisioned the congressman\\u2019s public hanging in a football stadium. The post remained live as of Sunday.\\n\\nAD\\n\\nA tweet from Rep. Steve Scalise (R-La.) describing Schiff as a \\u201cproven liar\\u201d who should be \\u201cheld accountable\\u201d was reposted by a user with thousands of followers and a longing for the \\u201cgood old days when traitors like Schiff would be hanged by the neck until dead.\\u201d It also remained live.\\n\\nA tweet from Matt Schlapp, the chairman of the American Conservative Union, was reposted by a user with only a small following who envisioned Schiff sitting in front of a firing squad. The post was taken down.\\n\\nAD\\n\\nNeither Giuliani nor Schlapp responded to requests for comment. The White House also did not respond. But a spokeswoman for Scalise defended his rhetoric, saying the Louisiana congressman \\u2014 among the victims of a shooting at congressional baseball practice in 2017 \\u2014 knows firsthand the consequences of extreme language.\\n\\nAD\\n\\n\\u201cAs someone who was targeted by a leftist motivated by violent rhetoric towards Republicans, Whip Scalise is well aware of the dangers of that kind of rhetoric,\\u201d said Lauren Fine, the spokeswoman. \\u201cAdam Schiff has a detailed history of using irresponsible, false and accusatory rhetoric throughout Trump\\u2019s presidency, which is what this tweet simply documents in Schiff\\u2019s own words.\\u201d\\n\\nA spokeswoman for Schiff said the security of the congressman and his staff is \\u201calways a top priority,\\u201d declining to go into more detail about specific threats. A spokeswoman for the Capitol Police said authorities consult with individual congressional offices on \\u201csecurity-related matters\\u201d but declined to discuss precautions around the high-stakes impeachment inquiry.\\n\\nAD\\n\\nThe most graphic and specific threats against Schiff were quickly scrubbed from Twitter, whose policies prohibit threats of violence as well as the \\u201cglorification of violence.\\u201d At least one additional tweet was removed after it was flagged for the company by The Washington Post.\\n\\nAD\\n\\nBut much of the vitriol remained. And the violent language also reached beyond Twitter, echoing on platforms such as Facebook and 4chan, a sprawling online agora where hate speech and violent threats are routine. A link to an article about Trump\\u2019s accusation of treason against Schiff appearing on a Facebook page called \\u201cUSA Patriots for Donald Trump,\\u201d which boasts nearly 2 million followers, drew a slew of comments about the congressman being hanged.\\n\\nThe heightened focus on Schiff reflects the extent to which the former prosecutor and longtime Los Angeles-area congressman has become the b\\u00eate noire of the Trump movement since becoming the de facto head of the investigation of Trump\\u2019s efforts to enlist Ukraine\\u2019s help in damaging former vice president Joe Biden, a Democratic presidential candidate. Schiff has come under criticism from Trump and congressional Republicans as they seek to delegitimize the inquiry by portraying it as tainted by political bias. The nub of the criticism of Schiff is that he spoofed the president\\u2019s call with his Ukrainian counterpart during a congressional hearing and that he made misleading statements about the nature of his prior knowledge of the initial whistleblower complaint.\\n\\nAD\\n\\nAnalysts say the pattern resulting in the violent rhetoric targeting Schiff makes evident the radicalizing effect of social media, which Trump uses to incite his followers against his perceived enemies.\\n\\nAD\\n\\n\\u201cWhole online communities are forming around these sentiments, like MAGA,\\u201d said Amarnath Amarasingam, an expert on political violence and an assistant professor at Queen\\u2019s University in Kingston, Ontario, referring to Trump\\u2019s campaign slogan. \\u201cThe online social movement of Trump supporters is very real, and a cohort of that movement has come out and said they\\u2019re ready to take up arms when needed. This is something a few of us have been worried about for some time.\\u201d\\n\\nThe web is where the president\\u2019s hold over his supporters comes into sharpest focus, the extremism researcher said. On Twitter, his opinions \\u2014 and his disparaging views of other politicians \\u2014 are received uncritically, Amarasingam added, giving Trump enormous power over his followers and \\u201csetting the stage for violence.\\u201d\\n\\nAD\\n\\nSome Trump critics have also used sharp language online, including accusing the president of treason and noting the maximum penalty: death.\\n\\nAD\\n\\n\\u201cIt\\u2019s treason, pure and simple, and the penalty for treason under the U.S. code is death,\\u201d former Massachusetts governor Bill Weld, who is challenging Trump for the Republican nomination, said last month on MSNBC of Trump\\u2019s phone call with the Ukrainian president. The comment was tweeted by a reporter, and retweeted by Rep. Sheila Jackson Lee (D-Tex.).\\n\\nFormer congresswoman Gabrielle Giffords (D-Ariz,), who was shot in the head in an assassination attempt in 2011, said the responsibility of politicians to \\u201cseek the truth\\u201d and \\u201ctreat their fellow Americans with respect\\u201d was heightened \\u201cin charged times.\\u201d\\n\\nAD\\n\\nGlobally, public figures are not living up to that responsibility, said Jacob Davey, senior research manager at the Institute for Strategic Dialogue, a U.K.-based think tank dedicated to countering extremism and polarization. The result is increasing online radicalization \\u2014 not just in the Middle East and Northern Africa, long the focus of extremism research, but also in the heart of the West.\\n\\nAD\\n\\nSocial media, he said, \\u201chas undoubtedly made engaging in such behavior easier than ever before, with users escaping the legal and social repercussions of their actions.\\u201d\\n\\nTrump\\u2019s ability to craft an alternate universe for his supporters, in which he is the victim of lawless Democrats, rests on an unregulated online ecosystem, where fake news travels faster than the truth.\\n\\nAD\\n\\nSpanbauer, who became dissatisfied with Obama during his first term and voted for his Republican challenger in 2012, said she gets most of her news on Twitter and YouTube. Among those she trusts are Fox News Channel host Sean Hannity (\\u201cof course\\u201d) and Tom Fitton, the president of Judicial Watch (\\u201cthank God for Tom Fitton\\u201d).\\n\\nTrump, she said, channels her anger at Washington, while speaking directly to his supporters. \\u201cIt\\u2019s wonderful, really, what Trump does on Twitter,\\u201d said Spanbauer, who has worked in retail and sales and struggles, along with her husband, to stay above the federal poverty line.\\n\\nAD\\n\\nBeneath her verdict on Schiff\\u2019s fate, which she acknowledges was hyperbolic, lies a firm conviction that the congressman is guilty of treason.\\n\\nThe impeachment inquiry, she said, is a \\u201csupreme insult to our country.\\u201d Those leading it \\u201cshould be held accountable to the length of the law,\\u201d she added. \\u201cIt\\u2019s treason. It\\u2019s treason.\\u201d\",\n          \"At the center of the bloody rampage unfolding in the \\u201cChurch of Fake News\\u201d is a man dressed in a dark pinstripe suit. President Trump\\u2019s head is superimposed on his body.\\n\\nThe graphic images are from a fake video that was shown during a pro-Trump conference last week at the president\\u2019s hotel and golf resort near Miami, according to the New York Times, which first reported on the video\\u2019s existence Sunday night. The clip has since drawn intense backlash from journalists and public figures who have decried it as \\u201cvile and horrific\\u201d and an \\u201cincitement of violence.\\u201d Many of the news organizations and people featured in the video have been publicly targeted by Trump, who is frequently criticized for his inflammatory remarks and anti-media rhetoric.\\n\\nAD\\n\\nAD\\n\\n\\u201cThis video isn\\u2019t funny,\\u201d tweeted former Texas congressman and Democratic presidential candidate Beto O\\u2019Rourke. \\u201cIt will get people killed.\\u201d\\n\\nAt a conference of Trump supporters, they played a video of our president murdering journalists in a church. Last year, a Trump supporter sent bombs to CNN\\u2014and a shooter entered a church yesterday. This video isn\\u2019t funny. It will get people killed. https://t.co/XWtq1z38Kc \\u2014 Beto O'Rourke (@BetoORourke) October 14, 2019\\n\\nOn Monday, White House press secretary Stephanie Grisham tweeted that Trump had not yet seen the clip, \\u201cbut based upon everything he has heard, he strongly condemns this video.\\u201d\\n\\nRe: the video played over the weekend: The @POTUS @realDonaldTrump has not yet seen the video, he will see it shortly, but based upon everything he has heard, he strongly condemns this video. \\u2014 Stephanie Grisham (@PressSec) October 14, 2019\\n\\nThe video, adapted from the scene of a church massacre in the 2014 film \\u201cKingsman: The Secret Service,\\u201d appeared to be shared to YouTube in 2018 on a channel that posts similar pro-Trump content and has been linked to a meme-maker associated with a website called MemeWorld. The site\\u2019s creator, a user known by his Internet handle, Carpe Donktum, scored an Oval Office meeting in July with Trump, who reportedly welcomed him as a \\u201cgenius.\\u201d\\n\\nAD\\n\\nCarpe Donktum confirmed in a Twitter message Sunday to The Washington Post that \\u201cThe creator of the video is, and will remain a contributor to my site MemeWorld.\\u201d Carpe Donktum declined to identify the video\\u2019s creator citing concerns that the person may face online or in-person harassment.\\n\\nAD\\n\\nAlex Phillips, organizer of the American Priority Festival and Conference, told the Times the video was played at one point during the three-day event that began Thursday as part of a \\u201cmeme exhibit.\\u201d The violent parody was included in a meme compilation that also featured Trump\\u2019s 2020 reelection campaign logo, according to the Times.\\n\\n\\u201cIt has come to our attention that an unauthorized video was shown in a side room at #AMPFest19,\\u201d a statement posted to the conference\\u2019s website said. \\u201cThis video was not approved, seen, or sanctioned by the #AMPFest19 organizers.\\u201d\\n\\nAD\\n\\nThe statement went on to note that the conference \\u201calways has and always will condemn political violence.\\u201d\\n\\nPhillips told the Times the \\u201cmatter is under review.\\u201d\\n\\nIn a statement to The Post early Monday, the Trump campaign distanced itself from the video.\\n\\nAD\\n\\n\\u201cThat video was not produced by the campaign, and we do not condone violence,\\u201d campaign spokesman Tim Murtaugh said.\\n\\nPeople close to Trump, such as former White House press secretary Sarah Sanders and Donald Trump Jr., were also scheduled to speak at the conference and told the Times they were not aware of the edited footage.\\n\\nThe video\\u2019s massacre scene opens with the Trump figure walking down the center aisle of a packed church. More than a dozen of the parishioners\\u2019 faces are covered by the logos of major media organizations, ranging from PBS to The Washington Post. Rising out of the pews when Trump passes them, some of the churchgoers appear to be yelling at the president, whose face contorts into a scowl.\\n\\nAD\\n\\nAs the shouting intensifies, Trump abruptly stops walking and turns to face the angry mob. He pulls out a black gun from his jacket\\u2019s inside pocket and shoots a person edited to represent late actor Peter Fonda, who was a vocal critic of the president, in the head from point-blank range.\\n\\nAD\\n\\nThen, chaos ensues.\\n\\nTrump takes down Bloomberg, Vox and \\u201cFake News\\u201d in quick succession before shooting Politico. At one point, he grabs someone who represents the Black Lives Matter movement in a chokehold and shoots that person in the head.\\n\\nAfter shooting MSNBC host Rachel Maddow, Vice News, Rep. Adam B. Schiff (D-Calif.) and Slate, Trump tries to shoot late senator John McCain (R-Ariz.), but he is out of bullets. Instead, he uses his gun to deliver a vicious blow to the back of McCain\\u2019s neck.\\n\\nAD\\n\\nThe attack continues with Trump going after some of his most prominent detractors. He stabs actress and comedian Rosie O\\u2019Donnell and repeatedly punches Rep. Maxine Waters (D-Calif.). He goes on to shoot MSNBC\\u2019s Mika Brzezinski and Sen. Mitt Romney (R-Utah), and later assaults Hillary Clinton with a gun.\\n\\nAD\\n\\nThe video comes to a dramatic end when Trump jams a sharp wooden stake through the head of a person whose face is a CNN logo. A now-grinning Trump appears to survey the carnage as DJ Khaled\\u2019s song, \\u201cAll I Do Is Win,\\u201d plays in the background. A pair of pixelated black sunglasses are lowered onto Trump\\u2019s face.\\n\\nBy late Sunday, \\u201cKingsman\\u201d was trending on Twitter with many expressing outrage at the video and calling on Trump to condemn it.\\n\\nAD\\n\\n\\u201cSadly, this is not the first time that supporters of the President have promoted violence against the media in a video they apparently find entertaining \\u2014 but it is by far and away the worst,\\u201d CNN said in a statement shared on Twitter.\\n\\nThe images in the recent video are \\u201cvile and horrific,\\u201d CNN said, adding, \\u201cThe President and his family, the White House, and the Trump campaign need to denounce it immediately in the strongest possible terms. Anything less equates to a tacit endorsement of violence and should not be tolerated by anyone.\\u201d\\n\\nAD\\n\\nWhite House Correspondents\\u2019 Association President Jonathan Karl of ABC News also denounced the video, noting that Trump has been warned that \\u201chis rhetoric could incite violence.\\u201d\\n\\nAD\\n\\nWHCA Statement on video depicting President Trump murdering journalists. pic.twitter.com/52lHFaQjU2 \\u2014 WHCA (@whca) October 14, 2019\\n\\nKarl\\u2019s statement was supported early Monday by Cindy McCain, who tweeted that the images in the video of the president killing the media and her late husband \\u201cviolate every norm our society expects from its leaders.\\u201d\\n\\nTrump has made it a habit to publicly lambaste the media, individual journalists and his critics, leading to heightened concerns about safety. In 2017, the president was widely criticized for tweeting a similarly edited video that showed him body slamming a person with a CNN logo for a face during a pro wrestling match. Earlier this year, Cesar Sayoc, a devoted Trump supporter, was sentenced to 20 years in prison for mailing 13 pipe bombs to high-profile Democrats, several of whom were featured in the recent video, and CNN.\\n\\nAD\\n\\nOn Sunday, journalists and political commentators suggested the church video is further evidence that Trump\\u2019s words have influenced his supporters.\\n\\nAD\\n\\n\\u201cThis is an incitement to violence that didn\\u2019t just come from the dark corners of the Internet \\u2014 it was shown at a pro-Trump conference at one of his resorts,\\u201d tweeted Politico reporter Andrew Desiderio. \\u201cI\\u2019m speechless.\\u201d\\n\\nCNN commentator Ana Navarro-C\\u00e1rdenas wrote, \\u201cTrump has legitimized hate.\\u201d\\n\\nEnablers choose to deny it, but this is the kind of crap Trump peddles & inspires. His constant attacks on the free press, the chants against journalists at his rallies, his retweeting of similar memes...Trump has legitimized hate. #Deplorable https://t.co/vqk0w9Kd9n \\u2014 Ana Navarro-C\\u00e1rdenas (@ananavarro) October 14, 2019\\n\\nA year ago this month a man mailed bombs to journalists, Democratic leaders, and critics of Donald Trump. He was responding to Trump\\u2019s violent rhetoric. Now we\\u2019ve got videos of mass slaughters.\\n\\n\\n\\nThere\\u2019s literally no telling what kind of dangers they could unleash. \\u2014 Jared Yates Sexton (@JYSexton) October 14, 2019\\n\\nCall someone an \\\"enemy\\\" over and over again, and you have some responsibility for what happens to them.\\n\\n\\n\\nTrump is responsible for a climate that is so hateful, so hostile toward journalists that it spawns videos like this one. https://t.co/mn1W8W69M1 \\u2014 Brian Stelter (@brianstelter) October 14, 2019\\n\\nActress Kathy Griffin, who drew widespread backlash in 2017 after sharing a photo of herself holding a prop of Trump\\u2019s bloody severed head, echoed concerns about the clip\\u2019s impact. Griffin, shown in the video getting beheaded by the ax-wielding CNN person, tweeted that it \\u201cisn\\u2019t a joke\\u201d to Trump supporters, adding, \\u201cAnd it will not be taken as such.\\\"\\n\\nBut some pushed back against criticisms of the video, pointing out that the film\\u2019s original scene, which depicted a church full of \\u201cconservative Christians\\u201d being killed, did not draw the same level of outcry. According to an NPR review of the movie, the fictional congregation was \\u201cclearly modeled on the Westboro Baptist Church,\\u201d a Kansas-based organization known for its anti-gay views.\\n\\nAD\\n\\nStill, others wondered if the video represents, as one person put it, \\u201cthe country hitting rock bottom.\\u201d\\n\\n\\u201cWe have enough mass shootings, we have enough journalists killed in the line of duty around the world \\u2014 we don\\u2019t need to glorify a massacre of people who challenge Trump,\\u201d Times columnist Nicholas Kristof tweeted. \\u201cThis demonization of opponents and fetishization of violence is unconscionable.\\u201d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# load text data (articles)\n",
        "df = pd.read_json('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/wp_articles.json')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHOYH4CjWJRk"
      },
      "source": [
        "How many articles are in the database?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjXfqs1IPyoS",
        "outputId": "81e75317-fad2-4b9d-f041-8cd8bf17ff13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHz9fsXBXz4a"
      },
      "source": [
        "The [`data_cleaning_toolkit()`](https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py)<br>\n",
        "* Cleans the documents<br>\n",
        "* Chops them into text strings of length `max_len` (default = 20) characters<br>\n",
        "* Creates the X and y split with the appropriate shapes to use with an RNN or LSTM model<br><br>\n",
        "For this  problem: <br>\n",
        "X is the input data -- the corpus of news articles, arranged in 20 character sequences, for which we want to predict the next character. <br>\n",
        "The dimension of X is [n_sequences, sequence_length, n_vocab]<br>\n",
        "The rows correspond to 20 character text sequences<br><br>\n",
        "In order to have more training data, each sequence starts at a position shifted forward by an integer step, compared to the previous text string<br><br>\n",
        "y is the \"next\" character that we are trying to predict for each sequence. y is a one-hot-encoded, of dimension [n_sequences, n_vocab]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BOvbQddF3Tj-",
        "outputId": "c403ff03-c690-4fa1-887d-a2d3b17381ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "10   Russian President Vladimir Putin speaks at a s...\n",
              "100  “The Queen’s Speech” is designed to acknowledg...\n",
              "101  Like an aging rock star, the president is now ...\n",
              "..                                                 ...\n",
              "95   Approaching its 150th birthday Nov. 6, college...\n",
              "96   A few factors contributed to this placid accep...\n",
              "97   On Thursday, four days after he set out on his...\n",
              "98   A South Carolina sheriff candidate is fessing ...\n",
              "99   The threat to hard-won women’s rights in Rojav...\n",
              "\n",
              "[136 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7036650-f4d1-46eb-8235-7b55416ee1b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>“The Queen’s Speech” is designed to acknowledg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Like an aging rock star, the president is now ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Approaching its 150th birthday Nov. 6, college...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>A few factors contributed to this placid accep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>On Thursday, four days after he set out on his...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>A South Carolina sheriff candidate is fessing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>The threat to hard-won women’s rights in Rojav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7036650-f4d1-46eb-8235-7b55416ee1b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7036650-f4d1-46eb-8235-7b55416ee1b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7036650-f4d1-46eb-8235-7b55416ee1b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c87e37b0-bbde-4225-a78a-35b7878adbbf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c87e37b0-bbde-4225-a78a-35b7878adbbf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c87e37b0-bbde-4225-a78a-35b7878adbbf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_06cce15e-00f4-4ee4-8a91-dcec5c4e5d32\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_06cce15e-00f4-4ee4-8a91-dcec5c4e5d32 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 136,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 126,\n        \"samples\": [\n          \"\\u201cPhillips may want us to think he\\u2019s giving us a movie all about the emptiness of our culture \\u2014 but really, he\\u2019s offering a prime example of it,\\u201d Zacharek wrote. Phillips, who is best known for directing raunchy, comedic bromances like \\u201cThe Hangover\\u201d franchise and \\u201cStarsky & Hutch,\\u201d presents Fleck as a man beset by misfortunes, from unrequited love to Gotham City budget cuts that block access to his psychiatric meds. In \\u201cJoker,\\u201d Zacharek says Phillips wants viewers to pity Fleck because \\u201che just hasn\\u2019t had enough love,\\u201d but what he\\u2019s done is create a protagonist who could become the \\u201cpatron saint of incels.\\u201d\",\n          \"\\u201cAs you can see, my tweets are pretty passionate,\\u201d Spanbauer, who uses a different name online, said in an interview, adding that she doesn\\u2019t specifically wish anyone physical harm. \\u201cIt hits very close to home for me. What the Democrats are doing to our president, to the office and to the people of this country is disgusting.\\u201d\\n\\nAD\\n\\nAs Trump and his allies have aimed increasingly caustic language at Schiff in recent days, the attacks have been echoed by supporters on social media who often take the message a step further \\u2014 invoking physical violence against one of the most prominent Democrats overseeing the inquiry that now threatens Trump\\u2019s presidency.\\n\\nAD\\n\\nThe chain reaction represents a new test of the power of weaponized language to inspire physical violence. Over the summer, Trump faced criticism for employing anti-immigrant rhetoric that was parroted by the man accused of fatally shooting22 people at a Walmart in El Paso in August. In the fall of 2018, an avid Trump supporter mailed pipe bombs to prominent Democrats.\\n\\nWhat many of the violent, anti-Schiff messages have in common is the inspiration they appear to draw from the president\\u2019s words, or from the words of his associates and allies in Congress and conservative media.\\n\\nAD\\n\\nA tweet from Rudolph W. Giuliani, Trump\\u2019s personal lawyer, arguing that Schiff should be \\u201csuspended\\u201d was reposted by a user with nearly 50,000 followers who envisioned the congressman\\u2019s public hanging in a football stadium. The post remained live as of Sunday.\\n\\nAD\\n\\nA tweet from Rep. Steve Scalise (R-La.) describing Schiff as a \\u201cproven liar\\u201d who should be \\u201cheld accountable\\u201d was reposted by a user with thousands of followers and a longing for the \\u201cgood old days when traitors like Schiff would be hanged by the neck until dead.\\u201d It also remained live.\\n\\nA tweet from Matt Schlapp, the chairman of the American Conservative Union, was reposted by a user with only a small following who envisioned Schiff sitting in front of a firing squad. The post was taken down.\\n\\nAD\\n\\nNeither Giuliani nor Schlapp responded to requests for comment. The White House also did not respond. But a spokeswoman for Scalise defended his rhetoric, saying the Louisiana congressman \\u2014 among the victims of a shooting at congressional baseball practice in 2017 \\u2014 knows firsthand the consequences of extreme language.\\n\\nAD\\n\\n\\u201cAs someone who was targeted by a leftist motivated by violent rhetoric towards Republicans, Whip Scalise is well aware of the dangers of that kind of rhetoric,\\u201d said Lauren Fine, the spokeswoman. \\u201cAdam Schiff has a detailed history of using irresponsible, false and accusatory rhetoric throughout Trump\\u2019s presidency, which is what this tweet simply documents in Schiff\\u2019s own words.\\u201d\\n\\nA spokeswoman for Schiff said the security of the congressman and his staff is \\u201calways a top priority,\\u201d declining to go into more detail about specific threats. A spokeswoman for the Capitol Police said authorities consult with individual congressional offices on \\u201csecurity-related matters\\u201d but declined to discuss precautions around the high-stakes impeachment inquiry.\\n\\nAD\\n\\nThe most graphic and specific threats against Schiff were quickly scrubbed from Twitter, whose policies prohibit threats of violence as well as the \\u201cglorification of violence.\\u201d At least one additional tweet was removed after it was flagged for the company by The Washington Post.\\n\\nAD\\n\\nBut much of the vitriol remained. And the violent language also reached beyond Twitter, echoing on platforms such as Facebook and 4chan, a sprawling online agora where hate speech and violent threats are routine. A link to an article about Trump\\u2019s accusation of treason against Schiff appearing on a Facebook page called \\u201cUSA Patriots for Donald Trump,\\u201d which boasts nearly 2 million followers, drew a slew of comments about the congressman being hanged.\\n\\nThe heightened focus on Schiff reflects the extent to which the former prosecutor and longtime Los Angeles-area congressman has become the b\\u00eate noire of the Trump movement since becoming the de facto head of the investigation of Trump\\u2019s efforts to enlist Ukraine\\u2019s help in damaging former vice president Joe Biden, a Democratic presidential candidate. Schiff has come under criticism from Trump and congressional Republicans as they seek to delegitimize the inquiry by portraying it as tainted by political bias. The nub of the criticism of Schiff is that he spoofed the president\\u2019s call with his Ukrainian counterpart during a congressional hearing and that he made misleading statements about the nature of his prior knowledge of the initial whistleblower complaint.\\n\\nAD\\n\\nAnalysts say the pattern resulting in the violent rhetoric targeting Schiff makes evident the radicalizing effect of social media, which Trump uses to incite his followers against his perceived enemies.\\n\\nAD\\n\\n\\u201cWhole online communities are forming around these sentiments, like MAGA,\\u201d said Amarnath Amarasingam, an expert on political violence and an assistant professor at Queen\\u2019s University in Kingston, Ontario, referring to Trump\\u2019s campaign slogan. \\u201cThe online social movement of Trump supporters is very real, and a cohort of that movement has come out and said they\\u2019re ready to take up arms when needed. This is something a few of us have been worried about for some time.\\u201d\\n\\nThe web is where the president\\u2019s hold over his supporters comes into sharpest focus, the extremism researcher said. On Twitter, his opinions \\u2014 and his disparaging views of other politicians \\u2014 are received uncritically, Amarasingam added, giving Trump enormous power over his followers and \\u201csetting the stage for violence.\\u201d\\n\\nAD\\n\\nSome Trump critics have also used sharp language online, including accusing the president of treason and noting the maximum penalty: death.\\n\\nAD\\n\\n\\u201cIt\\u2019s treason, pure and simple, and the penalty for treason under the U.S. code is death,\\u201d former Massachusetts governor Bill Weld, who is challenging Trump for the Republican nomination, said last month on MSNBC of Trump\\u2019s phone call with the Ukrainian president. The comment was tweeted by a reporter, and retweeted by Rep. Sheila Jackson Lee (D-Tex.).\\n\\nFormer congresswoman Gabrielle Giffords (D-Ariz,), who was shot in the head in an assassination attempt in 2011, said the responsibility of politicians to \\u201cseek the truth\\u201d and \\u201ctreat their fellow Americans with respect\\u201d was heightened \\u201cin charged times.\\u201d\\n\\nAD\\n\\nGlobally, public figures are not living up to that responsibility, said Jacob Davey, senior research manager at the Institute for Strategic Dialogue, a U.K.-based think tank dedicated to countering extremism and polarization. The result is increasing online radicalization \\u2014 not just in the Middle East and Northern Africa, long the focus of extremism research, but also in the heart of the West.\\n\\nAD\\n\\nSocial media, he said, \\u201chas undoubtedly made engaging in such behavior easier than ever before, with users escaping the legal and social repercussions of their actions.\\u201d\\n\\nTrump\\u2019s ability to craft an alternate universe for his supporters, in which he is the victim of lawless Democrats, rests on an unregulated online ecosystem, where fake news travels faster than the truth.\\n\\nAD\\n\\nSpanbauer, who became dissatisfied with Obama during his first term and voted for his Republican challenger in 2012, said she gets most of her news on Twitter and YouTube. Among those she trusts are Fox News Channel host Sean Hannity (\\u201cof course\\u201d) and Tom Fitton, the president of Judicial Watch (\\u201cthank God for Tom Fitton\\u201d).\\n\\nTrump, she said, channels her anger at Washington, while speaking directly to his supporters. \\u201cIt\\u2019s wonderful, really, what Trump does on Twitter,\\u201d said Spanbauer, who has worked in retail and sales and struggles, along with her husband, to stay above the federal poverty line.\\n\\nAD\\n\\nBeneath her verdict on Schiff\\u2019s fate, which she acknowledges was hyperbolic, lies a firm conviction that the congressman is guilty of treason.\\n\\nThe impeachment inquiry, she said, is a \\u201csupreme insult to our country.\\u201d Those leading it \\u201cshould be held accountable to the length of the law,\\u201d she added. \\u201cIt\\u2019s treason. It\\u2019s treason.\\u201d\",\n          \"At the center of the bloody rampage unfolding in the \\u201cChurch of Fake News\\u201d is a man dressed in a dark pinstripe suit. President Trump\\u2019s head is superimposed on his body.\\n\\nThe graphic images are from a fake video that was shown during a pro-Trump conference last week at the president\\u2019s hotel and golf resort near Miami, according to the New York Times, which first reported on the video\\u2019s existence Sunday night. The clip has since drawn intense backlash from journalists and public figures who have decried it as \\u201cvile and horrific\\u201d and an \\u201cincitement of violence.\\u201d Many of the news organizations and people featured in the video have been publicly targeted by Trump, who is frequently criticized for his inflammatory remarks and anti-media rhetoric.\\n\\nAD\\n\\nAD\\n\\n\\u201cThis video isn\\u2019t funny,\\u201d tweeted former Texas congressman and Democratic presidential candidate Beto O\\u2019Rourke. \\u201cIt will get people killed.\\u201d\\n\\nAt a conference of Trump supporters, they played a video of our president murdering journalists in a church. Last year, a Trump supporter sent bombs to CNN\\u2014and a shooter entered a church yesterday. This video isn\\u2019t funny. It will get people killed. https://t.co/XWtq1z38Kc \\u2014 Beto O'Rourke (@BetoORourke) October 14, 2019\\n\\nOn Monday, White House press secretary Stephanie Grisham tweeted that Trump had not yet seen the clip, \\u201cbut based upon everything he has heard, he strongly condemns this video.\\u201d\\n\\nRe: the video played over the weekend: The @POTUS @realDonaldTrump has not yet seen the video, he will see it shortly, but based upon everything he has heard, he strongly condemns this video. \\u2014 Stephanie Grisham (@PressSec) October 14, 2019\\n\\nThe video, adapted from the scene of a church massacre in the 2014 film \\u201cKingsman: The Secret Service,\\u201d appeared to be shared to YouTube in 2018 on a channel that posts similar pro-Trump content and has been linked to a meme-maker associated with a website called MemeWorld. The site\\u2019s creator, a user known by his Internet handle, Carpe Donktum, scored an Oval Office meeting in July with Trump, who reportedly welcomed him as a \\u201cgenius.\\u201d\\n\\nAD\\n\\nCarpe Donktum confirmed in a Twitter message Sunday to The Washington Post that \\u201cThe creator of the video is, and will remain a contributor to my site MemeWorld.\\u201d Carpe Donktum declined to identify the video\\u2019s creator citing concerns that the person may face online or in-person harassment.\\n\\nAD\\n\\nAlex Phillips, organizer of the American Priority Festival and Conference, told the Times the video was played at one point during the three-day event that began Thursday as part of a \\u201cmeme exhibit.\\u201d The violent parody was included in a meme compilation that also featured Trump\\u2019s 2020 reelection campaign logo, according to the Times.\\n\\n\\u201cIt has come to our attention that an unauthorized video was shown in a side room at #AMPFest19,\\u201d a statement posted to the conference\\u2019s website said. \\u201cThis video was not approved, seen, or sanctioned by the #AMPFest19 organizers.\\u201d\\n\\nAD\\n\\nThe statement went on to note that the conference \\u201calways has and always will condemn political violence.\\u201d\\n\\nPhillips told the Times the \\u201cmatter is under review.\\u201d\\n\\nIn a statement to The Post early Monday, the Trump campaign distanced itself from the video.\\n\\nAD\\n\\n\\u201cThat video was not produced by the campaign, and we do not condone violence,\\u201d campaign spokesman Tim Murtaugh said.\\n\\nPeople close to Trump, such as former White House press secretary Sarah Sanders and Donald Trump Jr., were also scheduled to speak at the conference and told the Times they were not aware of the edited footage.\\n\\nThe video\\u2019s massacre scene opens with the Trump figure walking down the center aisle of a packed church. More than a dozen of the parishioners\\u2019 faces are covered by the logos of major media organizations, ranging from PBS to The Washington Post. Rising out of the pews when Trump passes them, some of the churchgoers appear to be yelling at the president, whose face contorts into a scowl.\\n\\nAD\\n\\nAs the shouting intensifies, Trump abruptly stops walking and turns to face the angry mob. He pulls out a black gun from his jacket\\u2019s inside pocket and shoots a person edited to represent late actor Peter Fonda, who was a vocal critic of the president, in the head from point-blank range.\\n\\nAD\\n\\nThen, chaos ensues.\\n\\nTrump takes down Bloomberg, Vox and \\u201cFake News\\u201d in quick succession before shooting Politico. At one point, he grabs someone who represents the Black Lives Matter movement in a chokehold and shoots that person in the head.\\n\\nAfter shooting MSNBC host Rachel Maddow, Vice News, Rep. Adam B. Schiff (D-Calif.) and Slate, Trump tries to shoot late senator John McCain (R-Ariz.), but he is out of bullets. Instead, he uses his gun to deliver a vicious blow to the back of McCain\\u2019s neck.\\n\\nAD\\n\\nThe attack continues with Trump going after some of his most prominent detractors. He stabs actress and comedian Rosie O\\u2019Donnell and repeatedly punches Rep. Maxine Waters (D-Calif.). He goes on to shoot MSNBC\\u2019s Mika Brzezinski and Sen. Mitt Romney (R-Utah), and later assaults Hillary Clinton with a gun.\\n\\nAD\\n\\nThe video comes to a dramatic end when Trump jams a sharp wooden stake through the head of a person whose face is a CNN logo. A now-grinning Trump appears to survey the carnage as DJ Khaled\\u2019s song, \\u201cAll I Do Is Win,\\u201d plays in the background. A pair of pixelated black sunglasses are lowered onto Trump\\u2019s face.\\n\\nBy late Sunday, \\u201cKingsman\\u201d was trending on Twitter with many expressing outrage at the video and calling on Trump to condemn it.\\n\\nAD\\n\\n\\u201cSadly, this is not the first time that supporters of the President have promoted violence against the media in a video they apparently find entertaining \\u2014 but it is by far and away the worst,\\u201d CNN said in a statement shared on Twitter.\\n\\nThe images in the recent video are \\u201cvile and horrific,\\u201d CNN said, adding, \\u201cThe President and his family, the White House, and the Trump campaign need to denounce it immediately in the strongest possible terms. Anything less equates to a tacit endorsement of violence and should not be tolerated by anyone.\\u201d\\n\\nAD\\n\\nWhite House Correspondents\\u2019 Association President Jonathan Karl of ABC News also denounced the video, noting that Trump has been warned that \\u201chis rhetoric could incite violence.\\u201d\\n\\nAD\\n\\nWHCA Statement on video depicting President Trump murdering journalists. pic.twitter.com/52lHFaQjU2 \\u2014 WHCA (@whca) October 14, 2019\\n\\nKarl\\u2019s statement was supported early Monday by Cindy McCain, who tweeted that the images in the video of the president killing the media and her late husband \\u201cviolate every norm our society expects from its leaders.\\u201d\\n\\nTrump has made it a habit to publicly lambaste the media, individual journalists and his critics, leading to heightened concerns about safety. In 2017, the president was widely criticized for tweeting a similarly edited video that showed him body slamming a person with a CNN logo for a face during a pro wrestling match. Earlier this year, Cesar Sayoc, a devoted Trump supporter, was sentenced to 20 years in prison for mailing 13 pipe bombs to high-profile Democrats, several of whom were featured in the recent video, and CNN.\\n\\nAD\\n\\nOn Sunday, journalists and political commentators suggested the church video is further evidence that Trump\\u2019s words have influenced his supporters.\\n\\nAD\\n\\n\\u201cThis is an incitement to violence that didn\\u2019t just come from the dark corners of the Internet \\u2014 it was shown at a pro-Trump conference at one of his resorts,\\u201d tweeted Politico reporter Andrew Desiderio. \\u201cI\\u2019m speechless.\\u201d\\n\\nCNN commentator Ana Navarro-C\\u00e1rdenas wrote, \\u201cTrump has legitimized hate.\\u201d\\n\\nEnablers choose to deny it, but this is the kind of crap Trump peddles & inspires. His constant attacks on the free press, the chants against journalists at his rallies, his retweeting of similar memes...Trump has legitimized hate. #Deplorable https://t.co/vqk0w9Kd9n \\u2014 Ana Navarro-C\\u00e1rdenas (@ananavarro) October 14, 2019\\n\\nA year ago this month a man mailed bombs to journalists, Democratic leaders, and critics of Donald Trump. He was responding to Trump\\u2019s violent rhetoric. Now we\\u2019ve got videos of mass slaughters.\\n\\n\\n\\nThere\\u2019s literally no telling what kind of dangers they could unleash. \\u2014 Jared Yates Sexton (@JYSexton) October 14, 2019\\n\\nCall someone an \\\"enemy\\\" over and over again, and you have some responsibility for what happens to them.\\n\\n\\n\\nTrump is responsible for a climate that is so hateful, so hostile toward journalists that it spawns videos like this one. https://t.co/mn1W8W69M1 \\u2014 Brian Stelter (@brianstelter) October 14, 2019\\n\\nActress Kathy Griffin, who drew widespread backlash in 2017 after sharing a photo of herself holding a prop of Trump\\u2019s bloody severed head, echoed concerns about the clip\\u2019s impact. Griffin, shown in the video getting beheaded by the ax-wielding CNN person, tweeted that it \\u201cisn\\u2019t a joke\\u201d to Trump supporters, adding, \\u201cAnd it will not be taken as such.\\\"\\n\\nBut some pushed back against criticisms of the video, pointing out that the film\\u2019s original scene, which depicted a church full of \\u201cconservative Christians\\u201d being killed, did not draw the same level of outcry. According to an NPR review of the movie, the fictional congregation was \\u201cclearly modeled on the Westboro Baptist Church,\\u201d a Kansas-based organization known for its anti-gay views.\\n\\nAD\\n\\nStill, others wondered if the video represents, as one person put it, \\u201cthe country hitting rock bottom.\\u201d\\n\\n\\u201cWe have enough mass shootings, we have enough journalists killed in the line of duty around the world \\u2014 we don\\u2019t need to glorify a massacre of people who challenge Trump,\\u201d Times columnist Nicholas Kristof tweeted. \\u201cThis demonization of opponents and fetishization of violence is unconscionable.\\u201d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Szp3M3We36PX"
      },
      "outputs": [],
      "source": [
        "dctk = data_cleaning_toolkit() #  a python package to clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yWosuMX-6RGG"
      },
      "outputs": [],
      "source": [
        "dctk.sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Ku2t609uCK",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-292d1e2b08c74976",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "cfeae39f-74d5-47e3-b014-586a5bea1e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136\n",
            "136\n",
            "Created 168985 sequences.\n"
          ]
        }
      ],
      "source": [
        "# instantiate data cleaning toolkit\n",
        "dctk = data_cleaning_toolkit()\n",
        "\n",
        "# use regex to clean documents, applying the clean_data method from dctk\n",
        "df['clean_data'] = df.article.apply(lambda text: dctk.clean_data(text))\n",
        "print(len(df['clean_data']))\n",
        "\n",
        "# extract cleaned articles to an array of strings\n",
        "data = df['clean_data'].values\n",
        "print(len(data))\n",
        "\n",
        "# number of chars in each sequence\n",
        "doc_len = 20\n",
        "\n",
        "# numerically encode the sequences, using the create_char_sequences method from dctk\n",
        "dctk.create_char_sequences(data, doc_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDzu_NIH6cRE",
        "outputId": "5fa6f7ef-dda5-4e04-e074-89387ebf6e97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dctk.next_char[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QPOa3xqk-LF"
      },
      "source": [
        "Here is the first article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "wfbpmXNZOrS3",
        "outputId": "b286b819-2eac-44ea-db8b-df569d08fa43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Contributing columnist\\n\\nThe House is on fire. And with each passing day, Donald Trump defiles the office of the president. If only past defrocked presidents could provide a roadmap for this firestorm.\\n\\nAndrew Johnson fought impeachment vigorously and survived removal, but never won reelection. Richard Nixon got in the way of justice, but eventually bowed to the rule of law, accepting his asterisk in the annals of history and resigning before certain removal. Bill Clinton expressed contrition, went on to complete his presidency with high approval ratings and has remained a popular former president.\\n\\nIf you care about democracy, the rule of law and nearly 250 years of constitutional governance, take heed. President Trump is no Clinton or Nixon, or even Johnson. He will not go quietly. It will be ugly. He will betray us and the rule of law in the process — defying subpoenas, withholding documents, blocking witnesses.\\n\\nThis presidency is fouled with disrespect for rules, boundaries and norms. Trump walked away from major agreements negotiated by his predecessors — the Iran nuclear deal, the Paris climate accord — and the United States’ word as bond is no more. Look at the ease with which he discards supporters — ask former attorney general Jeff Sessions or former secretary of state Rex Tillerson. Ask our allies, here today, gone tomorrow — NATO, the Kurds in Syria.\\n\\nFrom his earliest days as a candidate, Trump voiced appallingly arrogant views about the power of the presidency: “Mexico will pay for the wall!” ; “I alone can fix it”; “My primary consultant is myself.” His possessiveness over people and institutions is also not new: “my generals and my military,” “my African American.”\\n\\nOnly months into his presidency, Trump disparaged democratic allies, including Germany’s Angela Merkel (“ruining Germany”) and Britain’s Theresa May (“foolish”) — notably, both women — in favor of strong-arm leaders such as North Korea’s Kim Jong Un (who wrote him “beautiful letters”), Saudi Arabia’s Mohammed bin Salman (“very good ally”), Turkey’s Recep Tayyip Erdogan (“great friendship”) and the Philippines’ Rodrigo Duterte (“great relationship”). Trump heaps praise on Russia’s Vladimir Putin (“he’s a strong leader”). And, days after revealing his words pressuring Ukrainian President Volodymyr Zelensky to dig up dirt on his opponent, he invited China to do it, too.\\n\\nTrump’s campaign for the White House was rotten from the beginning. We glimpsed its depths when his lawyer Michael Cohen pleaded guilty to campaign finance felonies and identified Trump as “Individual 1” in a conspiracy to pay off an adult-film star and a former Playboy model to silence them during the height of the 2016 presidential campaign. We got even more evidence of Trump’s deception in the dense report prepared by special counsel Robert S. Mueller III on Russia’s interference in the 2016 election to benefit Trump and try to defeat Hillary Clinton. Mueller laid the groundwork for at least 10 acts of obstruction of justice.\\n\\nEven with all of that, it’s this still-unraveling Ukraine story that makes clear the bits and pieces that we could only imagine with Trump’s pleas to “Russia, if you’re listening . . . .” We have the same threats, lies, subterfuge and obstruction — only this time, we have the president’s unambiguous words to Zelensky: “I would like you to do us a favor though.” Ukraine represents the same lawlessness that propelled Trump over the finish line in 2016: this time in plain sight, with witnesses, including at least one whistleblower and lots of bit players. From the State Department to the Energy Department to the Justice Department and throughout the White House, Trump is using every bit of the machinery of government and personnel at his disposal to strongarm a small country under the heel of its threatening Russian neighbor — all to get manufactured dirt on a political opponent.\\n\\nIt’s illegal. The evidence is bearing fruit. The time will come. And justice will be served.\\n\\nThe president’s personal approval rating remains low, though stable, but there is growing support for impeachment — a Fox News poll this week found that 51 percent support removing Trump from office. Independents, as well as Democrats, mostly support the impeachment inquiry, while Republicans are mostly holding tight. These things may or may not change.\\n\\nEither way, we will be changed if we do not right this ship of democracy.\\n\\n“Impeachment is not about punishment. Impeachment is about cleansing the office. Impeachment is about restoring honor and integrity to the office.” We should heed these words, spoken by the 1999 version of Sen. Lindsey O. Graham (R-S.C.). The fire did not start with Ukraine. Nonetheless, Ukraine may give us the water to finally put it out.\\n\\nRead more from Donna F. Edwards's archive.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "(df['article'][0]) # uncleaned data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE86rmUicjM_"
      },
      "source": [
        "`data` is an array containing the cleaned articles.<br>\n",
        "Here is the cleaned version of the first article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "mljIx-NSPX3E",
        "outputId": "fbbcbafc-b6b4-483e-f573-411437da6bb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contributing columnistthe house is on fire and with each passing day donald trump defiles the office of the president if only past defrocked presidents could provide a roadmap for this firestormandrew johnson fought impeachment vigorously and survived removal but never won reelection richard nixon got in the way of justice but eventually bowed to the rule of law accepting his asterisk in the annals of history and resigning before certain removal bill clinton expressed contrition went on to complete his presidency with high approval ratings and has remained a popular former presidentif you care about democracy the rule of law and nearlyyears of constitutional governance take heed president trump is no clinton or nixon or even johnson he will not go quietly it will be ugly he will betray us and the rule of law in the processdefying subpoenas withholding documents blocking witnessesthis presidency is fouled with disrespect for rules boundaries and norms trump walked away from major agreements negotiated by his predecessorsthe iran nuclear deal the paris climate accordand the united states word as bond is no more look at the ease with which he discards supportersask former attorney general jeff sessions or former secretary of state rex tillerson ask our allies here today gone tomorrownato the kurds in syriafrom his earliest days as a candidate trump voiced appallingly arrogant views about the power of the presidency mexico will pay for the walli alone can fix it my primary consultant is myself his possessiveness over people and institutions is also not new my generals and my military my african americanonly months into his presidency trump disparaged democratic allies including germanys angela merkel ruining germany and britains theresa may foolishnotably both womenin favor of strongarm leaders such as north koreas kim jong un who wrote him beautiful letters saudi arabias mohammed bin salman very good ally turkeys recep tayyip erdogan great friendship and the philippines rodrigo duterte great relationship trump heaps praise on russias vladimir putin hes a strong leader and days after revealing his words pressuring ukrainian president volodymyr zelensky to dig up dirt on his opponent he invited china to do it tootrumps campaign for the white house was rotten from the beginning we glimpsed its depths when his lawyer michael cohen pleaded guilty to campaign finance felonies and identified trump as individualin a conspiracy to pay off an adultfilm star and a former playboy model to silence them during the height of thepresidential campaign we got even more evidence of trumps deception in the dense report prepared by special counsel robert s mueller iii on russias interference in theelection to benefit trump and try to defeat hillary clinton mueller laid the groundwork for at leastacts of obstruction of justiceeven with all of that its this stillunraveling ukraine story that makes clear the bits and pieces that we could only imagine with trumps pleas to russia if youre listeningwe have the same threats lies subterfuge and obstructiononly this time we have the presidents unambiguous words to zelensky i would like you to do us a favor though ukraine represents the same lawlessness that propelled trump over the finish line inthis time in plain sight with witnesses including at least one whistleblower and lots of bit players from the state department to the energy department to the justice department and throughout the white house trump is using every bit of the machinery of government and personnel at his disposal to strongarm a small country under the heel of its threatening russian neighborall to get manufactured dirt on a political opponentits illegal the evidence is bearing fruit the time will come and justice will be servedthe presidents personal approval rating remains low though stable but there is growing support for impeachmenta fox news poll this week found thatpercent support removing trump from office independents as well as democrats mostly support the impeachment inquiry while republicans are mostly holding tight these things may or may not changeeither way we will be changed if we do not right this ship of democracyimpeachment is not about punishment impeachment is about cleansing the office impeachment is about restoring honor and integrity to the office we should heed these words spoken by theversion of sen lindsey o graham rsc the fire did not start with ukraine nonetheless ukraine may give us the water to finally put it outread more from donna f edwardss archive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "data[0] # after applying the data cleaning method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW5XKqPzisak"
      },
      "source": [
        "Let's explore the `dctk` class we just instantiated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4la7twqqhxmH",
        "outputId": "3173ecae-04f2-4211-f889-40dcfc1dd280"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "type(dctk)\n",
        "dctk.n_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dctk.sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHcx5u9gYoXa",
        "outputId": "1623dfca-e18c-4ffd-c296-227597d6aab3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[13,\n",
              "  11,\n",
              "  15,\n",
              "  21,\n",
              "  12,\n",
              "  18,\n",
              "  22,\n",
              "  17,\n",
              "  21,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  16,\n",
              "  13,\n",
              "  11,\n",
              "  1,\n",
              "  17,\n",
              "  25,\n",
              "  15,\n",
              "  18],\n",
              " [18, 22, 17, 21, 18, 15, 3, 16, 13, 11, 1, 17, 25, 15, 18, 20, 21, 21, 23, 0],\n",
              " [15, 3, 16, 13, 11, 1, 17, 25, 15, 18, 20, 21, 21, 23, 0, 16, 23, 11, 17, 20],\n",
              " [1, 17, 25, 15, 18, 20, 21, 21, 23, 0, 16, 23, 11, 17, 20, 0, 16, 18, 20, 16],\n",
              " [20,\n",
              "  21,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  23,\n",
              "  11,\n",
              "  17,\n",
              "  20,\n",
              "  0,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  19,\n",
              "  18],\n",
              " [16,\n",
              "  23,\n",
              "  11,\n",
              "  17,\n",
              "  20,\n",
              "  0,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  15],\n",
              " [0,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21],\n",
              " [11,\n",
              "  15,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  0,\n",
              "  14,\n",
              "  13],\n",
              " [12, 0, 16, 14, 15, 26, 16, 10, 18, 21, 23, 16, 0, 14, 13, 23, 16, 6, 14, 20],\n",
              " [26, 16, 10, 18, 21, 23, 16, 0, 14, 13, 23, 16, 6, 14, 20, 20, 18, 15, 3, 16],\n",
              " [23, 16, 0, 14, 13, 23, 16, 6, 14, 20, 20, 18, 15, 3, 16, 26, 14, 8, 16, 26],\n",
              " [23, 16, 6, 14, 20, 20, 18, 15, 3, 16, 26, 14, 8, 16, 26, 11, 15, 14, 1, 26],\n",
              " [20, 18, 15, 3, 16, 26, 14, 8, 16, 26, 11, 15, 14, 1, 26, 16, 21, 12, 17, 25],\n",
              " [26, 14, 8, 16, 26, 11, 15, 14, 1, 26, 16, 21, 12, 17, 25, 6, 16, 26, 0, 19],\n",
              " [11, 15, 14, 1, 26, 16, 21, 12, 17, 25, 6, 16, 26, 0, 19, 18, 1, 0, 20, 16],\n",
              " [16, 21, 12, 17, 25, 6, 16, 26, 0, 19, 18, 1, 0, 20, 16, 21, 23, 0, 16, 11],\n",
              " [6, 16, 26, 0, 19, 18, 1, 0, 20, 16, 21, 23, 0, 16, 11, 19, 19, 18, 13, 0],\n",
              " [18, 1, 0, 20, 16, 21, 23, 0, 16, 11, 19, 19, 18, 13, 0, 16, 11, 19, 16, 21],\n",
              " [21, 23, 0, 16, 11, 19, 19, 18, 13, 0, 16, 11, 19, 16, 21, 23, 0, 16, 6, 12],\n",
              " [19, 19, 18, 13, 0, 16, 11, 19, 16, 21, 23, 0, 16, 6, 12, 0, 20, 18, 26, 0],\n",
              " [16, 11, 19, 16, 21, 23, 0, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 16, 18, 19],\n",
              " [23, 0, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 16, 18, 19, 16, 11, 15, 1, 8],\n",
              " [0, 20, 18, 26, 0, 15, 21, 16, 18, 19, 16, 11, 15, 1, 8, 16, 6, 14, 20, 21],\n",
              " [15, 21, 16, 18, 19, 16, 11, 15, 1, 8, 16, 6, 14, 20, 21, 16, 26, 0, 19, 12],\n",
              " [16, 11, 15, 1, 8, 16, 6, 14, 20, 21, 16, 26, 0, 19, 12, 11, 13, 24, 0, 26],\n",
              " [16, 6, 14, 20, 21, 16, 26, 0, 19, 12, 11, 13, 24, 0, 26, 16, 6, 12, 0, 20],\n",
              " [16, 26, 0, 19, 12, 11, 13, 24, 0, 26, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21],\n",
              " [11, 13, 24, 0, 26, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 20, 16, 13, 11, 17],\n",
              " [16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 20, 16, 13, 11, 17, 1, 26, 16, 6, 12],\n",
              " [18, 26, 0, 15, 21, 20, 16, 13, 11, 17, 1, 26, 16, 6, 12, 11, 2, 18, 26, 0],\n",
              " [20, 16, 13, 11, 17, 1, 26, 16, 6, 12, 11, 2, 18, 26, 0, 16, 14, 16, 12, 11],\n",
              " [1, 26, 16, 6, 12, 11, 2, 18, 26, 0, 16, 14, 16, 12, 11, 14, 26, 25, 14, 6],\n",
              " [11, 2, 18, 26, 0, 16, 14, 16, 12, 11, 14, 26, 25, 14, 6, 16, 19, 11, 12, 16],\n",
              " [16,\n",
              "  14,\n",
              "  16,\n",
              "  12,\n",
              "  11,\n",
              "  14,\n",
              "  26,\n",
              "  25,\n",
              "  14,\n",
              "  6,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16],\n",
              " [14,\n",
              "  26,\n",
              "  25,\n",
              "  14,\n",
              "  6,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  20],\n",
              " [16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  20,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  14],\n",
              " [21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  20,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  12,\n",
              "  0,\n",
              "  10],\n",
              " [19, 18, 12, 0, 20, 21, 11, 12, 25, 14, 15, 26, 12, 0, 10, 16, 4, 11, 23, 15],\n",
              " [21,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  12,\n",
              "  0,\n",
              "  10,\n",
              "  16,\n",
              "  4,\n",
              "  11,\n",
              "  23,\n",
              "  15,\n",
              "  20,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  19],\n",
              " [15, 26, 12, 0, 10, 16, 4, 11, 23, 15, 20, 11, 15, 16, 19, 11, 17, 3, 23, 21],\n",
              " [16, 4, 11, 23, 15, 20, 11, 15, 16, 19, 11, 17, 3, 23, 21, 16, 18, 25, 6, 0],\n",
              " [20, 11, 15, 16, 19, 11, 17, 3, 23, 21, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0],\n",
              " [11, 17, 3, 23, 21, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 2, 18],\n",
              " [16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 2, 18, 3, 11, 12, 11, 17],\n",
              " [14, 13, 23, 25, 0, 15, 21, 16, 2, 18, 3, 11, 12, 11, 17, 20, 1, 8, 16, 14],\n",
              " [15, 21, 16, 2, 18, 3, 11, 12, 11, 17, 20, 1, 8, 16, 14, 15, 26, 16, 20, 17],\n",
              " [3, 11, 12, 11, 17, 20, 1, 8, 16, 14, 15, 26, 16, 20, 17, 12, 2, 18, 2, 0],\n",
              " [20, 1, 8, 16, 14, 15, 26, 16, 20, 17, 12, 2, 18, 2, 0, 26, 16, 12, 0, 25],\n",
              " [15, 26, 16, 20, 17, 12, 2, 18, 2, 0, 26, 16, 12, 0, 25, 11, 2, 14, 1, 16],\n",
              " [12, 2, 18, 2, 0, 26, 16, 12, 0, 25, 11, 2, 14, 1, 16, 22, 17, 21, 16, 15],\n",
              " [26, 16, 12, 0, 25, 11, 2, 14, 1, 16, 22, 17, 21, 16, 15, 0, 2, 0, 12, 16],\n",
              " [11, 2, 14, 1, 16, 22, 17, 21, 16, 15, 0, 2, 0, 12, 16, 10, 11, 15, 16, 12],\n",
              " [22, 17, 21, 16, 15, 0, 2, 0, 12, 16, 10, 11, 15, 16, 12, 0, 0, 1, 0, 13],\n",
              " [0, 2, 0, 12, 16, 10, 11, 15, 16, 12, 0, 0, 1, 0, 13, 21, 18, 11, 15, 16],\n",
              " [10, 11, 15, 16, 12, 0, 0, 1, 0, 13, 21, 18, 11, 15, 16, 12, 18, 13, 23, 14],\n",
              " [0, 0, 1, 0, 13, 21, 18, 11, 15, 16, 12, 18, 13, 23, 14, 12, 26, 16, 15, 18],\n",
              " [21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  12,\n",
              "  18,\n",
              "  13,\n",
              "  23,\n",
              "  14,\n",
              "  12,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  18,\n",
              "  9,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  3],\n",
              " [12,\n",
              "  18,\n",
              "  13,\n",
              "  23,\n",
              "  14,\n",
              "  12,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  18,\n",
              "  9,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  3,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  18,\n",
              "  15],\n",
              " [12, 26, 16, 15, 18, 9, 11, 15, 16, 3, 11, 21, 16, 18, 15, 16, 21, 23, 0, 16],\n",
              " [9, 11, 15, 16, 3, 11, 21, 16, 18, 15, 16, 21, 23, 0, 16, 10, 14, 8, 16, 11],\n",
              " [11, 21, 16, 18, 15, 16, 21, 23, 0, 16, 10, 14, 8, 16, 11, 19, 16, 4, 17, 20],\n",
              " [16, 21, 23, 0, 16, 10, 14, 8, 16, 11, 19, 16, 4, 17, 20, 21, 18, 13, 0, 16],\n",
              " [10, 14, 8, 16, 11, 19, 16, 4, 17, 20, 21, 18, 13, 0, 16, 22, 17, 21, 16, 0],\n",
              " [19, 16, 4, 17, 20, 21, 18, 13, 0, 16, 22, 17, 21, 16, 0, 2, 0, 15, 21, 17],\n",
              " [21, 18, 13, 0, 16, 22, 17, 21, 16, 0, 2, 0, 15, 21, 17, 14, 1, 1, 8, 16],\n",
              " [22, 17, 21, 16, 0, 2, 0, 15, 21, 17, 14, 1, 1, 8, 16, 22, 11, 10, 0, 26],\n",
              " [2, 0, 15, 21, 17, 14, 1, 1, 8, 16, 22, 11, 10, 0, 26, 16, 21, 11, 16, 21],\n",
              " [14, 1, 1, 8, 16, 22, 11, 10, 0, 26, 16, 21, 11, 16, 21, 23, 0, 16, 12, 17],\n",
              " [22, 11, 10, 0, 26, 16, 21, 11, 16, 21, 23, 0, 16, 12, 17, 1, 0, 16, 11, 19],\n",
              " [16, 21, 11, 16, 21, 23, 0, 16, 12, 17, 1, 0, 16, 11, 19, 16, 1, 14, 10, 16],\n",
              " [23, 0, 16, 12, 17, 1, 0, 16, 11, 19, 16, 1, 14, 10, 16, 14, 13, 13, 0, 6],\n",
              " [1, 0, 16, 11, 19, 16, 1, 14, 10, 16, 14, 13, 13, 0, 6, 21, 18, 15, 3, 16],\n",
              " [16, 1, 14, 10, 16, 14, 13, 13, 0, 6, 21, 18, 15, 3, 16, 23, 18, 20, 16, 14],\n",
              " [14, 13, 13, 0, 6, 21, 18, 15, 3, 16, 23, 18, 20, 16, 14, 20, 21, 0, 12, 18],\n",
              " [21,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  21,\n",
              "  0,\n",
              "  12,\n",
              "  18,\n",
              "  20,\n",
              "  24,\n",
              "  16,\n",
              "  18,\n",
              "  15],\n",
              " [23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  21,\n",
              "  0,\n",
              "  12,\n",
              "  18,\n",
              "  20,\n",
              "  24,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16],\n",
              " [20, 21, 0, 12, 18, 20, 24, 16, 18, 15, 16, 21, 23, 0, 16, 14, 15, 15, 14, 1],\n",
              " [20,\n",
              "  24,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  15,\n",
              "  14,\n",
              "  1,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16],\n",
              " [16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  15,\n",
              "  14,\n",
              "  1,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  21,\n",
              "  11],\n",
              " [14,\n",
              "  15,\n",
              "  15,\n",
              "  14,\n",
              "  1,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  8,\n",
              "  16,\n",
              "  14,\n",
              "  15],\n",
              " [20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  8,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  12,\n",
              "  0,\n",
              "  20],\n",
              " [23, 18, 20, 21, 11, 12, 8, 16, 14, 15, 26, 16, 12, 0, 20, 18, 3, 15, 18, 15],\n",
              " [12, 8, 16, 14, 15, 26, 16, 12, 0, 20, 18, 3, 15, 18, 15, 3, 16, 22, 0, 19],\n",
              " [26, 16, 12, 0, 20, 18, 3, 15, 18, 15, 3, 16, 22, 0, 19, 11, 12, 0, 16, 13],\n",
              " [18, 3, 15, 18, 15, 3, 16, 22, 0, 19, 11, 12, 0, 16, 13, 0, 12, 21, 14, 18],\n",
              " [3, 16, 22, 0, 19, 11, 12, 0, 16, 13, 0, 12, 21, 14, 18, 15, 16, 12, 0, 25],\n",
              " [11, 12, 0, 16, 13, 0, 12, 21, 14, 18, 15, 16, 12, 0, 25, 11, 2, 14, 1, 16],\n",
              " [0, 12, 21, 14, 18, 15, 16, 12, 0, 25, 11, 2, 14, 1, 16, 22, 18, 1, 1, 16],\n",
              " [15, 16, 12, 0, 25, 11, 2, 14, 1, 16, 22, 18, 1, 1, 16, 13, 1, 18, 15, 21],\n",
              " [11, 2, 14, 1, 16, 22, 18, 1, 1, 16, 13, 1, 18, 15, 21, 11, 15, 16, 0, 9],\n",
              " [22, 18, 1, 1, 16, 13, 1, 18, 15, 21, 11, 15, 16, 0, 9, 6, 12, 0, 20, 20],\n",
              " [13, 1, 18, 15, 21, 11, 15, 16, 0, 9, 6, 12, 0, 20, 20, 0, 26, 16, 13, 11],\n",
              " [11, 15, 16, 0, 9, 6, 12, 0, 20, 20, 0, 26, 16, 13, 11, 15, 21, 12, 18, 21],\n",
              " [6, 12, 0, 20, 20, 0, 26, 16, 13, 11, 15, 21, 12, 18, 21, 18, 11, 15, 16, 10],\n",
              " [0,\n",
              "  26,\n",
              "  16,\n",
              "  13,\n",
              "  11,\n",
              "  15,\n",
              "  21,\n",
              "  12,\n",
              "  18,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  10,\n",
              "  0,\n",
              "  15,\n",
              "  21,\n",
              "  16,\n",
              "  11],\n",
              " [15,\n",
              "  21,\n",
              "  12,\n",
              "  18,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  10,\n",
              "  0,\n",
              "  15,\n",
              "  21,\n",
              "  16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16],\n",
              " [18, 11, 15, 16, 10, 0, 15, 21, 16, 11, 15, 16, 21, 11, 16, 13, 11, 25, 6, 1],\n",
              " [0, 15, 21, 16, 11, 15, 16, 21, 11, 16, 13, 11, 25, 6, 1, 0, 21, 0, 16, 23],\n",
              " [15, 16, 21, 11, 16, 13, 11, 25, 6, 1, 0, 21, 0, 16, 23, 18, 20, 16, 6, 12],\n",
              " [13, 11, 25, 6, 1, 0, 21, 0, 16, 23, 18, 20, 16, 6, 12, 0, 20, 18, 26, 0],\n",
              " [0, 21, 0, 16, 23, 18, 20, 16, 6, 12, 0, 20, 18, 26, 0, 15, 13, 8, 16, 10],\n",
              " [18, 20, 16, 6, 12, 0, 20, 18, 26, 0, 15, 13, 8, 16, 10, 18, 21, 23, 16, 23],\n",
              " [0, 20, 18, 26, 0, 15, 13, 8, 16, 10, 18, 21, 23, 16, 23, 18, 3, 23, 16, 14],\n",
              " [15, 13, 8, 16, 10, 18, 21, 23, 16, 23, 18, 3, 23, 16, 14, 6, 6, 12, 11, 2],\n",
              " [18, 21, 23, 16, 23, 18, 3, 23, 16, 14, 6, 6, 12, 11, 2, 14, 1, 16, 12, 14],\n",
              " [18, 3, 23, 16, 14, 6, 6, 12, 11, 2, 14, 1, 16, 12, 14, 21, 18, 15, 3, 20],\n",
              " [6, 6, 12, 11, 2, 14, 1, 16, 12, 14, 21, 18, 15, 3, 20, 16, 14, 15, 26, 16],\n",
              " [14,\n",
              "  1,\n",
              "  16,\n",
              "  12,\n",
              "  14,\n",
              "  21,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  23,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  12],\n",
              " [21,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  23,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  12,\n",
              "  0,\n",
              "  25,\n",
              "  14,\n",
              "  18,\n",
              "  15],\n",
              " [16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  23,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  12,\n",
              "  0,\n",
              "  25,\n",
              "  14,\n",
              "  18,\n",
              "  15,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  14,\n",
              "  16],\n",
              " [23, 14, 20, 16, 12, 0, 25, 14, 18, 15, 0, 26, 16, 14, 16, 6, 11, 6, 17, 1],\n",
              " [0, 25, 14, 18, 15, 0, 26, 16, 14, 16, 6, 11, 6, 17, 1, 14, 12, 16, 19, 11],\n",
              " [0, 26, 16, 14, 16, 6, 11, 6, 17, 1, 14, 12, 16, 19, 11, 12, 25, 0, 12, 16],\n",
              " [6, 11, 6, 17, 1, 14, 12, 16, 19, 11, 12, 25, 0, 12, 16, 6, 12, 0, 20, 18],\n",
              " [14, 12, 16, 19, 11, 12, 25, 0, 12, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 18],\n",
              " [12, 25, 0, 12, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 18, 19, 16, 8, 11, 17],\n",
              " [6, 12, 0, 20, 18, 26, 0, 15, 21, 18, 19, 16, 8, 11, 17, 16, 13, 14, 12, 0],\n",
              " [26, 0, 15, 21, 18, 19, 16, 8, 11, 17, 16, 13, 14, 12, 0, 16, 14, 22, 11, 17],\n",
              " [19, 16, 8, 11, 17, 16, 13, 14, 12, 0, 16, 14, 22, 11, 17, 21, 16, 26, 0, 25],\n",
              " [16,\n",
              "  13,\n",
              "  14,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  22,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16,\n",
              "  26,\n",
              "  0,\n",
              "  25,\n",
              "  11,\n",
              "  13,\n",
              "  12,\n",
              "  14,\n",
              "  13],\n",
              " [16, 14, 22, 11, 17, 21, 16, 26, 0, 25, 11, 13, 12, 14, 13, 8, 16, 21, 23, 0],\n",
              " [21, 16, 26, 0, 25, 11, 13, 12, 14, 13, 8, 16, 21, 23, 0, 16, 12, 17, 1, 0],\n",
              " [11, 13, 12, 14, 13, 8, 16, 21, 23, 0, 16, 12, 17, 1, 0, 16, 11, 19, 16, 1],\n",
              " [8, 16, 21, 23, 0, 16, 12, 17, 1, 0, 16, 11, 19, 16, 1, 14, 10, 16, 14, 15],\n",
              " [16, 12, 17, 1, 0, 16, 11, 19, 16, 1, 14, 10, 16, 14, 15, 26, 16, 15, 0, 14],\n",
              " [16, 11, 19, 16, 1, 14, 10, 16, 14, 15, 26, 16, 15, 0, 14, 12, 1, 8, 8, 0],\n",
              " [14, 10, 16, 14, 15, 26, 16, 15, 0, 14, 12, 1, 8, 8, 0, 14, 12, 20, 16, 11],\n",
              " [26, 16, 15, 0, 14, 12, 1, 8, 8, 0, 14, 12, 20, 16, 11, 19, 16, 13, 11, 15],\n",
              " [12, 1, 8, 8, 0, 14, 12, 20, 16, 11, 19, 16, 13, 11, 15, 20, 21, 18, 21, 17],\n",
              " [14,\n",
              "  12,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  13,\n",
              "  11,\n",
              "  15,\n",
              "  20,\n",
              "  21,\n",
              "  18,\n",
              "  21,\n",
              "  17,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  14],\n",
              " [19, 16, 13, 11, 15, 20, 21, 18, 21, 17, 21, 18, 11, 15, 14, 1, 16, 3, 11, 2],\n",
              " [20, 21, 18, 21, 17, 21, 18, 11, 15, 14, 1, 16, 3, 11, 2, 0, 12, 15, 14, 15],\n",
              " [21, 18, 11, 15, 14, 1, 16, 3, 11, 2, 0, 12, 15, 14, 15, 13, 0, 16, 21, 14],\n",
              " [1, 16, 3, 11, 2, 0, 12, 15, 14, 15, 13, 0, 16, 21, 14, 24, 0, 16, 23, 0],\n",
              " [0, 12, 15, 14, 15, 13, 0, 16, 21, 14, 24, 0, 16, 23, 0, 0, 26, 16, 6, 12],\n",
              " [13, 0, 16, 21, 14, 24, 0, 16, 23, 0, 0, 26, 16, 6, 12, 0, 20, 18, 26, 0],\n",
              " [24, 0, 16, 23, 0, 0, 26, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 16, 21, 12],\n",
              " [0, 26, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 16, 21, 12, 17, 25, 6, 16, 18],\n",
              " [0, 20, 18, 26, 0, 15, 21, 16, 21, 12, 17, 25, 6, 16, 18, 20, 16, 15, 11, 16],\n",
              " [15,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  25,\n",
              "  6,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  16,\n",
              "  13,\n",
              "  1,\n",
              "  18,\n",
              "  15,\n",
              "  21],\n",
              " [17,\n",
              "  25,\n",
              "  6,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  16,\n",
              "  13,\n",
              "  1,\n",
              "  18,\n",
              "  15,\n",
              "  21,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  11,\n",
              "  12],\n",
              " [20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  16,\n",
              "  13,\n",
              "  1,\n",
              "  18,\n",
              "  15,\n",
              "  21,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  15,\n",
              "  18,\n",
              "  9,\n",
              "  11],\n",
              " [13,\n",
              "  1,\n",
              "  18,\n",
              "  15,\n",
              "  21,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  15,\n",
              "  18,\n",
              "  9,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  11,\n",
              "  12,\n",
              "  16],\n",
              " [11, 15, 16, 11, 12, 16, 15, 18, 9, 11, 15, 16, 11, 12, 16, 0, 2, 0, 15, 16],\n",
              " [16, 15, 18, 9, 11, 15, 16, 11, 12, 16, 0, 2, 0, 15, 16, 4, 11, 23, 15, 20],\n",
              " [15, 16, 11, 12, 16, 0, 2, 0, 15, 16, 4, 11, 23, 15, 20, 11, 15, 16, 23, 0],\n",
              " [0, 2, 0, 15, 16, 4, 11, 23, 15, 20, 11, 15, 16, 23, 0, 16, 10, 18, 1, 1],\n",
              " [4, 11, 23, 15, 20, 11, 15, 16, 23, 0, 16, 10, 18, 1, 1, 16, 15, 11, 21, 16],\n",
              " [11, 15, 16, 23, 0, 16, 10, 18, 1, 1, 16, 15, 11, 21, 16, 3, 11, 16, 5, 17],\n",
              " [16, 10, 18, 1, 1, 16, 15, 11, 21, 16, 3, 11, 16, 5, 17, 18, 0, 21, 1, 8],\n",
              " [16, 15, 11, 21, 16, 3, 11, 16, 5, 17, 18, 0, 21, 1, 8, 16, 18, 21, 16, 10],\n",
              " [3, 11, 16, 5, 17, 18, 0, 21, 1, 8, 16, 18, 21, 16, 10, 18, 1, 1, 16, 22],\n",
              " [18, 0, 21, 1, 8, 16, 18, 21, 16, 10, 18, 1, 1, 16, 22, 0, 16, 17, 3, 1],\n",
              " [16, 18, 21, 16, 10, 18, 1, 1, 16, 22, 0, 16, 17, 3, 1, 8, 16, 23, 0, 16],\n",
              " [18, 1, 1, 16, 22, 0, 16, 17, 3, 1, 8, 16, 23, 0, 16, 10, 18, 1, 1, 16],\n",
              " [0, 16, 17, 3, 1, 8, 16, 23, 0, 16, 10, 18, 1, 1, 16, 22, 0, 21, 12, 14],\n",
              " [8, 16, 23, 0, 16, 10, 18, 1, 1, 16, 22, 0, 21, 12, 14, 8, 16, 17, 20, 16],\n",
              " [10, 18, 1, 1, 16, 22, 0, 21, 12, 14, 8, 16, 17, 20, 16, 14, 15, 26, 16, 21],\n",
              " [22, 0, 21, 12, 14, 8, 16, 17, 20, 16, 14, 15, 26, 16, 21, 23, 0, 16, 12, 17],\n",
              " [8, 16, 17, 20, 16, 14, 15, 26, 16, 21, 23, 0, 16, 12, 17, 1, 0, 16, 11, 19],\n",
              " [14, 15, 26, 16, 21, 23, 0, 16, 12, 17, 1, 0, 16, 11, 19, 16, 1, 14, 10, 16],\n",
              " [23, 0, 16, 12, 17, 1, 0, 16, 11, 19, 16, 1, 14, 10, 16, 18, 15, 16, 21, 23],\n",
              " [1, 0, 16, 11, 19, 16, 1, 14, 10, 16, 18, 15, 16, 21, 23, 0, 16, 6, 12, 11],\n",
              " [16, 1, 14, 10, 16, 18, 15, 16, 21, 23, 0, 16, 6, 12, 11, 13, 0, 20, 20, 26],\n",
              " [18, 15, 16, 21, 23, 0, 16, 6, 12, 11, 13, 0, 20, 20, 26, 0, 19, 8, 18, 15],\n",
              " [0, 16, 6, 12, 11, 13, 0, 20, 20, 26, 0, 19, 8, 18, 15, 3, 16, 20, 17, 22],\n",
              " [13, 0, 20, 20, 26, 0, 19, 8, 18, 15, 3, 16, 20, 17, 22, 6, 11, 0, 15, 14],\n",
              " [0, 19, 8, 18, 15, 3, 16, 20, 17, 22, 6, 11, 0, 15, 14, 20, 16, 10, 18, 21],\n",
              " [3, 16, 20, 17, 22, 6, 11, 0, 15, 14, 20, 16, 10, 18, 21, 23, 23, 11, 1, 26],\n",
              " [6, 11, 0, 15, 14, 20, 16, 10, 18, 21, 23, 23, 11, 1, 26, 18, 15, 3, 16, 26],\n",
              " [20, 16, 10, 18, 21, 23, 23, 11, 1, 26, 18, 15, 3, 16, 26, 11, 13, 17, 25, 0],\n",
              " [23, 23, 11, 1, 26, 18, 15, 3, 16, 26, 11, 13, 17, 25, 0, 15, 21, 20, 16, 22],\n",
              " [18, 15, 3, 16, 26, 11, 13, 17, 25, 0, 15, 21, 20, 16, 22, 1, 11, 13, 24, 18],\n",
              " [11, 13, 17, 25, 0, 15, 21, 20, 16, 22, 1, 11, 13, 24, 18, 15, 3, 16, 10, 18],\n",
              " [15, 21, 20, 16, 22, 1, 11, 13, 24, 18, 15, 3, 16, 10, 18, 21, 15, 0, 20, 20],\n",
              " [1, 11, 13, 24, 18, 15, 3, 16, 10, 18, 21, 15, 0, 20, 20, 0, 20, 21, 23, 18],\n",
              " [15, 3, 16, 10, 18, 21, 15, 0, 20, 20, 0, 20, 21, 23, 18, 20, 16, 6, 12, 0],\n",
              " [21, 15, 0, 20, 20, 0, 20, 21, 23, 18, 20, 16, 6, 12, 0, 20, 18, 26, 0, 15],\n",
              " [0, 20, 21, 23, 18, 20, 16, 6, 12, 0, 20, 18, 26, 0, 15, 13, 8, 16, 18, 20],\n",
              " [20, 16, 6, 12, 0, 20, 18, 26, 0, 15, 13, 8, 16, 18, 20, 16, 19, 11, 17, 1],\n",
              " [20, 18, 26, 0, 15, 13, 8, 16, 18, 20, 16, 19, 11, 17, 1, 0, 26, 16, 10, 18],\n",
              " [13, 8, 16, 18, 20, 16, 19, 11, 17, 1, 0, 26, 16, 10, 18, 21, 23, 16, 26, 18],\n",
              " [16, 19, 11, 17, 1, 0, 26, 16, 10, 18, 21, 23, 16, 26, 18, 20, 12, 0, 20, 6],\n",
              " [0, 26, 16, 10, 18, 21, 23, 16, 26, 18, 20, 12, 0, 20, 6, 0, 13, 21, 16, 19],\n",
              " [21, 23, 16, 26, 18, 20, 12, 0, 20, 6, 0, 13, 21, 16, 19, 11, 12, 16, 12, 17],\n",
              " [20, 12, 0, 20, 6, 0, 13, 21, 16, 19, 11, 12, 16, 12, 17, 1, 0, 20, 16, 22],\n",
              " [0, 13, 21, 16, 19, 11, 12, 16, 12, 17, 1, 0, 20, 16, 22, 11, 17, 15, 26, 14],\n",
              " [11, 12, 16, 12, 17, 1, 0, 20, 16, 22, 11, 17, 15, 26, 14, 12, 18, 0, 20, 16],\n",
              " [1, 0, 20, 16, 22, 11, 17, 15, 26, 14, 12, 18, 0, 20, 16, 14, 15, 26, 16, 15],\n",
              " [11,\n",
              "  17,\n",
              "  15,\n",
              "  26,\n",
              "  14,\n",
              "  12,\n",
              "  18,\n",
              "  0,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  20,\n",
              "  16],\n",
              " [12,\n",
              "  18,\n",
              "  0,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  20,\n",
              "  16,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  25,\n",
              "  6],\n",
              " [14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  20,\n",
              "  16,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  25,\n",
              "  6,\n",
              "  16,\n",
              "  10,\n",
              "  14,\n",
              "  1,\n",
              "  24],\n",
              " [11, 12, 25, 20, 16, 21, 12, 17, 25, 6, 16, 10, 14, 1, 24, 0, 26, 16, 14, 10],\n",
              " [21, 12, 17, 25, 6, 16, 10, 14, 1, 24, 0, 26, 16, 14, 10, 14, 8, 16, 19, 12],\n",
              " [16, 10, 14, 1, 24, 0, 26, 16, 14, 10, 14, 8, 16, 19, 12, 11, 25, 16, 25, 14],\n",
              " [0, 26, 16, 14, 10, 14, 8, 16, 19, 12, 11, 25, 16, 25, 14, 4, 11, 12, 16, 14],\n",
              " [14, 8, 16, 19, 12, 11, 25, 16, 25, 14, 4, 11, 12, 16, 14, 3, 12, 0, 0, 25],\n",
              " [11, 25, 16, 25, 14, 4, 11, 12, 16, 14, 3, 12, 0, 0, 25, 0, 15, 21, 20, 16],\n",
              " [4, 11, 12, 16, 14, 3, 12, 0, 0, 25, 0, 15, 21, 20, 16, 15, 0, 3, 11, 21],\n",
              " [3, 12, 0, 0, 25, 0, 15, 21, 20, 16, 15, 0, 3, 11, 21, 18, 14, 21, 0, 26],\n",
              " [0, 15, 21, 20, 16, 15, 0, 3, 11, 21, 18, 14, 21, 0, 26, 16, 22, 8, 16, 23],\n",
              " [15, 0, 3, 11, 21, 18, 14, 21, 0, 26, 16, 22, 8, 16, 23, 18, 20, 16, 6, 12],\n",
              " [18, 14, 21, 0, 26, 16, 22, 8, 16, 23, 18, 20, 16, 6, 12, 0, 26, 0, 13, 0],\n",
              " [16, 22, 8, 16, 23, 18, 20, 16, 6, 12, 0, 26, 0, 13, 0, 20, 20, 11, 12, 20],\n",
              " [18, 20, 16, 6, 12, 0, 26, 0, 13, 0, 20, 20, 11, 12, 20, 21, 23, 0, 16, 18],\n",
              " [0, 26, 0, 13, 0, 20, 20, 11, 12, 20, 21, 23, 0, 16, 18, 12, 14, 15, 16, 15],\n",
              " [20, 20, 11, 12, 20, 21, 23, 0, 16, 18, 12, 14, 15, 16, 15, 17, 13, 1, 0, 14],\n",
              " [21, 23, 0, 16, 18, 12, 14, 15, 16, 15, 17, 13, 1, 0, 14, 12, 16, 26, 0, 14],\n",
              " [12, 14, 15, 16, 15, 17, 13, 1, 0, 14, 12, 16, 26, 0, 14, 1, 16, 21, 23, 0],\n",
              " [17, 13, 1, 0, 14, 12, 16, 26, 0, 14, 1, 16, 21, 23, 0, 16, 6, 14, 12, 18],\n",
              " [12, 16, 26, 0, 14, 1, 16, 21, 23, 0, 16, 6, 14, 12, 18, 20, 16, 13, 1, 18],\n",
              " [1, 16, 21, 23, 0, 16, 6, 14, 12, 18, 20, 16, 13, 1, 18, 25, 14, 21, 0, 16],\n",
              " [16, 6, 14, 12, 18, 20, 16, 13, 1, 18, 25, 14, 21, 0, 16, 14, 13, 13, 11, 12],\n",
              " [20,\n",
              "  16,\n",
              "  13,\n",
              "  1,\n",
              "  18,\n",
              "  25,\n",
              "  14,\n",
              "  21,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  13,\n",
              "  13,\n",
              "  11,\n",
              "  12,\n",
              "  26,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16],\n",
              " [25,\n",
              "  14,\n",
              "  21,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  13,\n",
              "  13,\n",
              "  11,\n",
              "  12,\n",
              "  26,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  17],\n",
              " [14,\n",
              "  13,\n",
              "  13,\n",
              "  11,\n",
              "  12,\n",
              "  26,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  17,\n",
              "  15,\n",
              "  18,\n",
              "  21,\n",
              "  0,\n",
              "  26],\n",
              " [26,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  17,\n",
              "  15,\n",
              "  18,\n",
              "  21,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  21],\n",
              " [21, 23, 0, 16, 17, 15, 18, 21, 0, 26, 16, 20, 21, 14, 21, 0, 20, 16, 10, 11],\n",
              " [15,\n",
              "  18,\n",
              "  21,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  21,\n",
              "  0,\n",
              "  20,\n",
              "  16,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  26,\n",
              "  16,\n",
              "  14,\n",
              "  20],\n",
              " [16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  21,\n",
              "  0,\n",
              "  20,\n",
              "  16,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  26,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  22,\n",
              "  11,\n",
              "  15,\n",
              "  26],\n",
              " [0,\n",
              "  20,\n",
              "  16,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  26,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  22,\n",
              "  11,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  15],\n",
              " [12,\n",
              "  26,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  22,\n",
              "  11,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  12],\n",
              " [16,\n",
              "  22,\n",
              "  11,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  1,\n",
              "  11,\n",
              "  11],\n",
              " [16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  1,\n",
              "  11,\n",
              "  11,\n",
              "  24,\n",
              "  16,\n",
              "  14,\n",
              "  21,\n",
              "  16],\n",
              " [11, 16, 25, 11, 12, 0, 16, 1, 11, 11, 24, 16, 14, 21, 16, 21, 23, 0, 16, 0],\n",
              " [0, 16, 1, 11, 11, 24, 16, 14, 21, 16, 21, 23, 0, 16, 0, 14, 20, 0, 16, 10],\n",
              " [24, 16, 14, 21, 16, 21, 23, 0, 16, 0, 14, 20, 0, 16, 10, 18, 21, 23, 16, 10],\n",
              " [21, 23, 0, 16, 0, 14, 20, 0, 16, 10, 18, 21, 23, 16, 10, 23, 18, 13, 23, 16],\n",
              " [14,\n",
              "  20,\n",
              "  0,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  10,\n",
              "  23,\n",
              "  18,\n",
              "  13,\n",
              "  23,\n",
              "  16,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  26,\n",
              "  18],\n",
              " [18,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  10,\n",
              "  23,\n",
              "  18,\n",
              "  13,\n",
              "  23,\n",
              "  16,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  20,\n",
              "  13,\n",
              "  14,\n",
              "  12,\n",
              "  26],\n",
              " [23,\n",
              "  18,\n",
              "  13,\n",
              "  23,\n",
              "  16,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  20,\n",
              "  13,\n",
              "  14,\n",
              "  12,\n",
              "  26,\n",
              "  20,\n",
              "  16,\n",
              "  20,\n",
              "  17,\n",
              "  6],\n",
              " [23, 0, 16, 26, 18, 20, 13, 14, 12, 26, 20, 16, 20, 17, 6, 6, 11, 12, 21, 0],\n",
              " [20, 13, 14, 12, 26, 20, 16, 20, 17, 6, 6, 11, 12, 21, 0, 12, 20, 14, 20, 24],\n",
              " [20, 16, 20, 17, 6, 6, 11, 12, 21, 0, 12, 20, 14, 20, 24, 16, 19, 11, 12, 25],\n",
              " [6, 11, 12, 21, 0, 12, 20, 14, 20, 24, 16, 19, 11, 12, 25, 0, 12, 16, 14, 21],\n",
              " [12,\n",
              "  20,\n",
              "  14,\n",
              "  20,\n",
              "  24,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  0,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  21,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  15,\n",
              "  0],\n",
              " [16, 19, 11, 12, 25, 0, 12, 16, 14, 21, 21, 11, 12, 15, 0, 8, 16, 3, 0, 15],\n",
              " [0, 12, 16, 14, 21, 21, 11, 12, 15, 0, 8, 16, 3, 0, 15, 0, 12, 14, 1, 16],\n",
              " [21, 11, 12, 15, 0, 8, 16, 3, 0, 15, 0, 12, 14, 1, 16, 4, 0, 19, 19, 16],\n",
              " [8, 16, 3, 0, 15, 0, 12, 14, 1, 16, 4, 0, 19, 19, 16, 20, 0, 20, 20, 18],\n",
              " [0, 12, 14, 1, 16, 4, 0, 19, 19, 16, 20, 0, 20, 20, 18, 11, 15, 20, 16, 11],\n",
              " [4, 0, 19, 19, 16, 20, 0, 20, 20, 18, 11, 15, 20, 16, 11, 12, 16, 19, 11, 12],\n",
              " [20,\n",
              "  0,\n",
              "  20,\n",
              "  20,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  0,\n",
              "  12,\n",
              "  16,\n",
              "  20],\n",
              " [11, 15, 20, 16, 11, 12, 16, 19, 11, 12, 25, 0, 12, 16, 20, 0, 13, 12, 0, 21],\n",
              " [12, 16, 19, 11, 12, 25, 0, 12, 16, 20, 0, 13, 12, 0, 21, 14, 12, 8, 16, 11],\n",
              " [25, 0, 12, 16, 20, 0, 13, 12, 0, 21, 14, 12, 8, 16, 11, 19, 16, 20, 21, 14],\n",
              " [0, 13, 12, 0, 21, 14, 12, 8, 16, 11, 19, 16, 20, 21, 14, 21, 0, 16, 12, 0],\n",
              " [14, 12, 8, 16, 11, 19, 16, 20, 21, 14, 21, 0, 16, 12, 0, 9, 16, 21, 18, 1],\n",
              " [19, 16, 20, 21, 14, 21, 0, 16, 12, 0, 9, 16, 21, 18, 1, 1, 0, 12, 20, 11],\n",
              " [21, 0, 16, 12, 0, 9, 16, 21, 18, 1, 1, 0, 12, 20, 11, 15, 16, 14, 20, 24],\n",
              " [9, 16, 21, 18, 1, 1, 0, 12, 20, 11, 15, 16, 14, 20, 24, 16, 11, 17, 12, 16],\n",
              " [1, 0, 12, 20, 11, 15, 16, 14, 20, 24, 16, 11, 17, 12, 16, 14, 1, 1, 18, 0],\n",
              " [15, 16, 14, 20, 24, 16, 11, 17, 12, 16, 14, 1, 1, 18, 0, 20, 16, 23, 0, 12],\n",
              " [16, 11, 17, 12, 16, 14, 1, 1, 18, 0, 20, 16, 23, 0, 12, 0, 16, 21, 11, 26],\n",
              " [14, 1, 1, 18, 0, 20, 16, 23, 0, 12, 0, 16, 21, 11, 26, 14, 8, 16, 3, 11],\n",
              " [20, 16, 23, 0, 12, 0, 16, 21, 11, 26, 14, 8, 16, 3, 11, 15, 0, 16, 21, 11],\n",
              " [0, 16, 21, 11, 26, 14, 8, 16, 3, 11, 15, 0, 16, 21, 11, 25, 11, 12, 12, 11],\n",
              " [14, 8, 16, 3, 11, 15, 0, 16, 21, 11, 25, 11, 12, 12, 11, 10, 15, 14, 21, 11],\n",
              " [15,\n",
              "  0,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  25,\n",
              "  11,\n",
              "  12,\n",
              "  12,\n",
              "  11,\n",
              "  10,\n",
              "  15,\n",
              "  14,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16],\n",
              " [25,\n",
              "  11,\n",
              "  12,\n",
              "  12,\n",
              "  11,\n",
              "  10,\n",
              "  15,\n",
              "  14,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  24,\n",
              "  17,\n",
              "  12,\n",
              "  26,\n",
              "  20],\n",
              " [10,\n",
              "  15,\n",
              "  14,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  24,\n",
              "  17,\n",
              "  12,\n",
              "  26,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  20],\n",
              " [16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  24,\n",
              "  17,\n",
              "  12,\n",
              "  26,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  20,\n",
              "  8,\n",
              "  12,\n",
              "  18,\n",
              "  14,\n",
              "  19],\n",
              " [24,\n",
              "  17,\n",
              "  12,\n",
              "  26,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  20,\n",
              "  8,\n",
              "  12,\n",
              "  18,\n",
              "  14,\n",
              "  19,\n",
              "  12,\n",
              "  11,\n",
              "  25,\n",
              "  16,\n",
              "  23],\n",
              " [16,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  20,\n",
              "  8,\n",
              "  12,\n",
              "  18,\n",
              "  14,\n",
              "  19,\n",
              "  12,\n",
              "  11,\n",
              "  25,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  0,\n",
              "  14],\n",
              " [8, 12, 18, 14, 19, 12, 11, 25, 16, 23, 18, 20, 16, 0, 14, 12, 1, 18, 0, 20],\n",
              " [12, 11, 25, 16, 23, 18, 20, 16, 0, 14, 12, 1, 18, 0, 20, 21, 16, 26, 14, 8],\n",
              " [18, 20, 16, 0, 14, 12, 1, 18, 0, 20, 21, 16, 26, 14, 8, 20, 16, 14, 20, 16],\n",
              " [12, 1, 18, 0, 20, 21, 16, 26, 14, 8, 20, 16, 14, 20, 16, 14, 16, 13, 14, 15],\n",
              " [21,\n",
              "  16,\n",
              "  26,\n",
              "  14,\n",
              "  8,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  18,\n",
              "  26,\n",
              "  14,\n",
              "  21],\n",
              " [20,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  18,\n",
              "  26,\n",
              "  14,\n",
              "  21,\n",
              "  0,\n",
              "  16,\n",
              "  21,\n",
              "  12,\n",
              "  17],\n",
              " [14, 16, 13, 14, 15, 26, 18, 26, 14, 21, 0, 16, 21, 12, 17, 25, 6, 16, 2, 11],\n",
              " [26, 18, 26, 14, 21, 0, 16, 21, 12, 17, 25, 6, 16, 2, 11, 18, 13, 0, 26, 16],\n",
              " [0, 16, 21, 12, 17, 25, 6, 16, 2, 11, 18, 13, 0, 26, 16, 14, 6, 6, 14, 1],\n",
              " [25, 6, 16, 2, 11, 18, 13, 0, 26, 16, 14, 6, 6, 14, 1, 1, 18, 15, 3, 1],\n",
              " [18, 13, 0, 26, 16, 14, 6, 6, 14, 1, 1, 18, 15, 3, 1, 8, 16, 14, 12, 12],\n",
              " [14, 6, 6, 14, 1, 1, 18, 15, 3, 1, 8, 16, 14, 12, 12, 11, 3, 14, 15, 21],\n",
              " [1, 18, 15, 3, 1, 8, 16, 14, 12, 12, 11, 3, 14, 15, 21, 16, 2, 18, 0, 10],\n",
              " [8, 16, 14, 12, 12, 11, 3, 14, 15, 21, 16, 2, 18, 0, 10, 20, 16, 14, 22, 11],\n",
              " [11, 3, 14, 15, 21, 16, 2, 18, 0, 10, 20, 16, 14, 22, 11, 17, 21, 16, 21, 23],\n",
              " [16, 2, 18, 0, 10, 20, 16, 14, 22, 11, 17, 21, 16, 21, 23, 0, 16, 6, 11, 10],\n",
              " [20, 16, 14, 22, 11, 17, 21, 16, 21, 23, 0, 16, 6, 11, 10, 0, 12, 16, 11, 19],\n",
              " [17, 21, 16, 21, 23, 0, 16, 6, 11, 10, 0, 12, 16, 11, 19, 16, 21, 23, 0, 16],\n",
              " [0, 16, 6, 11, 10, 0, 12, 16, 11, 19, 16, 21, 23, 0, 16, 6, 12, 0, 20, 18],\n",
              " [0, 12, 16, 11, 19, 16, 21, 23, 0, 16, 6, 12, 0, 20, 18, 26, 0, 15, 13, 8],\n",
              " [16, 21, 23, 0, 16, 6, 12, 0, 20, 18, 26, 0, 15, 13, 8, 16, 25, 0, 9, 18],\n",
              " [6, 12, 0, 20, 18, 26, 0, 15, 13, 8, 16, 25, 0, 9, 18, 13, 11, 16, 10, 18],\n",
              " [26, 0, 15, 13, 8, 16, 25, 0, 9, 18, 13, 11, 16, 10, 18, 1, 1, 16, 6, 14],\n",
              " [16, 25, 0, 9, 18, 13, 11, 16, 10, 18, 1, 1, 16, 6, 14, 8, 16, 19, 11, 12],\n",
              " [13, 11, 16, 10, 18, 1, 1, 16, 6, 14, 8, 16, 19, 11, 12, 16, 21, 23, 0, 16],\n",
              " [1, 1, 16, 6, 14, 8, 16, 19, 11, 12, 16, 21, 23, 0, 16, 10, 14, 1, 1, 18],\n",
              " [8, 16, 19, 11, 12, 16, 21, 23, 0, 16, 10, 14, 1, 1, 18, 16, 14, 1, 11, 15],\n",
              " [16, 21, 23, 0, 16, 10, 14, 1, 1, 18, 16, 14, 1, 11, 15, 0, 16, 13, 14, 15],\n",
              " [10, 14, 1, 1, 18, 16, 14, 1, 11, 15, 0, 16, 13, 14, 15, 16, 19, 18, 9, 16],\n",
              " [16, 14, 1, 11, 15, 0, 16, 13, 14, 15, 16, 19, 18, 9, 16, 18, 21, 16, 25, 8],\n",
              " [0, 16, 13, 14, 15, 16, 19, 18, 9, 16, 18, 21, 16, 25, 8, 16, 6, 12, 18, 25],\n",
              " [16, 19, 18, 9, 16, 18, 21, 16, 25, 8, 16, 6, 12, 18, 25, 14, 12, 8, 16, 13],\n",
              " [18, 21, 16, 25, 8, 16, 6, 12, 18, 25, 14, 12, 8, 16, 13, 11, 15, 20, 17, 1],\n",
              " [16, 6, 12, 18, 25, 14, 12, 8, 16, 13, 11, 15, 20, 17, 1, 21, 14, 15, 21, 16],\n",
              " [14, 12, 8, 16, 13, 11, 15, 20, 17, 1, 21, 14, 15, 21, 16, 18, 20, 16, 25, 8],\n",
              " [11, 15, 20, 17, 1, 21, 14, 15, 21, 16, 18, 20, 16, 25, 8, 20, 0, 1, 19, 16],\n",
              " [21, 14, 15, 21, 16, 18, 20, 16, 25, 8, 20, 0, 1, 19, 16, 23, 18, 20, 16, 6],\n",
              " [18, 20, 16, 25, 8, 20, 0, 1, 19, 16, 23, 18, 20, 16, 6, 11, 20, 20, 0, 20],\n",
              " [20, 0, 1, 19, 16, 23, 18, 20, 16, 6, 11, 20, 20, 0, 20, 20, 18, 2, 0, 15],\n",
              " [23, 18, 20, 16, 6, 11, 20, 20, 0, 20, 20, 18, 2, 0, 15, 0, 20, 20, 16, 11],\n",
              " [11, 20, 20, 0, 20, 20, 18, 2, 0, 15, 0, 20, 20, 16, 11, 2, 0, 12, 16, 6],\n",
              " [20, 18, 2, 0, 15, 0, 20, 20, 16, 11, 2, 0, 12, 16, 6, 0, 11, 6, 1, 0],\n",
              " [0, 20, 20, 16, 11, 2, 0, 12, 16, 6, 0, 11, 6, 1, 0, 16, 14, 15, 26, 16],\n",
              " [2, 0, 12, 16, 6, 0, 11, 6, 1, 0, 16, 14, 15, 26, 16, 18, 15, 20, 21, 18],\n",
              " [0, 11, 6, 1, 0, 16, 14, 15, 26, 16, 18, 15, 20, 21, 18, 21, 17, 21, 18, 11],\n",
              " [16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  20,\n",
              "  21,\n",
              "  18,\n",
              "  21,\n",
              "  17,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  20],\n",
              " [18,\n",
              "  15,\n",
              "  20,\n",
              "  21,\n",
              "  18,\n",
              "  21,\n",
              "  17,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  1,\n",
              "  20,\n",
              "  11],\n",
              " [21,\n",
              "  17,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  1,\n",
              "  20,\n",
              "  11,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16],\n",
              " [15,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  1,\n",
              "  20,\n",
              "  11,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  15,\n",
              "  0,\n",
              "  10,\n",
              "  16,\n",
              "  25],\n",
              " [16, 14, 1, 20, 11, 16, 15, 11, 21, 16, 15, 0, 10, 16, 25, 8, 16, 3, 0, 15],\n",
              " [16, 15, 11, 21, 16, 15, 0, 10, 16, 25, 8, 16, 3, 0, 15, 0, 12, 14, 1, 20],\n",
              " [15, 0, 10, 16, 25, 8, 16, 3, 0, 15, 0, 12, 14, 1, 20, 16, 14, 15, 26, 16],\n",
              " [8, 16, 3, 0, 15, 0, 12, 14, 1, 20, 16, 14, 15, 26, 16, 25, 8, 16, 25, 18],\n",
              " [0, 12, 14, 1, 20, 16, 14, 15, 26, 16, 25, 8, 16, 25, 18, 1, 18, 21, 14, 12],\n",
              " [16, 14, 15, 26, 16, 25, 8, 16, 25, 18, 1, 18, 21, 14, 12, 8, 16, 25, 8, 16],\n",
              " [25, 8, 16, 25, 18, 1, 18, 21, 14, 12, 8, 16, 25, 8, 16, 14, 19, 12, 18, 13],\n",
              " [1, 18, 21, 14, 12, 8, 16, 25, 8, 16, 14, 19, 12, 18, 13, 14, 15, 16, 14, 25],\n",
              " [8, 16, 25, 8, 16, 14, 19, 12, 18, 13, 14, 15, 16, 14, 25, 0, 12, 18, 13, 14],\n",
              " [14, 19, 12, 18, 13, 14, 15, 16, 14, 25, 0, 12, 18, 13, 14, 15, 11, 15, 1, 8],\n",
              " [14, 15, 16, 14, 25, 0, 12, 18, 13, 14, 15, 11, 15, 1, 8, 16, 25, 11, 15, 21],\n",
              " [0, 12, 18, 13, 14, 15, 11, 15, 1, 8, 16, 25, 11, 15, 21, 23, 20, 16, 18, 15],\n",
              " [15,\n",
              "  11,\n",
              "  15,\n",
              "  1,\n",
              "  8,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  15,\n",
              "  21,\n",
              "  23,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  23,\n",
              "  18],\n",
              " [16,\n",
              "  25,\n",
              "  11,\n",
              "  15,\n",
              "  21,\n",
              "  23,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  6,\n",
              "  12,\n",
              "  0],\n",
              " [23, 20, 16, 18, 15, 21, 11, 16, 23, 18, 20, 16, 6, 12, 0, 20, 18, 26, 0, 15],\n",
              " [21, 11, 16, 23, 18, 20, 16, 6, 12, 0, 20, 18, 26, 0, 15, 13, 8, 16, 21, 12],\n",
              " [20, 16, 6, 12, 0, 20, 18, 26, 0, 15, 13, 8, 16, 21, 12, 17, 25, 6, 16, 26],\n",
              " [20, 18, 26, 0, 15, 13, 8, 16, 21, 12, 17, 25, 6, 16, 26, 18, 20, 6, 14, 12],\n",
              " [13, 8, 16, 21, 12, 17, 25, 6, 16, 26, 18, 20, 6, 14, 12, 14, 3, 0, 26, 16],\n",
              " [17, 25, 6, 16, 26, 18, 20, 6, 14, 12, 14, 3, 0, 26, 16, 26, 0, 25, 11, 13],\n",
              " [18, 20, 6, 14, 12, 14, 3, 0, 26, 16, 26, 0, 25, 11, 13, 12, 14, 21, 18, 13],\n",
              " [14, 3, 0, 26, 16, 26, 0, 25, 11, 13, 12, 14, 21, 18, 13, 16, 14, 1, 1, 18],\n",
              " [26, 0, 25, 11, 13, 12, 14, 21, 18, 13, 16, 14, 1, 1, 18, 0, 20, 16, 18, 15],\n",
              " [12, 14, 21, 18, 13, 16, 14, 1, 1, 18, 0, 20, 16, 18, 15, 13, 1, 17, 26, 18],\n",
              " [16, 14, 1, 1, 18, 0, 20, 16, 18, 15, 13, 1, 17, 26, 18, 15, 3, 16, 3, 0],\n",
              " [0, 20, 16, 18, 15, 13, 1, 17, 26, 18, 15, 3, 16, 3, 0, 12, 25, 14, 15, 8],\n",
              " [13, 1, 17, 26, 18, 15, 3, 16, 3, 0, 12, 25, 14, 15, 8, 20, 16, 14, 15, 3],\n",
              " [15, 3, 16, 3, 0, 12, 25, 14, 15, 8, 20, 16, 14, 15, 3, 0, 1, 14, 16, 25],\n",
              " [12, 25, 14, 15, 8, 20, 16, 14, 15, 3, 0, 1, 14, 16, 25, 0, 12, 24, 0, 1],\n",
              " [20, 16, 14, 15, 3, 0, 1, 14, 16, 25, 0, 12, 24, 0, 1, 16, 12, 17, 18, 15],\n",
              " [0, 1, 14, 16, 25, 0, 12, 24, 0, 1, 16, 12, 17, 18, 15, 18, 15, 3, 16, 3],\n",
              " [0, 12, 24, 0, 1, 16, 12, 17, 18, 15, 18, 15, 3, 16, 3, 0, 12, 25, 14, 15],\n",
              " [16, 12, 17, 18, 15, 18, 15, 3, 16, 3, 0, 12, 25, 14, 15, 8, 16, 14, 15, 26],\n",
              " [18, 15, 3, 16, 3, 0, 12, 25, 14, 15, 8, 16, 14, 15, 26, 16, 22, 12, 18, 21],\n",
              " [0,\n",
              "  12,\n",
              "  25,\n",
              "  14,\n",
              "  15,\n",
              "  8,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  22,\n",
              "  12,\n",
              "  18,\n",
              "  21,\n",
              "  14,\n",
              "  18,\n",
              "  15,\n",
              "  20,\n",
              "  16],\n",
              " [8, 16, 14, 15, 26, 16, 22, 12, 18, 21, 14, 18, 15, 20, 16, 21, 23, 0, 12, 0],\n",
              " [16,\n",
              "  22,\n",
              "  12,\n",
              "  18,\n",
              "  21,\n",
              "  14,\n",
              "  18,\n",
              "  15,\n",
              "  20,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  12,\n",
              "  0,\n",
              "  20,\n",
              "  14,\n",
              "  16,\n",
              "  25,\n",
              "  14],\n",
              " [14, 18, 15, 20, 16, 21, 23, 0, 12, 0, 20, 14, 16, 25, 14, 8, 16, 19, 11, 11],\n",
              " [21, 23, 0, 12, 0, 20, 14, 16, 25, 14, 8, 16, 19, 11, 11, 1, 18, 20, 23, 15],\n",
              " [20, 14, 16, 25, 14, 8, 16, 19, 11, 11, 1, 18, 20, 23, 15, 11, 21, 14, 22, 1],\n",
              " [8, 16, 19, 11, 11, 1, 18, 20, 23, 15, 11, 21, 14, 22, 1, 8, 16, 22, 11, 21],\n",
              " [1, 18, 20, 23, 15, 11, 21, 14, 22, 1, 8, 16, 22, 11, 21, 23, 16, 10, 11, 25],\n",
              " [11, 21, 14, 22, 1, 8, 16, 22, 11, 21, 23, 16, 10, 11, 25, 0, 15, 18, 15, 16],\n",
              " [8, 16, 22, 11, 21, 23, 16, 10, 11, 25, 0, 15, 18, 15, 16, 19, 14, 2, 11, 12],\n",
              " [23,\n",
              "  16,\n",
              "  10,\n",
              "  11,\n",
              "  25,\n",
              "  0,\n",
              "  15,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  19,\n",
              "  14,\n",
              "  2,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  20],\n",
              " [0, 15, 18, 15, 16, 19, 14, 2, 11, 12, 16, 11, 19, 16, 20, 21, 12, 11, 15, 3],\n",
              " [19, 14, 2, 11, 12, 16, 11, 19, 16, 20, 21, 12, 11, 15, 3, 14, 12, 25, 16, 1],\n",
              " [16, 11, 19, 16, 20, 21, 12, 11, 15, 3, 14, 12, 25, 16, 1, 0, 14, 26, 0, 12],\n",
              " [21, 12, 11, 15, 3, 14, 12, 25, 16, 1, 0, 14, 26, 0, 12, 20, 16, 20, 17, 13],\n",
              " [14, 12, 25, 16, 1, 0, 14, 26, 0, 12, 20, 16, 20, 17, 13, 23, 16, 14, 20, 16],\n",
              " [0,\n",
              "  14,\n",
              "  26,\n",
              "  0,\n",
              "  12,\n",
              "  20,\n",
              "  16,\n",
              "  20,\n",
              "  17,\n",
              "  13,\n",
              "  23,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  21,\n",
              "  23],\n",
              " [20,\n",
              "  16,\n",
              "  20,\n",
              "  17,\n",
              "  13,\n",
              "  23,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  24,\n",
              "  11,\n",
              "  12,\n",
              "  0],\n",
              " [23,\n",
              "  16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  24,\n",
              "  11,\n",
              "  12,\n",
              "  0,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  24,\n",
              "  18],\n",
              " [15,\n",
              "  11,\n",
              "  12,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  24,\n",
              "  11,\n",
              "  12,\n",
              "  0,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  24,\n",
              "  18,\n",
              "  25,\n",
              "  16,\n",
              "  4,\n",
              "  11,\n",
              "  15],\n",
              " [16, 24, 11, 12, 0, 14, 20, 16, 24, 18, 25, 16, 4, 11, 15, 3, 16, 17, 15, 16],\n",
              " [14,\n",
              "  20,\n",
              "  16,\n",
              "  24,\n",
              "  18,\n",
              "  25,\n",
              "  16,\n",
              "  4,\n",
              "  11,\n",
              "  15,\n",
              "  3,\n",
              "  16,\n",
              "  17,\n",
              "  15,\n",
              "  16,\n",
              "  10,\n",
              "  23,\n",
              "  11,\n",
              "  16,\n",
              "  10],\n",
              " [25, 16, 4, 11, 15, 3, 16, 17, 15, 16, 10, 23, 11, 16, 10, 12, 11, 21, 0, 16],\n",
              " [3,\n",
              "  16,\n",
              "  17,\n",
              "  15,\n",
              "  16,\n",
              "  10,\n",
              "  23,\n",
              "  11,\n",
              "  16,\n",
              "  10,\n",
              "  12,\n",
              "  11,\n",
              "  21,\n",
              "  0,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  25,\n",
              "  16,\n",
              "  22],\n",
              " [10,\n",
              "  23,\n",
              "  11,\n",
              "  16,\n",
              "  10,\n",
              "  12,\n",
              "  11,\n",
              "  21,\n",
              "  0,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  25,\n",
              "  16,\n",
              "  22,\n",
              "  0,\n",
              "  14,\n",
              "  17,\n",
              "  21,\n",
              "  18],\n",
              " [12, 11, 21, 0, 16, 23, 18, 25, 16, 22, 0, 14, 17, 21, 18, 19, 17, 1, 16, 1],\n",
              " [23, 18, 25, 16, 22, 0, 14, 17, 21, 18, 19, 17, 1, 16, 1, 0, 21, 21, 0, 12],\n",
              " [0, 14, 17, 21, 18, 19, 17, 1, 16, 1, 0, 21, 21, 0, 12, 20, 16, 20, 14, 17],\n",
              " [19, 17, 1, 16, 1, 0, 21, 21, 0, 12, 20, 16, 20, 14, 17, 26, 18, 16, 14, 12],\n",
              " [0,\n",
              "  21,\n",
              "  21,\n",
              "  0,\n",
              "  12,\n",
              "  20,\n",
              "  16,\n",
              "  20,\n",
              "  14,\n",
              "  17,\n",
              "  26,\n",
              "  18,\n",
              "  16,\n",
              "  14,\n",
              "  12,\n",
              "  14,\n",
              "  22,\n",
              "  18,\n",
              "  14,\n",
              "  20],\n",
              " [20,\n",
              "  16,\n",
              "  20,\n",
              "  14,\n",
              "  17,\n",
              "  26,\n",
              "  18,\n",
              "  16,\n",
              "  14,\n",
              "  12,\n",
              "  14,\n",
              "  22,\n",
              "  18,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  23,\n",
              "  14],\n",
              " [26,\n",
              "  18,\n",
              "  16,\n",
              "  14,\n",
              "  12,\n",
              "  14,\n",
              "  22,\n",
              "  18,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  23,\n",
              "  14,\n",
              "  25,\n",
              "  25,\n",
              "  0,\n",
              "  26,\n",
              "  16],\n",
              " [14,\n",
              "  22,\n",
              "  18,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  23,\n",
              "  14,\n",
              "  25,\n",
              "  25,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  22,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  20],\n",
              " [16,\n",
              "  25,\n",
              "  11,\n",
              "  23,\n",
              "  14,\n",
              "  25,\n",
              "  25,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  22,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  20,\n",
              "  14,\n",
              "  1,\n",
              "  25,\n",
              "  14,\n",
              "  15],\n",
              " [25, 25, 0, 26, 16, 22, 18, 15, 16, 20, 14, 1, 25, 14, 15, 16, 2, 0, 12, 8],\n",
              " [22, 18, 15, 16, 20, 14, 1, 25, 14, 15, 16, 2, 0, 12, 8, 16, 3, 11, 11, 26],\n",
              " [14, 1, 25, 14, 15, 16, 2, 0, 12, 8, 16, 3, 11, 11, 26, 16, 14, 1, 1, 8],\n",
              " [16, 2, 0, 12, 8, 16, 3, 11, 11, 26, 16, 14, 1, 1, 8, 16, 21, 17, 12, 24],\n",
              " [16, 3, 11, 11, 26, 16, 14, 1, 1, 8, 16, 21, 17, 12, 24, 0, 8, 20, 16, 12],\n",
              " [16, 14, 1, 1, 8, 16, 21, 17, 12, 24, 0, 8, 20, 16, 12, 0, 13, 0, 6, 16],\n",
              " [16, 21, 17, 12, 24, 0, 8, 20, 16, 12, 0, 13, 0, 6, 16, 21, 14, 8, 8, 18],\n",
              " [0, 8, 20, 16, 12, 0, 13, 0, 6, 16, 21, 14, 8, 8, 18, 6, 16, 0, 12, 26],\n",
              " [0, 13, 0, 6, 16, 21, 14, 8, 8, 18, 6, 16, 0, 12, 26, 11, 3, 14, 15, 16],\n",
              " [21, 14, 8, 8, 18, 6, 16, 0, 12, 26, 11, 3, 14, 15, 16, 3, 12, 0, 14, 21],\n",
              " [6, 16, 0, 12, 26, 11, 3, 14, 15, 16, 3, 12, 0, 14, 21, 16, 19, 12, 18, 0],\n",
              " [11, 3, 14, 15, 16, 3, 12, 0, 14, 21, 16, 19, 12, 18, 0, 15, 26, 20, 23, 18],\n",
              " [3, 12, 0, 14, 21, 16, 19, 12, 18, 0, 15, 26, 20, 23, 18, 6, 16, 14, 15, 26],\n",
              " [16, 19, 12, 18, 0, 15, 26, 20, 23, 18, 6, 16, 14, 15, 26, 16, 21, 23, 0, 16],\n",
              " [15, 26, 20, 23, 18, 6, 16, 14, 15, 26, 16, 21, 23, 0, 16, 6, 23, 18, 1, 18],\n",
              " [6, 16, 14, 15, 26, 16, 21, 23, 0, 16, 6, 23, 18, 1, 18, 6, 6, 18, 15, 0],\n",
              " [16, 21, 23, 0, 16, 6, 23, 18, 1, 18, 6, 6, 18, 15, 0, 20, 16, 12, 11, 26],\n",
              " [6, 23, 18, 1, 18, 6, 6, 18, 15, 0, 20, 16, 12, 11, 26, 12, 18, 3, 11, 16],\n",
              " [6, 6, 18, 15, 0, 20, 16, 12, 11, 26, 12, 18, 3, 11, 16, 26, 17, 21, 0, 12],\n",
              " [20, 16, 12, 11, 26, 12, 18, 3, 11, 16, 26, 17, 21, 0, 12, 21, 0, 16, 3, 12],\n",
              " [12, 18, 3, 11, 16, 26, 17, 21, 0, 12, 21, 0, 16, 3, 12, 0, 14, 21, 16, 12],\n",
              " [26, 17, 21, 0, 12, 21, 0, 16, 3, 12, 0, 14, 21, 16, 12, 0, 1, 14, 21, 18],\n",
              " [21, 0, 16, 3, 12, 0, 14, 21, 16, 12, 0, 1, 14, 21, 18, 11, 15, 20, 23, 18],\n",
              " [0, 14, 21, 16, 12, 0, 1, 14, 21, 18, 11, 15, 20, 23, 18, 6, 16, 21, 12, 17],\n",
              " [0, 1, 14, 21, 18, 11, 15, 20, 23, 18, 6, 16, 21, 12, 17, 25, 6, 16, 23, 0],\n",
              " [11, 15, 20, 23, 18, 6, 16, 21, 12, 17, 25, 6, 16, 23, 0, 14, 6, 20, 16, 6],\n",
              " [6, 16, 21, 12, 17, 25, 6, 16, 23, 0, 14, 6, 20, 16, 6, 12, 14, 18, 20, 0],\n",
              " [25, 6, 16, 23, 0, 14, 6, 20, 16, 6, 12, 14, 18, 20, 0, 16, 11, 15, 16, 12],\n",
              " [14, 6, 20, 16, 6, 12, 14, 18, 20, 0, 16, 11, 15, 16, 12, 17, 20, 20, 18, 14],\n",
              " [12, 14, 18, 20, 0, 16, 11, 15, 16, 12, 17, 20, 20, 18, 14, 20, 16, 2, 1, 14],\n",
              " [16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  12,\n",
              "  17,\n",
              "  20,\n",
              "  20,\n",
              "  18,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  2,\n",
              "  1,\n",
              "  14,\n",
              "  26,\n",
              "  18,\n",
              "  25,\n",
              "  18,\n",
              "  12],\n",
              " [17, 20, 20, 18, 14, 20, 16, 2, 1, 14, 26, 18, 25, 18, 12, 16, 6, 17, 21, 18],\n",
              " [20, 16, 2, 1, 14, 26, 18, 25, 18, 12, 16, 6, 17, 21, 18, 15, 16, 23, 0, 20],\n",
              " [26,\n",
              "  18,\n",
              "  25,\n",
              "  18,\n",
              "  12,\n",
              "  16,\n",
              "  6,\n",
              "  17,\n",
              "  21,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  23,\n",
              "  0,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  20,\n",
              "  21],\n",
              " [16, 6, 17, 21, 18, 15, 16, 23, 0, 20, 16, 14, 16, 20, 21, 12, 11, 15, 3, 16],\n",
              " [15, 16, 23, 0, 20, 16, 14, 16, 20, 21, 12, 11, 15, 3, 16, 1, 0, 14, 26, 0],\n",
              " [16, 14, 16, 20, 21, 12, 11, 15, 3, 16, 1, 0, 14, 26, 0, 12, 16, 14, 15, 26],\n",
              " [12, 11, 15, 3, 16, 1, 0, 14, 26, 0, 12, 16, 14, 15, 26, 16, 26, 14, 8, 20],\n",
              " [1, 0, 14, 26, 0, 12, 16, 14, 15, 26, 16, 26, 14, 8, 20, 16, 14, 19, 21, 0],\n",
              " [12, 16, 14, 15, 26, 16, 26, 14, 8, 20, 16, 14, 19, 21, 0, 12, 16, 12, 0, 2],\n",
              " [16, 26, 14, 8, 20, 16, 14, 19, 21, 0, 12, 16, 12, 0, 2, 0, 14, 1, 18, 15],\n",
              " [16, 14, 19, 21, 0, 12, 16, 12, 0, 2, 0, 14, 1, 18, 15, 3, 16, 23, 18, 20],\n",
              " [12, 16, 12, 0, 2, 0, 14, 1, 18, 15, 3, 16, 23, 18, 20, 16, 10, 11, 12, 26],\n",
              " [0, 14, 1, 18, 15, 3, 16, 23, 18, 20, 16, 10, 11, 12, 26, 20, 16, 6, 12, 0],\n",
              " [3, 16, 23, 18, 20, 16, 10, 11, 12, 26, 20, 16, 6, 12, 0, 20, 20, 17, 12, 18],\n",
              " [16, 10, 11, 12, 26, 20, 16, 6, 12, 0, 20, 20, 17, 12, 18, 15, 3, 16, 17, 24],\n",
              " [20, 16, 6, 12, 0, 20, 20, 17, 12, 18, 15, 3, 16, 17, 24, 12, 14, 18, 15, 18],\n",
              " [20,\n",
              "  20,\n",
              "  17,\n",
              "  12,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  16,\n",
              "  17,\n",
              "  24,\n",
              "  12,\n",
              "  14,\n",
              "  18,\n",
              "  15,\n",
              "  18,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  6,\n",
              "  12],\n",
              " [15, 3, 16, 17, 24, 12, 14, 18, 15, 18, 14, 15, 16, 6, 12, 0, 20, 18, 26, 0],\n",
              " [12, 14, 18, 15, 18, 14, 15, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 16, 2, 11],\n",
              " [14, 15, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 16, 2, 11, 1, 11, 26, 8, 25],\n",
              " [0, 20, 18, 26, 0, 15, 21, 16, 2, 11, 1, 11, 26, 8, 25, 8, 12, 16, 7, 0],\n",
              " [15, 21, 16, 2, 11, 1, 11, 26, 8, 25, 8, 12, 16, 7, 0, 1, 0, 15, 20, 24],\n",
              " [1, 11, 26, 8, 25, 8, 12, 16, 7, 0, 1, 0, 15, 20, 24, 8, 16, 21, 11, 16],\n",
              " [8, 12, 16, 7, 0, 1, 0, 15, 20, 24, 8, 16, 21, 11, 16, 26, 18, 3, 16, 17],\n",
              " [1, 0, 15, 20, 24, 8, 16, 21, 11, 16, 26, 18, 3, 16, 17, 6, 16, 26, 18, 12],\n",
              " [8, 16, 21, 11, 16, 26, 18, 3, 16, 17, 6, 16, 26, 18, 12, 21, 16, 11, 15, 16],\n",
              " [26,\n",
              "  18,\n",
              "  3,\n",
              "  16,\n",
              "  17,\n",
              "  6,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  12,\n",
              "  21,\n",
              "  16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  11],\n",
              " [6, 16, 26, 18, 12, 21, 16, 11, 15, 16, 23, 18, 20, 16, 11, 6, 6, 11, 15, 0],\n",
              " [21, 16, 11, 15, 16, 23, 18, 20, 16, 11, 6, 6, 11, 15, 0, 15, 21, 16, 23, 0],\n",
              " [23, 18, 20, 16, 11, 6, 6, 11, 15, 0, 15, 21, 16, 23, 0, 16, 18, 15, 2, 18],\n",
              " [6, 6, 11, 15, 0, 15, 21, 16, 23, 0, 16, 18, 15, 2, 18, 21, 0, 26, 16, 13],\n",
              " [15, 21, 16, 23, 0, 16, 18, 15, 2, 18, 21, 0, 26, 16, 13, 23, 18, 15, 14, 16],\n",
              " [16,\n",
              "  18,\n",
              "  15,\n",
              "  2,\n",
              "  18,\n",
              "  21,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  13,\n",
              "  23,\n",
              "  18,\n",
              "  15,\n",
              "  14,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  26,\n",
              "  11],\n",
              " [21,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  13,\n",
              "  23,\n",
              "  18,\n",
              "  15,\n",
              "  14,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  16,\n",
              "  18,\n",
              "  21,\n",
              "  16,\n",
              "  21],\n",
              " [23,\n",
              "  18,\n",
              "  15,\n",
              "  14,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  16,\n",
              "  18,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  11,\n",
              "  21,\n",
              "  12,\n",
              "  17],\n",
              " [21,\n",
              "  11,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  16,\n",
              "  18,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  11,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  25,\n",
              "  6,\n",
              "  20,\n",
              "  16,\n",
              "  13],\n",
              " [16,\n",
              "  18,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  11,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  25,\n",
              "  6,\n",
              "  20,\n",
              "  16,\n",
              "  13,\n",
              "  14,\n",
              "  25,\n",
              "  6,\n",
              "  14,\n",
              "  18],\n",
              " [11, 11, 21, 12, 17, 25, 6, 20, 16, 13, 14, 25, 6, 14, 18, 3, 15, 16, 19, 11],\n",
              " [25, 6, 20, 16, 13, 14, 25, 6, 14, 18, 3, 15, 16, 19, 11, 12, 16, 21, 23, 0],\n",
              " [14, 25, 6, 14, 18, 3, 15, 16, 19, 11, 12, 16, 21, 23, 0, 16, 10, 23, 18, 21],\n",
              " [3, 15, 16, 19, 11, 12, 16, 21, 23, 0, 16, 10, 23, 18, 21, 0, 16, 23, 11, 17],\n",
              " [12, 16, 21, 23, 0, 16, 10, 23, 18, 21, 0, 16, 23, 11, 17, 20, 0, 16, 10, 14],\n",
              " [16,\n",
              "  10,\n",
              "  23,\n",
              "  18,\n",
              "  21,\n",
              "  0,\n",
              "  16,\n",
              "  23,\n",
              "  11,\n",
              "  17,\n",
              "  20,\n",
              "  0,\n",
              "  16,\n",
              "  10,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  12,\n",
              "  11,\n",
              "  21],\n",
              " [0, 16, 23, 11, 17, 20, 0, 16, 10, 14, 20, 16, 12, 11, 21, 21, 0, 15, 16, 19],\n",
              " [20,\n",
              "  0,\n",
              "  16,\n",
              "  10,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  12,\n",
              "  11,\n",
              "  21,\n",
              "  21,\n",
              "  0,\n",
              "  15,\n",
              "  16,\n",
              "  19,\n",
              "  12,\n",
              "  11,\n",
              "  25,\n",
              "  16,\n",
              "  21],\n",
              " [20, 16, 12, 11, 21, 21, 0, 15, 16, 19, 12, 11, 25, 16, 21, 23, 0, 16, 22, 0],\n",
              " [21, 0, 15, 16, 19, 12, 11, 25, 16, 21, 23, 0, 16, 22, 0, 3, 18, 15, 15, 18],\n",
              " [12, 11, 25, 16, 21, 23, 0, 16, 22, 0, 3, 18, 15, 15, 18, 15, 3, 16, 10, 0],\n",
              " [23, 0, 16, 22, 0, 3, 18, 15, 15, 18, 15, 3, 16, 10, 0, 16, 3, 1, 18, 25],\n",
              " [3, 18, 15, 15, 18, 15, 3, 16, 10, 0, 16, 3, 1, 18, 25, 6, 20, 0, 26, 16],\n",
              " [15, 3, 16, 10, 0, 16, 3, 1, 18, 25, 6, 20, 0, 26, 16, 18, 21, 20, 16, 26],\n",
              " [16, 3, 1, 18, 25, 6, 20, 0, 26, 16, 18, 21, 20, 16, 26, 0, 6, 21, 23, 20],\n",
              " [6, 20, 0, 26, 16, 18, 21, 20, 16, 26, 0, 6, 21, 23, 20, 16, 10, 23, 0, 15],\n",
              " [18, 21, 20, 16, 26, 0, 6, 21, 23, 20, 16, 10, 23, 0, 15, 16, 23, 18, 20, 16],\n",
              " [0, 6, 21, 23, 20, 16, 10, 23, 0, 15, 16, 23, 18, 20, 16, 1, 14, 10, 8, 0],\n",
              " [16, 10, 23, 0, 15, 16, 23, 18, 20, 16, 1, 14, 10, 8, 0, 12, 16, 25, 18, 13],\n",
              " [16, 23, 18, 20, 16, 1, 14, 10, 8, 0, 12, 16, 25, 18, 13, 23, 14, 0, 1, 16],\n",
              " [1, 14, 10, 8, 0, 12, 16, 25, 18, 13, 23, 14, 0, 1, 16, 13, 11, 23, 0, 15],\n",
              " [12, 16, 25, 18, 13, 23, 14, 0, 1, 16, 13, 11, 23, 0, 15, 16, 6, 1, 0, 14],\n",
              " [23, 14, 0, 1, 16, 13, 11, 23, 0, 15, 16, 6, 1, 0, 14, 26, 0, 26, 16, 3],\n",
              " [13, 11, 23, 0, 15, 16, 6, 1, 0, 14, 26, 0, 26, 16, 3, 17, 18, 1, 21, 8],\n",
              " [16, 6, 1, 0, 14, 26, 0, 26, 16, 3, 17, 18, 1, 21, 8, 16, 21, 11, 16, 13],\n",
              " [26, 0, 26, 16, 3, 17, 18, 1, 21, 8, 16, 21, 11, 16, 13, 14, 25, 6, 14, 18],\n",
              " [17, 18, 1, 21, 8, 16, 21, 11, 16, 13, 14, 25, 6, 14, 18, 3, 15, 16, 19, 18],\n",
              " [16, 21, 11, 16, 13, 14, 25, 6, 14, 18, 3, 15, 16, 19, 18, 15, 14, 15, 13, 0],\n",
              " [14, 25, 6, 14, 18, 3, 15, 16, 19, 18, 15, 14, 15, 13, 0, 16, 19, 0, 1, 11],\n",
              " [3, 15, 16, 19, 18, 15, 14, 15, 13, 0, 16, 19, 0, 1, 11, 15, 18, 0, 20, 16],\n",
              " [15, 14, 15, 13, 0, 16, 19, 0, 1, 11, 15, 18, 0, 20, 16, 14, 15, 26, 16, 18],\n",
              " [16, 19, 0, 1, 11, 15, 18, 0, 20, 16, 14, 15, 26, 16, 18, 26, 0, 15, 21, 18],\n",
              " [15, 18, 0, 20, 16, 14, 15, 26, 16, 18, 26, 0, 15, 21, 18, 19, 18, 0, 26, 16],\n",
              " [14, 15, 26, 16, 18, 26, 0, 15, 21, 18, 19, 18, 0, 26, 16, 21, 12, 17, 25, 6],\n",
              " [26, 0, 15, 21, 18, 19, 18, 0, 26, 16, 21, 12, 17, 25, 6, 16, 14, 20, 16, 18],\n",
              " [19, 18, 0, 26, 16, 21, 12, 17, 25, 6, 16, 14, 20, 16, 18, 15, 26, 18, 2, 18],\n",
              " [21, 12, 17, 25, 6, 16, 14, 20, 16, 18, 15, 26, 18, 2, 18, 26, 17, 14, 1, 18],\n",
              " [16,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  26,\n",
              "  18,\n",
              "  2,\n",
              "  18,\n",
              "  26,\n",
              "  17,\n",
              "  14,\n",
              "  1,\n",
              "  18,\n",
              "  15,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  13],\n",
              " [15, 26, 18, 2, 18, 26, 17, 14, 1, 18, 15, 16, 14, 16, 13, 11, 15, 20, 6, 18],\n",
              " [26, 17, 14, 1, 18, 15, 16, 14, 16, 13, 11, 15, 20, 6, 18, 12, 14, 13, 8, 16],\n",
              " [15, 16, 14, 16, 13, 11, 15, 20, 6, 18, 12, 14, 13, 8, 16, 21, 11, 16, 6, 14],\n",
              " [11, 15, 20, 6, 18, 12, 14, 13, 8, 16, 21, 11, 16, 6, 14, 8, 16, 11, 19, 19],\n",
              " [12, 14, 13, 8, 16, 21, 11, 16, 6, 14, 8, 16, 11, 19, 19, 16, 14, 15, 16, 14],\n",
              " [21, 11, 16, 6, 14, 8, 16, 11, 19, 19, 16, 14, 15, 16, 14, 26, 17, 1, 21, 19],\n",
              " [8, 16, 11, 19, 19, 16, 14, 15, 16, 14, 26, 17, 1, 21, 19, 18, 1, 25, 16, 20],\n",
              " [16,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  14,\n",
              "  26,\n",
              "  17,\n",
              "  1,\n",
              "  21,\n",
              "  19,\n",
              "  18,\n",
              "  1,\n",
              "  25,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  12,\n",
              "  16,\n",
              "  14],\n",
              " [26,\n",
              "  17,\n",
              "  1,\n",
              "  21,\n",
              "  19,\n",
              "  18,\n",
              "  1,\n",
              "  25,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  14,\n",
              "  16],\n",
              " [18,\n",
              "  1,\n",
              "  25,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  25,\n",
              "  0],\n",
              " [21, 14, 12, 16, 14, 15, 26, 16, 14, 16, 19, 11, 12, 25, 0, 12, 16, 6, 1, 14],\n",
              " [15, 26, 16, 14, 16, 19, 11, 12, 25, 0, 12, 16, 6, 1, 14, 8, 22, 11, 8, 16],\n",
              " [19, 11, 12, 25, 0, 12, 16, 6, 1, 14, 8, 22, 11, 8, 16, 25, 11, 26, 0, 1],\n",
              " [12, 16, 6, 1, 14, 8, 22, 11, 8, 16, 25, 11, 26, 0, 1, 16, 21, 11, 16, 20],\n",
              " [8, 22, 11, 8, 16, 25, 11, 26, 0, 1, 16, 21, 11, 16, 20, 18, 1, 0, 15, 13],\n",
              " [25, 11, 26, 0, 1, 16, 21, 11, 16, 20, 18, 1, 0, 15, 13, 0, 16, 21, 23, 0],\n",
              " [16, 21, 11, 16, 20, 18, 1, 0, 15, 13, 0, 16, 21, 23, 0, 25, 16, 26, 17, 12],\n",
              " [18, 1, 0, 15, 13, 0, 16, 21, 23, 0, 25, 16, 26, 17, 12, 18, 15, 3, 16, 21],\n",
              " [0, 16, 21, 23, 0, 25, 16, 26, 17, 12, 18, 15, 3, 16, 21, 23, 0, 16, 23, 0],\n",
              " [25, 16, 26, 17, 12, 18, 15, 3, 16, 21, 23, 0, 16, 23, 0, 18, 3, 23, 21, 16],\n",
              " [18, 15, 3, 16, 21, 23, 0, 16, 23, 0, 18, 3, 23, 21, 16, 11, 19, 16, 21, 23],\n",
              " [23, 0, 16, 23, 0, 18, 3, 23, 21, 16, 11, 19, 16, 21, 23, 0, 6, 12, 0, 20],\n",
              " [18, 3, 23, 21, 16, 11, 19, 16, 21, 23, 0, 6, 12, 0, 20, 18, 26, 0, 15, 21],\n",
              " [11, 19, 16, 21, 23, 0, 6, 12, 0, 20, 18, 26, 0, 15, 21, 18, 14, 1, 16, 13],\n",
              " [0, 6, 12, 0, 20, 18, 26, 0, 15, 21, 18, 14, 1, 16, 13, 14, 25, 6, 14, 18],\n",
              " [18, 26, 0, 15, 21, 18, 14, 1, 16, 13, 14, 25, 6, 14, 18, 3, 15, 16, 10, 0],\n",
              " [18, 14, 1, 16, 13, 14, 25, 6, 14, 18, 3, 15, 16, 10, 0, 16, 3, 11, 21, 16],\n",
              " [14, 25, 6, 14, 18, 3, 15, 16, 10, 0, 16, 3, 11, 21, 16, 0, 2, 0, 15, 16],\n",
              " [3, 15, 16, 10, 0, 16, 3, 11, 21, 16, 0, 2, 0, 15, 16, 25, 11, 12, 0, 16],\n",
              " [16, 3, 11, 21, 16, 0, 2, 0, 15, 16, 25, 11, 12, 0, 16, 0, 2, 18, 26, 0],\n",
              " [0, 2, 0, 15, 16, 25, 11, 12, 0, 16, 0, 2, 18, 26, 0, 15, 13, 0, 16, 11],\n",
              " [25, 11, 12, 0, 16, 0, 2, 18, 26, 0, 15, 13, 0, 16, 11, 19, 16, 21, 12, 17],\n",
              " [0, 2, 18, 26, 0, 15, 13, 0, 16, 11, 19, 16, 21, 12, 17, 25, 6, 20, 16, 26],\n",
              " [15, 13, 0, 16, 11, 19, 16, 21, 12, 17, 25, 6, 20, 16, 26, 0, 13, 0, 6, 21],\n",
              " [19, 16, 21, 12, 17, 25, 6, 20, 16, 26, 0, 13, 0, 6, 21, 18, 11, 15, 16, 18],\n",
              " [25, 6, 20, 16, 26, 0, 13, 0, 6, 21, 18, 11, 15, 16, 18, 15, 16, 21, 23, 0],\n",
              " [0, 13, 0, 6, 21, 18, 11, 15, 16, 18, 15, 16, 21, 23, 0, 16, 26, 0, 15, 20],\n",
              " [18, 11, 15, 16, 18, 15, 16, 21, 23, 0, 16, 26, 0, 15, 20, 0, 16, 12, 0, 6],\n",
              " [15, 16, 21, 23, 0, 16, 26, 0, 15, 20, 0, 16, 12, 0, 6, 11, 12, 21, 16, 6],\n",
              " [16, 26, 0, 15, 20, 0, 16, 12, 0, 6, 11, 12, 21, 16, 6, 12, 0, 6, 14, 12],\n",
              " [0, 16, 12, 0, 6, 11, 12, 21, 16, 6, 12, 0, 6, 14, 12, 0, 26, 16, 22, 8],\n",
              " [11, 12, 21, 16, 6, 12, 0, 6, 14, 12, 0, 26, 16, 22, 8, 16, 20, 6, 0, 13],\n",
              " [12, 0, 6, 14, 12, 0, 26, 16, 22, 8, 16, 20, 6, 0, 13, 18, 14, 1, 16, 13],\n",
              " [0, 26, 16, 22, 8, 16, 20, 6, 0, 13, 18, 14, 1, 16, 13, 11, 17, 15, 20, 0],\n",
              " [16, 20, 6, 0, 13, 18, 14, 1, 16, 13, 11, 17, 15, 20, 0, 1, 16, 12, 11, 22],\n",
              " [18, 14, 1, 16, 13, 11, 17, 15, 20, 0, 1, 16, 12, 11, 22, 0, 12, 21, 16, 20],\n",
              " [11, 17, 15, 20, 0, 1, 16, 12, 11, 22, 0, 12, 21, 16, 20, 16, 25, 17, 0, 1],\n",
              " [1, 16, 12, 11, 22, 0, 12, 21, 16, 20, 16, 25, 17, 0, 1, 1, 0, 12, 16, 18],\n",
              " [0, 12, 21, 16, 20, 16, 25, 17, 0, 1, 1, 0, 12, 16, 18, 18, 18, 16, 11, 15],\n",
              " [16, 25, 17, 0, 1, 1, 0, 12, 16, 18, 18, 18, 16, 11, 15, 16, 12, 17, 20, 20],\n",
              " [1,\n",
              "  0,\n",
              "  12,\n",
              "  16,\n",
              "  18,\n",
              "  18,\n",
              "  18,\n",
              "  16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  12,\n",
              "  17,\n",
              "  20,\n",
              "  20,\n",
              "  18,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  18],\n",
              " [18,\n",
              "  18,\n",
              "  16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  12,\n",
              "  17,\n",
              "  20,\n",
              "  20,\n",
              "  18,\n",
              "  14,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  21,\n",
              "  0,\n",
              "  12,\n",
              "  19],\n",
              " [16, 12, 17, 20, 20, 18, 14, 20, 16, 18, 15, 21, 0, 12, 19, 0, 12, 0, 15, 13],\n",
              " [18, 14, 20, 16, 18, 15, 21, 0, 12, 19, 0, 12, 0, 15, 13, 0, 16, 18, 15, 16],\n",
              " [15, 21, 0, 12, 19, 0, 12, 0, 15, 13, 0, 16, 18, 15, 16, 21, 23, 0, 0, 1],\n",
              " [0, 12, 0, 15, 13, 0, 16, 18, 15, 16, 21, 23, 0, 0, 1, 0, 13, 21, 18, 11],\n",
              " [0, 16, 18, 15, 16, 21, 23, 0, 0, 1, 0, 13, 21, 18, 11, 15, 16, 21, 11, 16],\n",
              " [21, 23, 0, 0, 1, 0, 13, 21, 18, 11, 15, 16, 21, 11, 16, 22, 0, 15, 0, 19],\n",
              " [0, 13, 21, 18, 11, 15, 16, 21, 11, 16, 22, 0, 15, 0, 19, 18, 21, 16, 21, 12],\n",
              " [15, 16, 21, 11, 16, 22, 0, 15, 0, 19, 18, 21, 16, 21, 12, 17, 25, 6, 16, 14],\n",
              " [22, 0, 15, 0, 19, 18, 21, 16, 21, 12, 17, 25, 6, 16, 14, 15, 26, 16, 21, 12],\n",
              " [18,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  25,\n",
              "  6,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  12,\n",
              "  8,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16],\n",
              " [17, 25, 6, 16, 14, 15, 26, 16, 21, 12, 8, 16, 21, 11, 16, 26, 0, 19, 0, 14],\n",
              " [15, 26, 16, 21, 12, 8, 16, 21, 11, 16, 26, 0, 19, 0, 14, 21, 16, 23, 18, 1],\n",
              " [8, 16, 21, 11, 16, 26, 0, 19, 0, 14, 21, 16, 23, 18, 1, 1, 14, 12, 8, 16],\n",
              " [26, 0, 19, 0, 14, 21, 16, 23, 18, 1, 1, 14, 12, 8, 16, 13, 1, 18, 15, 21],\n",
              " [21, 16, 23, 18, 1, 1, 14, 12, 8, 16, 13, 1, 18, 15, 21, 11, 15, 16, 25, 17],\n",
              " [1, 14, 12, 8, 16, 13, 1, 18, 15, 21, 11, 15, 16, 25, 17, 0, 1, 1, 0, 12],\n",
              " [13, 1, 18, 15, 21, 11, 15, 16, 25, 17, 0, 1, 1, 0, 12, 16, 1, 14, 18, 26],\n",
              " [11, 15, 16, 25, 17, 0, 1, 1, 0, 12, 16, 1, 14, 18, 26, 16, 21, 23, 0, 16],\n",
              " [0, 1, 1, 0, 12, 16, 1, 14, 18, 26, 16, 21, 23, 0, 16, 3, 12, 11, 17, 15],\n",
              " [16, 1, 14, 18, 26, 16, 21, 23, 0, 16, 3, 12, 11, 17, 15, 26, 10, 11, 12, 24],\n",
              " [16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  3,\n",
              "  12,\n",
              "  11,\n",
              "  17,\n",
              "  15,\n",
              "  26,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  24,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  16],\n",
              " [3, 12, 11, 17, 15, 26, 10, 11, 12, 24, 16, 19, 11, 12, 16, 14, 21, 16, 1, 0],\n",
              " [26,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  24,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  21,\n",
              "  16,\n",
              "  1,\n",
              "  0,\n",
              "  14,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  13],\n",
              " [16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  21,\n",
              "  16,\n",
              "  1,\n",
              "  0,\n",
              "  14,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  13,\n",
              "  21,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19],\n",
              " [14,\n",
              "  21,\n",
              "  16,\n",
              "  1,\n",
              "  0,\n",
              "  14,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  13,\n",
              "  21,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  11,\n",
              "  22,\n",
              "  20,\n",
              "  21],\n",
              " [14,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  13,\n",
              "  21,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  11,\n",
              "  22,\n",
              "  20,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  13,\n",
              "  21,\n",
              "  18],\n",
              " [21,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  11,\n",
              "  22,\n",
              "  20,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  13,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  11,\n",
              "  19],\n",
              " [16,\n",
              "  11,\n",
              "  22,\n",
              "  20,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  13,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  4,\n",
              "  17,\n",
              "  20,\n",
              "  21],\n",
              " [12, 17, 13, 21, 18, 11, 15, 16, 11, 19, 16, 4, 17, 20, 21, 18, 13, 0, 0, 2],\n",
              " [11, 15, 16, 11, 19, 16, 4, 17, 20, 21, 18, 13, 0, 0, 2, 0, 15, 16, 10, 18],\n",
              " [16, 4, 17, 20, 21, 18, 13, 0, 0, 2, 0, 15, 16, 10, 18, 21, 23, 16, 14, 1],\n",
              " [18, 13, 0, 0, 2, 0, 15, 16, 10, 18, 21, 23, 16, 14, 1, 1, 16, 11, 19, 16],\n",
              " [0, 15, 16, 10, 18, 21, 23, 16, 14, 1, 1, 16, 11, 19, 16, 21, 23, 14, 21, 16],\n",
              " [21,\n",
              "  23,\n",
              "  16,\n",
              "  14,\n",
              "  1,\n",
              "  1,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  14,\n",
              "  21,\n",
              "  16,\n",
              "  18,\n",
              "  21,\n",
              "  20,\n",
              "  16,\n",
              "  21],\n",
              " [1,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  14,\n",
              "  21,\n",
              "  16,\n",
              "  18,\n",
              "  21,\n",
              "  20,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  20],\n",
              " [21,\n",
              "  23,\n",
              "  14,\n",
              "  21,\n",
              "  16,\n",
              "  18,\n",
              "  21,\n",
              "  20,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  18,\n",
              "  1,\n",
              "  1,\n",
              "  17],\n",
              " [18, 21, 20, 16, 21, 23, 18, 20, 16, 20, 21, 18, 1, 1, 17, 15, 12, 14, 2, 0],\n",
              " [23, 18, 20, 16, 20, 21, 18, 1, 1, 17, 15, 12, 14, 2, 0, 1, 18, 15, 3, 16],\n",
              " [21, 18, 1, 1, 17, 15, 12, 14, 2, 0, 1, 18, 15, 3, 16, 17, 24, 12, 14, 18],\n",
              " [15, 12, 14, 2, 0, 1, 18, 15, 3, 16, 17, 24, 12, 14, 18, 15, 0, 16, 20, 21],\n",
              " [1, 18, 15, 3, 16, 17, 24, 12, 14, 18, 15, 0, 16, 20, 21, 11, 12, 8, 16, 21],\n",
              " [17,\n",
              "  24,\n",
              "  12,\n",
              "  14,\n",
              "  18,\n",
              "  15,\n",
              "  0,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  8,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  14,\n",
              "  21,\n",
              "  16,\n",
              "  25],\n",
              " [15, 0, 16, 20, 21, 11, 12, 8, 16, 21, 23, 14, 21, 16, 25, 14, 24, 0, 20, 16],\n",
              " [11, 12, 8, 16, 21, 23, 14, 21, 16, 25, 14, 24, 0, 20, 16, 13, 1, 0, 14, 12],\n",
              " [23, 14, 21, 16, 25, 14, 24, 0, 20, 16, 13, 1, 0, 14, 12, 16, 21, 23, 0, 16],\n",
              " [14, 24, 0, 20, 16, 13, 1, 0, 14, 12, 16, 21, 23, 0, 16, 22, 18, 21, 20, 16],\n",
              " [13, 1, 0, 14, 12, 16, 21, 23, 0, 16, 22, 18, 21, 20, 16, 14, 15, 26, 16, 6],\n",
              " [16, 21, 23, 0, 16, 22, 18, 21, 20, 16, 14, 15, 26, 16, 6, 18, 0, 13, 0, 20],\n",
              " [22, 18, 21, 20, 16, 14, 15, 26, 16, 6, 18, 0, 13, 0, 20, 16, 21, 23, 14, 21],\n",
              " [14, 15, 26, 16, 6, 18, 0, 13, 0, 20, 16, 21, 23, 14, 21, 16, 10, 0, 16, 13],\n",
              " [18, 0, 13, 0, 20, 16, 21, 23, 14, 21, 16, 10, 0, 16, 13, 11, 17, 1, 26, 16],\n",
              " [16, 21, 23, 14, 21, 16, 10, 0, 16, 13, 11, 17, 1, 26, 16, 11, 15, 1, 8, 16],\n",
              " [16, 10, 0, 16, 13, 11, 17, 1, 26, 16, 11, 15, 1, 8, 16, 18, 25, 14, 3, 18],\n",
              " [11, 17, 1, 26, 16, 11, 15, 1, 8, 16, 18, 25, 14, 3, 18, 15, 0, 16, 10, 18],\n",
              " [11, 15, 1, 8, 16, 18, 25, 14, 3, 18, 15, 0, 16, 10, 18, 21, 23, 16, 21, 12],\n",
              " [18, 25, 14, 3, 18, 15, 0, 16, 10, 18, 21, 23, 16, 21, 12, 17, 25, 6, 20, 16],\n",
              " [15, 0, 16, 10, 18, 21, 23, 16, 21, 12, 17, 25, 6, 20, 16, 6, 1, 0, 14, 20],\n",
              " [21, 23, 16, 21, 12, 17, 25, 6, 20, 16, 6, 1, 0, 14, 20, 16, 21, 11, 16, 12],\n",
              " [17, 25, 6, 20, 16, 6, 1, 0, 14, 20, 16, 21, 11, 16, 12, 17, 20, 20, 18, 14],\n",
              " [6, 1, 0, 14, 20, 16, 21, 11, 16, 12, 17, 20, 20, 18, 14, 16, 18, 19, 16, 8],\n",
              " [16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  12,\n",
              "  17,\n",
              "  20,\n",
              "  20,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  18,\n",
              "  19,\n",
              "  16,\n",
              "  8,\n",
              "  11,\n",
              "  17,\n",
              "  12,\n",
              "  0,\n",
              "  16],\n",
              " [17, 20, 20, 18, 14, 16, 18, 19, 16, 8, 11, 17, 12, 0, 16, 1, 18, 20, 21, 0],\n",
              " [16, 18, 19, 16, 8, 11, 17, 12, 0, 16, 1, 18, 20, 21, 0, 15, 18, 15, 3, 10],\n",
              " [11, 17, 12, 0, 16, 1, 18, 20, 21, 0, 15, 18, 15, 3, 10, 0, 16, 23, 14, 2],\n",
              " [1, 18, 20, 21, 0, 15, 18, 15, 3, 10, 0, 16, 23, 14, 2, 0, 16, 21, 23, 0],\n",
              " [15, 18, 15, 3, 10, 0, 16, 23, 14, 2, 0, 16, 21, 23, 0, 16, 20, 14, 25, 0],\n",
              " [0, 16, 23, 14, 2, 0, 16, 21, 23, 0, 16, 20, 14, 25, 0, 16, 21, 23, 12, 0],\n",
              " [0, 16, 21, 23, 0, 16, 20, 14, 25, 0, 16, 21, 23, 12, 0, 14, 21, 20, 16, 1],\n",
              " [16, 20, 14, 25, 0, 16, 21, 23, 12, 0, 14, 21, 20, 16, 1, 18, 0, 20, 16, 20],\n",
              " [16, 21, 23, 12, 0, 14, 21, 20, 16, 1, 18, 0, 20, 16, 20, 17, 22, 21, 0, 12],\n",
              " [14, 21, 20, 16, 1, 18, 0, 20, 16, 20, 17, 22, 21, 0, 12, 19, 17, 3, 0, 16],\n",
              " [18, 0, 20, 16, 20, 17, 22, 21, 0, 12, 19, 17, 3, 0, 16, 14, 15, 26, 16, 11],\n",
              " [17, 22, 21, 0, 12, 19, 17, 3, 0, 16, 14, 15, 26, 16, 11, 22, 20, 21, 12, 17],\n",
              " [19,\n",
              "  17,\n",
              "  3,\n",
              "  0,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  11,\n",
              "  22,\n",
              "  20,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  13,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15],\n",
              " [14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  11,\n",
              "  22,\n",
              "  20,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  13,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  11,\n",
              "  15,\n",
              "  1,\n",
              "  8,\n",
              "  16],\n",
              " [22,\n",
              "  20,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  13,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  11,\n",
              "  15,\n",
              "  1,\n",
              "  8,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16],\n",
              " [13, 21, 18, 11, 15, 11, 15, 1, 8, 16, 21, 23, 18, 20, 16, 21, 18, 25, 0, 16],\n",
              " [11, 15, 1, 8, 16, 21, 23, 18, 20, 16, 21, 18, 25, 0, 16, 10, 0, 16, 23, 14],\n",
              " [21, 23, 18, 20, 16, 21, 18, 25, 0, 16, 10, 0, 16, 23, 14, 2, 0, 16, 21, 23],\n",
              " [21, 18, 25, 0, 16, 10, 0, 16, 23, 14, 2, 0, 16, 21, 23, 0, 16, 6, 12, 0],\n",
              " [10, 0, 16, 23, 14, 2, 0, 16, 21, 23, 0, 16, 6, 12, 0, 20, 18, 26, 0, 15],\n",
              " [2, 0, 16, 21, 23, 0, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 20, 16, 17, 15],\n",
              " [0, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 20, 16, 17, 15, 14, 25, 22, 18, 3],\n",
              " [20,\n",
              "  18,\n",
              "  26,\n",
              "  0,\n",
              "  15,\n",
              "  21,\n",
              "  20,\n",
              "  16,\n",
              "  17,\n",
              "  15,\n",
              "  14,\n",
              "  25,\n",
              "  22,\n",
              "  18,\n",
              "  3,\n",
              "  17,\n",
              "  11,\n",
              "  17,\n",
              "  20,\n",
              "  16],\n",
              " [21,\n",
              "  20,\n",
              "  16,\n",
              "  17,\n",
              "  15,\n",
              "  14,\n",
              "  25,\n",
              "  22,\n",
              "  18,\n",
              "  3,\n",
              "  17,\n",
              "  11,\n",
              "  17,\n",
              "  20,\n",
              "  16,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  26,\n",
              "  20],\n",
              " [14,\n",
              "  25,\n",
              "  22,\n",
              "  18,\n",
              "  3,\n",
              "  17,\n",
              "  11,\n",
              "  17,\n",
              "  20,\n",
              "  16,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  26,\n",
              "  20,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  7],\n",
              " [17, 11, 17, 20, 16, 10, 11, 12, 26, 20, 16, 21, 11, 16, 7, 0, 1, 0, 15, 20],\n",
              " [10, 11, 12, 26, 20, 16, 21, 11, 16, 7, 0, 1, 0, 15, 20, 24, 8, 16, 18, 16],\n",
              " [16, 21, 11, 16, 7, 0, 1, 0, 15, 20, 24, 8, 16, 18, 16, 10, 11, 17, 1, 26],\n",
              " [0, 1, 0, 15, 20, 24, 8, 16, 18, 16, 10, 11, 17, 1, 26, 16, 1, 18, 24, 0],\n",
              " [24, 8, 16, 18, 16, 10, 11, 17, 1, 26, 16, 1, 18, 24, 0, 16, 8, 11, 17, 16],\n",
              " [10, 11, 17, 1, 26, 16, 1, 18, 24, 0, 16, 8, 11, 17, 16, 21, 11, 16, 26, 11],\n",
              " [16, 1, 18, 24, 0, 16, 8, 11, 17, 16, 21, 11, 16, 26, 11, 16, 17, 20, 16, 14],\n",
              " [16,\n",
              "  8,\n",
              "  11,\n",
              "  17,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  16,\n",
              "  17,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  19,\n",
              "  14,\n",
              "  2,\n",
              "  11],\n",
              " [21,\n",
              "  11,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  16,\n",
              "  17,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  19,\n",
              "  14,\n",
              "  2,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  11],\n",
              " [16,\n",
              "  17,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  19,\n",
              "  14,\n",
              "  2,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  11,\n",
              "  17,\n",
              "  3,\n",
              "  23,\n",
              "  16,\n",
              "  17],\n",
              " [16,\n",
              "  19,\n",
              "  14,\n",
              "  2,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  11,\n",
              "  17,\n",
              "  3,\n",
              "  23,\n",
              "  16,\n",
              "  17,\n",
              "  24,\n",
              "  12,\n",
              "  14,\n",
              "  18,\n",
              "  15],\n",
              " [12, 16, 21, 23, 11, 17, 3, 23, 16, 17, 24, 12, 14, 18, 15, 0, 16, 12, 0, 6],\n",
              " [17, 3, 23, 16, 17, 24, 12, 14, 18, 15, 0, 16, 12, 0, 6, 12, 0, 20, 0, 15],\n",
              " [24, 12, 14, 18, 15, 0, 16, 12, 0, 6, 12, 0, 20, 0, 15, 21, 20, 16, 21, 23],\n",
              " [0, 16, 12, 0, 6, 12, 0, 20, 0, 15, 21, 20, 16, 21, 23, 0, 16, 20, 14, 25],\n",
              " [12, 0, 20, 0, 15, 21, 20, 16, 21, 23, 0, 16, 20, 14, 25, 0, 16, 1, 14, 10],\n",
              " [21, 20, 16, 21, 23, 0, 16, 20, 14, 25, 0, 16, 1, 14, 10, 1, 0, 20, 20, 15],\n",
              " [0, 16, 20, 14, 25, 0, 16, 1, 14, 10, 1, 0, 20, 20, 15, 0, 20, 20, 16, 21],\n",
              " [0, 16, 1, 14, 10, 1, 0, 20, 20, 15, 0, 20, 20, 16, 21, 23, 14, 21, 16, 6],\n",
              " [1, 0, 20, 20, 15, 0, 20, 20, 16, 21, 23, 14, 21, 16, 6, 12, 11, 6, 0, 1],\n",
              " [0, 20, 20, 16, 21, 23, 14, 21, 16, 6, 12, 11, 6, 0, 1, 1, 0, 26, 16, 21],\n",
              " [23, 14, 21, 16, 6, 12, 11, 6, 0, 1, 1, 0, 26, 16, 21, 12, 17, 25, 6, 16],\n",
              " [12, 11, 6, 0, 1, 1, 0, 26, 16, 21, 12, 17, 25, 6, 16, 11, 2, 0, 12, 16],\n",
              " [1, 0, 26, 16, 21, 12, 17, 25, 6, 16, 11, 2, 0, 12, 16, 21, 23, 0, 16, 19],\n",
              " [12, 17, 25, 6, 16, 11, 2, 0, 12, 16, 21, 23, 0, 16, 19, 18, 15, 18, 20, 23],\n",
              " [11, 2, 0, 12, 16, 21, 23, 0, 16, 19, 18, 15, 18, 20, 23, 16, 1, 18, 15, 0],\n",
              " [21, 23, 0, 16, 19, 18, 15, 18, 20, 23, 16, 1, 18, 15, 0, 16, 18, 15, 21, 23],\n",
              " [18,\n",
              "  15,\n",
              "  18,\n",
              "  20,\n",
              "  23,\n",
              "  16,\n",
              "  1,\n",
              "  18,\n",
              "  15,\n",
              "  0,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  21,\n",
              "  18],\n",
              " [16, 1, 18, 15, 0, 16, 18, 15, 21, 23, 18, 20, 16, 21, 18, 25, 0, 16, 18, 15],\n",
              " [16, 18, 15, 21, 23, 18, 20, 16, 21, 18, 25, 0, 16, 18, 15, 16, 6, 1, 14, 18],\n",
              " [18, 20, 16, 21, 18, 25, 0, 16, 18, 15, 16, 6, 1, 14, 18, 15, 16, 20, 18, 3],\n",
              " [25, 0, 16, 18, 15, 16, 6, 1, 14, 18, 15, 16, 20, 18, 3, 23, 21, 16, 10, 18],\n",
              " [16, 6, 1, 14, 18, 15, 16, 20, 18, 3, 23, 21, 16, 10, 18, 21, 23, 16, 10, 18],\n",
              " [15,\n",
              "  16,\n",
              "  20,\n",
              "  18,\n",
              "  3,\n",
              "  23,\n",
              "  21,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  15,\n",
              "  0,\n",
              "  20,\n",
              "  20],\n",
              " [23,\n",
              "  21,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  15,\n",
              "  0,\n",
              "  20,\n",
              "  20,\n",
              "  0,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  15],\n",
              " [21, 23, 16, 10, 18, 21, 15, 0, 20, 20, 0, 20, 16, 18, 15, 13, 1, 17, 26, 18],\n",
              " [21, 15, 0, 20, 20, 0, 20, 16, 18, 15, 13, 1, 17, 26, 18, 15, 3, 16, 14, 21],\n",
              " [0, 20, 16, 18, 15, 13, 1, 17, 26, 18, 15, 3, 16, 14, 21, 16, 1, 0, 14, 20],\n",
              " [13, 1, 17, 26, 18, 15, 3, 16, 14, 21, 16, 1, 0, 14, 20, 21, 16, 11, 15, 0],\n",
              " [15, 3, 16, 14, 21, 16, 1, 0, 14, 20, 21, 16, 11, 15, 0, 16, 10, 23, 18, 20],\n",
              " [16, 1, 0, 14, 20, 21, 16, 11, 15, 0, 16, 10, 23, 18, 20, 21, 1, 0, 22, 1],\n",
              " [21, 16, 11, 15, 0, 16, 10, 23, 18, 20, 21, 1, 0, 22, 1, 11, 10, 0, 12, 16],\n",
              " [16, 10, 23, 18, 20, 21, 1, 0, 22, 1, 11, 10, 0, 12, 16, 14, 15, 26, 16, 1],\n",
              " [21, 1, 0, 22, 1, 11, 10, 0, 12, 16, 14, 15, 26, 16, 1, 11, 21, 20, 16, 11],\n",
              " [11,\n",
              "  10,\n",
              "  0,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  1,\n",
              "  11,\n",
              "  21,\n",
              "  20,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  22,\n",
              "  18,\n",
              "  21],\n",
              " [14, 15, 26, 16, 1, 11, 21, 20, 16, 11, 19, 16, 22, 18, 21, 16, 6, 1, 14, 8],\n",
              " [11, 21, 20, 16, 11, 19, 16, 22, 18, 21, 16, 6, 1, 14, 8, 0, 12, 20, 16, 19],\n",
              " [19, 16, 22, 18, 21, 16, 6, 1, 14, 8, 0, 12, 20, 16, 19, 12, 11, 25, 16, 21],\n",
              " [16, 6, 1, 14, 8, 0, 12, 20, 16, 19, 12, 11, 25, 16, 21, 23, 0, 16, 20, 21],\n",
              " [0, 12, 20, 16, 19, 12, 11, 25, 16, 21, 23, 0, 16, 20, 21, 14, 21, 0, 16, 26],\n",
              " [12, 11, 25, 16, 21, 23, 0, 16, 20, 21, 14, 21, 0, 16, 26, 0, 6, 14, 12, 21],\n",
              " [23, 0, 16, 20, 21, 14, 21, 0, 16, 26, 0, 6, 14, 12, 21, 25, 0, 15, 21, 16],\n",
              " [14, 21, 0, 16, 26, 0, 6, 14, 12, 21, 25, 0, 15, 21, 16, 21, 11, 16, 21, 23],\n",
              " [0, 6, 14, 12, 21, 25, 0, 15, 21, 16, 21, 11, 16, 21, 23, 0, 16, 0, 15, 0],\n",
              " [25, 0, 15, 21, 16, 21, 11, 16, 21, 23, 0, 16, 0, 15, 0, 12, 3, 8, 16, 26],\n",
              " [21, 11, 16, 21, 23, 0, 16, 0, 15, 0, 12, 3, 8, 16, 26, 0, 6, 14, 12, 21],\n",
              " [0, 16, 0, 15, 0, 12, 3, 8, 16, 26, 0, 6, 14, 12, 21, 25, 0, 15, 21, 16],\n",
              " [12, 3, 8, 16, 26, 0, 6, 14, 12, 21, 25, 0, 15, 21, 16, 21, 11, 16, 21, 23],\n",
              " [0, 6, 14, 12, 21, 25, 0, 15, 21, 16, 21, 11, 16, 21, 23, 0, 16, 4, 17, 20],\n",
              " [25, 0, 15, 21, 16, 21, 11, 16, 21, 23, 0, 16, 4, 17, 20, 21, 18, 13, 0, 16],\n",
              " [21, 11, 16, 21, 23, 0, 16, 4, 17, 20, 21, 18, 13, 0, 16, 26, 0, 6, 14, 12],\n",
              " [0, 16, 4, 17, 20, 21, 18, 13, 0, 16, 26, 0, 6, 14, 12, 21, 25, 0, 15, 21],\n",
              " [21, 18, 13, 0, 16, 26, 0, 6, 14, 12, 21, 25, 0, 15, 21, 16, 14, 15, 26, 16],\n",
              " [26, 0, 6, 14, 12, 21, 25, 0, 15, 21, 16, 14, 15, 26, 16, 21, 23, 12, 11, 17],\n",
              " [21,\n",
              "  25,\n",
              "  0,\n",
              "  15,\n",
              "  21,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  12,\n",
              "  11,\n",
              "  17,\n",
              "  3,\n",
              "  23,\n",
              "  11,\n",
              "  17,\n",
              "  21],\n",
              " [16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  12,\n",
              "  11,\n",
              "  17,\n",
              "  3,\n",
              "  23,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16],\n",
              " [21, 23, 12, 11, 17, 3, 23, 11, 17, 21, 16, 21, 23, 0, 16, 10, 23, 18, 21, 0],\n",
              " [3, 23, 11, 17, 21, 16, 21, 23, 0, 16, 10, 23, 18, 21, 0, 16, 23, 11, 17, 20],\n",
              " [16, 21, 23, 0, 16, 10, 23, 18, 21, 0, 16, 23, 11, 17, 20, 0, 16, 21, 12, 17],\n",
              " [10, 23, 18, 21, 0, 16, 23, 11, 17, 20, 0, 16, 21, 12, 17, 25, 6, 16, 18, 20],\n",
              " [16,\n",
              "  23,\n",
              "  11,\n",
              "  17,\n",
              "  20,\n",
              "  0,\n",
              "  16,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  25,\n",
              "  6,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  17,\n",
              "  20,\n",
              "  18,\n",
              "  15],\n",
              " [0, 16, 21, 12, 17, 25, 6, 16, 18, 20, 16, 17, 20, 18, 15, 3, 16, 0, 2, 0],\n",
              " [25, 6, 16, 18, 20, 16, 17, 20, 18, 15, 3, 16, 0, 2, 0, 12, 8, 16, 22, 18],\n",
              " [16, 17, 20, 18, 15, 3, 16, 0, 2, 0, 12, 8, 16, 22, 18, 21, 16, 11, 19, 16],\n",
              " [3, 16, 0, 2, 0, 12, 8, 16, 22, 18, 21, 16, 11, 19, 16, 21, 23, 0, 16, 25],\n",
              " [12,\n",
              "  8,\n",
              "  16,\n",
              "  22,\n",
              "  18,\n",
              "  21,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  25,\n",
              "  14,\n",
              "  13,\n",
              "  23,\n",
              "  18,\n",
              "  15],\n",
              " [21, 16, 11, 19, 16, 21, 23, 0, 16, 25, 14, 13, 23, 18, 15, 0, 12, 8, 16, 11],\n",
              " [21, 23, 0, 16, 25, 14, 13, 23, 18, 15, 0, 12, 8, 16, 11, 19, 16, 3, 11, 2],\n",
              " [14, 13, 23, 18, 15, 0, 12, 8, 16, 11, 19, 16, 3, 11, 2, 0, 12, 15, 25, 0],\n",
              " [0, 12, 8, 16, 11, 19, 16, 3, 11, 2, 0, 12, 15, 25, 0, 15, 21, 16, 14, 15],\n",
              " [19, 16, 3, 11, 2, 0, 12, 15, 25, 0, 15, 21, 16, 14, 15, 26, 16, 6, 0, 12],\n",
              " [0, 12, 15, 25, 0, 15, 21, 16, 14, 15, 26, 16, 6, 0, 12, 20, 11, 15, 15, 0],\n",
              " [15, 21, 16, 14, 15, 26, 16, 6, 0, 12, 20, 11, 15, 15, 0, 1, 16, 14, 21, 16],\n",
              " [26, 16, 6, 0, 12, 20, 11, 15, 15, 0, 1, 16, 14, 21, 16, 23, 18, 20, 16, 26],\n",
              " [20, 11, 15, 15, 0, 1, 16, 14, 21, 16, 23, 18, 20, 16, 26, 18, 20, 6, 11, 20],\n",
              " [1, 16, 14, 21, 16, 23, 18, 20, 16, 26, 18, 20, 6, 11, 20, 14, 1, 16, 21, 11],\n",
              " [23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  20,\n",
              "  6,\n",
              "  11,\n",
              "  20,\n",
              "  14,\n",
              "  1,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  12,\n",
              "  11],\n",
              " [18, 20, 6, 11, 20, 14, 1, 16, 21, 11, 16, 20, 21, 12, 11, 15, 3, 14, 12, 25],\n",
              " [14,\n",
              "  1,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  12,\n",
              "  11,\n",
              "  15,\n",
              "  3,\n",
              "  14,\n",
              "  12,\n",
              "  25,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  20,\n",
              "  25],\n",
              " [16, 20, 21, 12, 11, 15, 3, 14, 12, 25, 16, 14, 16, 20, 25, 14, 1, 1, 16, 13],\n",
              " [15, 3, 14, 12, 25, 16, 14, 16, 20, 25, 14, 1, 1, 16, 13, 11, 17, 15, 21, 12],\n",
              " [16, 14, 16, 20, 25, 14, 1, 1, 16, 13, 11, 17, 15, 21, 12, 8, 16, 17, 15, 26],\n",
              " [14, 1, 1, 16, 13, 11, 17, 15, 21, 12, 8, 16, 17, 15, 26, 0, 12, 16, 21, 23],\n",
              " [11, 17, 15, 21, 12, 8, 16, 17, 15, 26, 0, 12, 16, 21, 23, 0, 16, 23, 0, 0],\n",
              " [8, 16, 17, 15, 26, 0, 12, 16, 21, 23, 0, 16, 23, 0, 0, 1, 16, 11, 19, 16],\n",
              " [0, 12, 16, 21, 23, 0, 16, 23, 0, 0, 1, 16, 11, 19, 16, 18, 21, 20, 16, 21],\n",
              " [0, 16, 23, 0, 0, 1, 16, 11, 19, 16, 18, 21, 20, 16, 21, 23, 12, 0, 14, 21],\n",
              " [1, 16, 11, 19, 16, 18, 21, 20, 16, 21, 23, 12, 0, 14, 21, 0, 15, 18, 15, 3],\n",
              " [18, 21, 20, 16, 21, 23, 12, 0, 14, 21, 0, 15, 18, 15, 3, 16, 12, 17, 20, 20],\n",
              " [23, 12, 0, 14, 21, 0, 15, 18, 15, 3, 16, 12, 17, 20, 20, 18, 14, 15, 16, 15],\n",
              " [0, 15, 18, 15, 3, 16, 12, 17, 20, 20, 18, 14, 15, 16, 15, 0, 18, 3, 23, 22],\n",
              " [16, 12, 17, 20, 20, 18, 14, 15, 16, 15, 0, 18, 3, 23, 22, 11, 12, 14, 1, 1],\n",
              " [18, 14, 15, 16, 15, 0, 18, 3, 23, 22, 11, 12, 14, 1, 1, 16, 21, 11, 16, 3],\n",
              " [0, 18, 3, 23, 22, 11, 12, 14, 1, 1, 16, 21, 11, 16, 3, 0, 21, 16, 25, 14],\n",
              " [11, 12, 14, 1, 1, 16, 21, 11, 16, 3, 0, 21, 16, 25, 14, 15, 17, 19, 14, 13],\n",
              " [16, 21, 11, 16, 3, 0, 21, 16, 25, 14, 15, 17, 19, 14, 13, 21, 17, 12, 0, 26],\n",
              " [0,\n",
              "  21,\n",
              "  16,\n",
              "  25,\n",
              "  14,\n",
              "  15,\n",
              "  17,\n",
              "  19,\n",
              "  14,\n",
              "  13,\n",
              "  21,\n",
              "  17,\n",
              "  12,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  12,\n",
              "  21],\n",
              " [15,\n",
              "  17,\n",
              "  19,\n",
              "  14,\n",
              "  13,\n",
              "  21,\n",
              "  17,\n",
              "  12,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  12,\n",
              "  21,\n",
              "  16,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  14],\n",
              " [21, 17, 12, 0, 26, 16, 26, 18, 12, 21, 16, 11, 15, 16, 14, 16, 6, 11, 1, 18],\n",
              " [16, 26, 18, 12, 21, 16, 11, 15, 16, 14, 16, 6, 11, 1, 18, 21, 18, 13, 14, 1],\n",
              " [16, 11, 15, 16, 14, 16, 6, 11, 1, 18, 21, 18, 13, 14, 1, 16, 11, 6, 6, 11],\n",
              " [16, 6, 11, 1, 18, 21, 18, 13, 14, 1, 16, 11, 6, 6, 11, 15, 0, 15, 21, 18],\n",
              " [21, 18, 13, 14, 1, 16, 11, 6, 6, 11, 15, 0, 15, 21, 18, 21, 20, 16, 18, 1],\n",
              " [16, 11, 6, 6, 11, 15, 0, 15, 21, 18, 21, 20, 16, 18, 1, 1, 0, 3, 14, 1],\n",
              " [15, 0, 15, 21, 18, 21, 20, 16, 18, 1, 1, 0, 3, 14, 1, 16, 21, 23, 0, 16],\n",
              " [21, 20, 16, 18, 1, 1, 0, 3, 14, 1, 16, 21, 23, 0, 16, 0, 2, 18, 26, 0],\n",
              " [1, 0, 3, 14, 1, 16, 21, 23, 0, 16, 0, 2, 18, 26, 0, 15, 13, 0, 16, 18],\n",
              " [16, 21, 23, 0, 16, 0, 2, 18, 26, 0, 15, 13, 0, 16, 18, 20, 16, 22, 0, 14],\n",
              " [0, 2, 18, 26, 0, 15, 13, 0, 16, 18, 20, 16, 22, 0, 14, 12, 18, 15, 3, 16],\n",
              " [15, 13, 0, 16, 18, 20, 16, 22, 0, 14, 12, 18, 15, 3, 16, 19, 12, 17, 18, 21],\n",
              " [20, 16, 22, 0, 14, 12, 18, 15, 3, 16, 19, 12, 17, 18, 21, 16, 21, 23, 0, 16],\n",
              " [12, 18, 15, 3, 16, 19, 12, 17, 18, 21, 16, 21, 23, 0, 16, 21, 18, 25, 0, 16],\n",
              " [19, 12, 17, 18, 21, 16, 21, 23, 0, 16, 21, 18, 25, 0, 16, 10, 18, 1, 1, 16],\n",
              " [16, 21, 23, 0, 16, 21, 18, 25, 0, 16, 10, 18, 1, 1, 16, 13, 11, 25, 0, 16],\n",
              " [21, 18, 25, 0, 16, 10, 18, 1, 1, 16, 13, 11, 25, 0, 16, 14, 15, 26, 16, 4],\n",
              " [10, 18, 1, 1, 16, 13, 11, 25, 0, 16, 14, 15, 26, 16, 4, 17, 20, 21, 18, 13],\n",
              " [13, 11, 25, 0, 16, 14, 15, 26, 16, 4, 17, 20, 21, 18, 13, 0, 16, 10, 18, 1],\n",
              " [14, 15, 26, 16, 4, 17, 20, 21, 18, 13, 0, 16, 10, 18, 1, 1, 16, 22, 0, 16],\n",
              " [17, 20, 21, 18, 13, 0, 16, 10, 18, 1, 1, 16, 22, 0, 16, 20, 0, 12, 2, 0],\n",
              " [0, 16, 10, 18, 1, 1, 16, 22, 0, 16, 20, 0, 12, 2, 0, 26, 21, 23, 0, 16],\n",
              " [1, 16, 22, 0, 16, 20, 0, 12, 2, 0, 26, 21, 23, 0, 16, 6, 12, 0, 20, 18],\n",
              " [20, 0, 12, 2, 0, 26, 21, 23, 0, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 20],\n",
              " [26, 21, 23, 0, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 20, 16, 6, 0, 12, 20],\n",
              " [6, 12, 0, 20, 18, 26, 0, 15, 21, 20, 16, 6, 0, 12, 20, 11, 15, 14, 1, 16],\n",
              " [26, 0, 15, 21, 20, 16, 6, 0, 12, 20, 11, 15, 14, 1, 16, 14, 6, 6, 12, 11],\n",
              " [16, 6, 0, 12, 20, 11, 15, 14, 1, 16, 14, 6, 6, 12, 11, 2, 14, 1, 16, 12],\n",
              " [11, 15, 14, 1, 16, 14, 6, 6, 12, 11, 2, 14, 1, 16, 12, 14, 21, 18, 15, 3],\n",
              " [14, 6, 6, 12, 11, 2, 14, 1, 16, 12, 14, 21, 18, 15, 3, 16, 12, 0, 25, 14],\n",
              " [2, 14, 1, 16, 12, 14, 21, 18, 15, 3, 16, 12, 0, 25, 14, 18, 15, 20, 16, 1],\n",
              " [14, 21, 18, 15, 3, 16, 12, 0, 25, 14, 18, 15, 20, 16, 1, 11, 10, 16, 21, 23],\n",
              " [16, 12, 0, 25, 14, 18, 15, 20, 16, 1, 11, 10, 16, 21, 23, 11, 17, 3, 23, 16],\n",
              " [18, 15, 20, 16, 1, 11, 10, 16, 21, 23, 11, 17, 3, 23, 16, 20, 21, 14, 22, 1],\n",
              " [11, 10, 16, 21, 23, 11, 17, 3, 23, 16, 20, 21, 14, 22, 1, 0, 16, 22, 17, 21],\n",
              " [11, 17, 3, 23, 16, 20, 21, 14, 22, 1, 0, 16, 22, 17, 21, 16, 21, 23, 0, 12],\n",
              " [20, 21, 14, 22, 1, 0, 16, 22, 17, 21, 16, 21, 23, 0, 12, 0, 16, 18, 20, 16],\n",
              " [0, 16, 22, 17, 21, 16, 21, 23, 0, 12, 0, 16, 18, 20, 16, 3, 12, 11, 10, 18],\n",
              " [16, 21, 23, 0, 12, 0, 16, 18, 20, 16, 3, 12, 11, 10, 18, 15, 3, 16, 20, 17],\n",
              " [0, 16, 18, 20, 16, 3, 12, 11, 10, 18, 15, 3, 16, 20, 17, 6, 6, 11, 12, 21],\n",
              " [3, 12, 11, 10, 18, 15, 3, 16, 20, 17, 6, 6, 11, 12, 21, 16, 19, 11, 12, 16],\n",
              " [15, 3, 16, 20, 17, 6, 6, 11, 12, 21, 16, 19, 11, 12, 16, 18, 25, 6, 0, 14],\n",
              " [6, 6, 11, 12, 21, 16, 19, 11, 12, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15],\n",
              " [16, 19, 11, 12, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 14, 16, 19, 11],\n",
              " [18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 14, 16, 19, 11, 9, 16, 15, 0, 10],\n",
              " [13, 23, 25, 0, 15, 21, 14, 16, 19, 11, 9, 16, 15, 0, 10, 20, 16, 6, 11, 1],\n",
              " [21, 14, 16, 19, 11, 9, 16, 15, 0, 10, 20, 16, 6, 11, 1, 1, 16, 21, 23, 18],\n",
              " [9, 16, 15, 0, 10, 20, 16, 6, 11, 1, 1, 16, 21, 23, 18, 20, 16, 10, 0, 0],\n",
              " [20, 16, 6, 11, 1, 1, 16, 21, 23, 18, 20, 16, 10, 0, 0, 24, 16, 19, 11, 17],\n",
              " [1, 16, 21, 23, 18, 20, 16, 10, 0, 0, 24, 16, 19, 11, 17, 15, 26, 16, 21, 23],\n",
              " [20, 16, 10, 0, 0, 24, 16, 19, 11, 17, 15, 26, 16, 21, 23, 14, 21, 6, 0, 12],\n",
              " [24, 16, 19, 11, 17, 15, 26, 16, 21, 23, 14, 21, 6, 0, 12, 13, 0, 15, 21, 16],\n",
              " [15, 26, 16, 21, 23, 14, 21, 6, 0, 12, 13, 0, 15, 21, 16, 20, 17, 6, 6, 11],\n",
              " [14, 21, 6, 0, 12, 13, 0, 15, 21, 16, 20, 17, 6, 6, 11, 12, 21, 16, 12, 0],\n",
              " [13, 0, 15, 21, 16, 20, 17, 6, 6, 11, 12, 21, 16, 12, 0, 25, 11, 2, 18, 15],\n",
              " [20, 17, 6, 6, 11, 12, 21, 16, 12, 0, 25, 11, 2, 18, 15, 3, 16, 21, 12, 17],\n",
              " [12, 21, 16, 12, 0, 25, 11, 2, 18, 15, 3, 16, 21, 12, 17, 25, 6, 16, 19, 12],\n",
              " [25, 11, 2, 18, 15, 3, 16, 21, 12, 17, 25, 6, 16, 19, 12, 11, 25, 16, 11, 19],\n",
              " [3, 16, 21, 12, 17, 25, 6, 16, 19, 12, 11, 25, 16, 11, 19, 19, 18, 13, 0, 16],\n",
              " [25, 6, 16, 19, 12, 11, 25, 16, 11, 19, 19, 18, 13, 0, 16, 18, 15, 26, 0, 6],\n",
              " [11, 25, 16, 11, 19, 19, 18, 13, 0, 16, 18, 15, 26, 0, 6, 0, 15, 26, 0, 15],\n",
              " [19, 18, 13, 0, 16, 18, 15, 26, 0, 6, 0, 15, 26, 0, 15, 21, 20, 16, 14, 20],\n",
              " [18, 15, 26, 0, 6, 0, 15, 26, 0, 15, 21, 20, 16, 14, 20, 16, 10, 0, 1, 1],\n",
              " [0, 15, 26, 0, 15, 21, 20, 16, 14, 20, 16, 10, 0, 1, 1, 16, 14, 20, 16, 26],\n",
              " [21, 20, 16, 14, 20, 16, 10, 0, 1, 1, 16, 14, 20, 16, 26, 0, 25, 11, 13, 12],\n",
              " [16, 10, 0, 1, 1, 16, 14, 20, 16, 26, 0, 25, 11, 13, 12, 14, 21, 20, 16, 25],\n",
              " [16, 14, 20, 16, 26, 0, 25, 11, 13, 12, 14, 21, 20, 16, 25, 11, 20, 21, 1, 8],\n",
              " [0, 25, 11, 13, 12, 14, 21, 20, 16, 25, 11, 20, 21, 1, 8, 16, 20, 17, 6, 6],\n",
              " [14, 21, 20, 16, 25, 11, 20, 21, 1, 8, 16, 20, 17, 6, 6, 11, 12, 21, 16, 21],\n",
              " [11, 20, 21, 1, 8, 16, 20, 17, 6, 6, 11, 12, 21, 16, 21, 23, 0, 16, 18, 25],\n",
              " [16, 20, 17, 6, 6, 11, 12, 21, 16, 21, 23, 0, 16, 18, 25, 6, 0, 14, 13, 23],\n",
              " [11, 12, 21, 16, 21, 23, 0, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16],\n",
              " [23, 0, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 18, 15, 5, 17, 18],\n",
              " [6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 18, 15, 5, 17, 18, 12, 8, 16, 10, 23],\n",
              " [25, 0, 15, 21, 16, 18, 15, 5, 17, 18, 12, 8, 16, 10, 23, 18, 1, 0, 16, 12],\n",
              " [18, 15, 5, 17, 18, 12, 8, 16, 10, 23, 18, 1, 0, 16, 12, 0, 6, 17, 22, 1],\n",
              " [12, 8, 16, 10, 23, 18, 1, 0, 16, 12, 0, 6, 17, 22, 1, 18, 13, 14, 15, 20],\n",
              " [18, 1, 0, 16, 12, 0, 6, 17, 22, 1, 18, 13, 14, 15, 20, 16, 14, 12, 0, 16],\n",
              " [0, 6, 17, 22, 1, 18, 13, 14, 15, 20, 16, 14, 12, 0, 16, 25, 11, 20, 21, 1],\n",
              " [18, 13, 14, 15, 20, 16, 14, 12, 0, 16, 25, 11, 20, 21, 1, 8, 16, 23, 11, 1],\n",
              " [16, 14, 12, 0, 16, 25, 11, 20, 21, 1, 8, 16, 23, 11, 1, 26, 18, 15, 3, 16],\n",
              " [25, 11, 20, 21, 1, 8, 16, 23, 11, 1, 26, 18, 15, 3, 16, 21, 18, 3, 23, 21],\n",
              " [8, 16, 23, 11, 1, 26, 18, 15, 3, 16, 21, 18, 3, 23, 21, 16, 21, 23, 0, 20],\n",
              " [26, 18, 15, 3, 16, 21, 18, 3, 23, 21, 16, 21, 23, 0, 20, 0, 16, 21, 23, 18],\n",
              " [21, 18, 3, 23, 21, 16, 21, 23, 0, 20, 0, 16, 21, 23, 18, 15, 3, 20, 16, 25],\n",
              " [16, 21, 23, 0, 20, 0, 16, 21, 23, 18, 15, 3, 20, 16, 25, 14, 8, 16, 11, 12],\n",
              " [0, 16, 21, 23, 18, 15, 3, 20, 16, 25, 14, 8, 16, 11, 12, 16, 25, 14, 8, 16],\n",
              " [15, 3, 20, 16, 25, 14, 8, 16, 11, 12, 16, 25, 14, 8, 16, 15, 11, 21, 16, 13],\n",
              " [14, 8, 16, 11, 12, 16, 25, 14, 8, 16, 15, 11, 21, 16, 13, 23, 14, 15, 3, 0],\n",
              " [16, 25, 14, 8, 16, 15, 11, 21, 16, 13, 23, 14, 15, 3, 0, 0, 18, 21, 23, 0],\n",
              " [15, 11, 21, 16, 13, 23, 14, 15, 3, 0, 0, 18, 21, 23, 0, 12, 16, 10, 14, 8],\n",
              " [23, 14, 15, 3, 0, 0, 18, 21, 23, 0, 12, 16, 10, 14, 8, 16, 10, 0, 16, 10],\n",
              " [0, 18, 21, 23, 0, 12, 16, 10, 14, 8, 16, 10, 0, 16, 10, 18, 1, 1, 16, 22],\n",
              " [12, 16, 10, 14, 8, 16, 10, 0, 16, 10, 18, 1, 1, 16, 22, 0, 16, 13, 23, 14],\n",
              " [16, 10, 0, 16, 10, 18, 1, 1, 16, 22, 0, 16, 13, 23, 14, 15, 3, 0, 26, 16],\n",
              " [18, 1, 1, 16, 22, 0, 16, 13, 23, 14, 15, 3, 0, 26, 16, 18, 19, 16, 10, 0],\n",
              " [0, 16, 13, 23, 14, 15, 3, 0, 26, 16, 18, 19, 16, 10, 0, 16, 26, 11, 16, 15],\n",
              " [15, 3, 0, 26, 16, 18, 19, 16, 10, 0, 16, 26, 11, 16, 15, 11, 21, 16, 12, 18],\n",
              " [18,\n",
              "  19,\n",
              "  16,\n",
              "  10,\n",
              "  0,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  12,\n",
              "  18,\n",
              "  3,\n",
              "  23,\n",
              "  21,\n",
              "  16,\n",
              "  21],\n",
              " [16,\n",
              "  26,\n",
              "  11,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  12,\n",
              "  18,\n",
              "  3,\n",
              "  23,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  20],\n",
              " [11,\n",
              "  21,\n",
              "  16,\n",
              "  12,\n",
              "  18,\n",
              "  3,\n",
              "  23,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  20,\n",
              "  23,\n",
              "  18,\n",
              "  6,\n",
              "  16,\n",
              "  11],\n",
              " [3, 23, 21, 16, 21, 23, 18, 20, 16, 20, 23, 18, 6, 16, 11, 19, 16, 26, 0, 25],\n",
              " [23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  20,\n",
              "  23,\n",
              "  18,\n",
              "  6,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  16,\n",
              "  26,\n",
              "  0,\n",
              "  25,\n",
              "  11,\n",
              "  13,\n",
              "  12,\n",
              "  14,\n",
              "  13],\n",
              " [23, 18, 6, 16, 11, 19, 16, 26, 0, 25, 11, 13, 12, 14, 13, 8, 18, 25, 6, 0],\n",
              " [19, 16, 26, 0, 25, 11, 13, 12, 14, 13, 8, 18, 25, 6, 0, 14, 13, 23, 25, 0],\n",
              " [11, 13, 12, 14, 13, 8, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 18, 20],\n",
              " [8, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 18, 20, 16, 15, 11, 21, 16],\n",
              " [14,\n",
              "  13,\n",
              "  23,\n",
              "  25,\n",
              "  0,\n",
              "  15,\n",
              "  21,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  14,\n",
              "  22,\n",
              "  11,\n",
              "  17,\n",
              "  21],\n",
              " [15,\n",
              "  21,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  14,\n",
              "  22,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16,\n",
              "  6,\n",
              "  17,\n",
              "  15,\n",
              "  18],\n",
              " [16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  14,\n",
              "  22,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16,\n",
              "  6,\n",
              "  17,\n",
              "  15,\n",
              "  18,\n",
              "  20,\n",
              "  23,\n",
              "  25,\n",
              "  0,\n",
              "  15],\n",
              " [14, 22, 11, 17, 21, 16, 6, 17, 15, 18, 20, 23, 25, 0, 15, 21, 16, 18, 25, 6],\n",
              " [16, 6, 17, 15, 18, 20, 23, 25, 0, 15, 21, 16, 18, 25, 6, 0, 14, 13, 23, 25],\n",
              " [20, 23, 25, 0, 15, 21, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 18],\n",
              " [21, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 18, 20, 16, 14, 22, 11],\n",
              " [0, 14, 13, 23, 25, 0, 15, 21, 16, 18, 20, 16, 14, 22, 11, 17, 21, 16, 13, 1],\n",
              " [0, 15, 21, 16, 18, 20, 16, 14, 22, 11, 17, 21, 16, 13, 1, 0, 14, 15, 20, 18],\n",
              " [20, 16, 14, 22, 11, 17, 21, 16, 13, 1, 0, 14, 15, 20, 18, 15, 3, 16, 21, 23],\n",
              " [17, 21, 16, 13, 1, 0, 14, 15, 20, 18, 15, 3, 16, 21, 23, 0, 16, 11, 19, 19],\n",
              " [0, 14, 15, 20, 18, 15, 3, 16, 21, 23, 0, 16, 11, 19, 19, 18, 13, 0, 16, 18],\n",
              " [15, 3, 16, 21, 23, 0, 16, 11, 19, 19, 18, 13, 0, 16, 18, 25, 6, 0, 14, 13],\n",
              " [0, 16, 11, 19, 19, 18, 13, 0, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21],\n",
              " [18, 13, 0, 16, 18, 25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 18, 20, 16, 14],\n",
              " [25, 6, 0, 14, 13, 23, 25, 0, 15, 21, 16, 18, 20, 16, 14, 22, 11, 17, 21, 16],\n",
              " [23,\n",
              "  25,\n",
              "  0,\n",
              "  15,\n",
              "  21,\n",
              "  16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  22,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16,\n",
              "  12,\n",
              "  0,\n",
              "  20,\n",
              "  21,\n",
              "  11],\n",
              " [16,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  22,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16,\n",
              "  12,\n",
              "  0,\n",
              "  20,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  16],\n",
              " [22,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16,\n",
              "  12,\n",
              "  0,\n",
              "  20,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  16,\n",
              "  23,\n",
              "  11,\n",
              "  15,\n",
              "  11,\n",
              "  12],\n",
              " [12,\n",
              "  0,\n",
              "  20,\n",
              "  21,\n",
              "  11,\n",
              "  12,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  16,\n",
              "  23,\n",
              "  11,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16],\n",
              " [12, 18, 15, 3, 16, 23, 11, 15, 11, 12, 16, 14, 15, 26, 16, 18, 15, 21, 0, 3],\n",
              " [23, 11, 15, 11, 12, 16, 14, 15, 26, 16, 18, 15, 21, 0, 3, 12, 18, 21, 8, 16],\n",
              " [16, 14, 15, 26, 16, 18, 15, 21, 0, 3, 12, 18, 21, 8, 16, 21, 11, 16, 21, 23],\n",
              " [18, 15, 21, 0, 3, 12, 18, 21, 8, 16, 21, 11, 16, 21, 23, 0, 16, 11, 19, 19],\n",
              " [12, 18, 21, 8, 16, 21, 11, 16, 21, 23, 0, 16, 11, 19, 19, 18, 13, 0, 16, 10],\n",
              " [21, 11, 16, 21, 23, 0, 16, 11, 19, 19, 18, 13, 0, 16, 10, 0, 16, 20, 23, 11],\n",
              " [0, 16, 11, 19, 19, 18, 13, 0, 16, 10, 0, 16, 20, 23, 11, 17, 1, 26, 16, 23],\n",
              " [18, 13, 0, 16, 10, 0, 16, 20, 23, 11, 17, 1, 26, 16, 23, 0, 0, 26, 16, 21],\n",
              " [0, 16, 20, 23, 11, 17, 1, 26, 16, 23, 0, 0, 26, 16, 21, 23, 0, 20, 0, 16],\n",
              " [17, 1, 26, 16, 23, 0, 0, 26, 16, 21, 23, 0, 20, 0, 16, 10, 11, 12, 26, 20],\n",
              " [0, 0, 26, 16, 21, 23, 0, 20, 0, 16, 10, 11, 12, 26, 20, 16, 20, 6, 11, 24],\n",
              " [23, 0, 20, 0, 16, 10, 11, 12, 26, 20, 16, 20, 6, 11, 24, 0, 15, 16, 22, 8],\n",
              " [10, 11, 12, 26, 20, 16, 20, 6, 11, 24, 0, 15, 16, 22, 8, 16, 21, 23, 0, 2],\n",
              " [16, 20, 6, 11, 24, 0, 15, 16, 22, 8, 16, 21, 23, 0, 2, 0, 12, 20, 18, 11],\n",
              " [0, 15, 16, 22, 8, 16, 21, 23, 0, 2, 0, 12, 20, 18, 11, 15, 16, 11, 19, 16],\n",
              " [16, 21, 23, 0, 2, 0, 12, 20, 18, 11, 15, 16, 11, 19, 16, 20, 0, 15, 16, 1],\n",
              " [0, 12, 20, 18, 11, 15, 16, 11, 19, 16, 20, 0, 15, 16, 1, 18, 15, 26, 20, 0],\n",
              " [15, 16, 11, 19, 16, 20, 0, 15, 16, 1, 18, 15, 26, 20, 0, 8, 16, 11, 16, 3],\n",
              " [20, 0, 15, 16, 1, 18, 15, 26, 20, 0, 8, 16, 11, 16, 3, 12, 14, 23, 14, 25],\n",
              " [18, 15, 26, 20, 0, 8, 16, 11, 16, 3, 12, 14, 23, 14, 25, 16, 12, 20, 13, 16],\n",
              " [8, 16, 11, 16, 3, 12, 14, 23, 14, 25, 16, 12, 20, 13, 16, 21, 23, 0, 16, 19],\n",
              " [12,\n",
              "  14,\n",
              "  23,\n",
              "  14,\n",
              "  25,\n",
              "  16,\n",
              "  12,\n",
              "  20,\n",
              "  13,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  26],\n",
              " [16,\n",
              "  12,\n",
              "  20,\n",
              "  13,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  11],\n",
              " [21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14],\n",
              " [18,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  26,\n",
              "  18,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  12,\n",
              "  21,\n",
              "  16,\n",
              "  10,\n",
              "  18],\n",
              " [18,\n",
              "  26,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  21,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  12,\n",
              "  21,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  17,\n",
              "  24],\n",
              " [21,\n",
              "  16,\n",
              "  20,\n",
              "  21,\n",
              "  14,\n",
              "  12,\n",
              "  21,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  17,\n",
              "  24,\n",
              "  12,\n",
              "  14,\n",
              "  18,\n",
              "  15,\n",
              "  0],\n",
              " [12,\n",
              "  21,\n",
              "  16,\n",
              "  10,\n",
              "  18,\n",
              "  21,\n",
              "  23,\n",
              "  16,\n",
              "  17,\n",
              "  24,\n",
              "  12,\n",
              "  14,\n",
              "  18,\n",
              "  15,\n",
              "  0,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  15,\n",
              "  0],\n",
              " [21, 23, 16, 17, 24, 12, 14, 18, 15, 0, 16, 15, 11, 15, 0, 21, 23, 0, 1, 0],\n",
              " [12, 14, 18, 15, 0, 16, 15, 11, 15, 0, 21, 23, 0, 1, 0, 20, 20, 16, 17, 24],\n",
              " [16, 15, 11, 15, 0, 21, 23, 0, 1, 0, 20, 20, 16, 17, 24, 12, 14, 18, 15, 0],\n",
              " [21, 23, 0, 1, 0, 20, 20, 16, 17, 24, 12, 14, 18, 15, 0, 16, 25, 14, 8, 16],\n",
              " [20, 20, 16, 17, 24, 12, 14, 18, 15, 0, 16, 25, 14, 8, 16, 3, 18, 2, 0, 16],\n",
              " [12, 14, 18, 15, 0, 16, 25, 14, 8, 16, 3, 18, 2, 0, 16, 17, 20, 16, 21, 23],\n",
              " [16, 25, 14, 8, 16, 3, 18, 2, 0, 16, 17, 20, 16, 21, 23, 0, 16, 10, 14, 21],\n",
              " [3, 18, 2, 0, 16, 17, 20, 16, 21, 23, 0, 16, 10, 14, 21, 0, 12, 16, 21, 11],\n",
              " [17,\n",
              "  20,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  10,\n",
              "  14,\n",
              "  21,\n",
              "  0,\n",
              "  12,\n",
              "  16,\n",
              "  21,\n",
              "  11,\n",
              "  16,\n",
              "  19,\n",
              "  18,\n",
              "  15,\n",
              "  14],\n",
              " [0, 16, 10, 14, 21, 0, 12, 16, 21, 11, 16, 19, 18, 15, 14, 1, 1, 8, 16, 6],\n",
              " [0, 12, 16, 21, 11, 16, 19, 18, 15, 14, 1, 1, 8, 16, 6, 17, 21, 16, 18, 21],\n",
              " [16, 19, 18, 15, 14, 1, 1, 8, 16, 6, 17, 21, 16, 18, 21, 16, 11, 17, 21, 12],\n",
              " [1, 1, 8, 16, 6, 17, 21, 16, 18, 21, 16, 11, 17, 21, 12, 0, 14, 26, 16, 25],\n",
              " [17,\n",
              "  21,\n",
              "  16,\n",
              "  18,\n",
              "  21,\n",
              "  16,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  12,\n",
              "  0,\n",
              "  14,\n",
              "  26,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  19],\n",
              " [16,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  12,\n",
              "  0,\n",
              "  14,\n",
              "  26,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  19,\n",
              "  12,\n",
              "  11,\n",
              "  25,\n",
              "  16,\n",
              "  26],\n",
              " [0,\n",
              "  14,\n",
              "  26,\n",
              "  16,\n",
              "  25,\n",
              "  11,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  19,\n",
              "  12,\n",
              "  11,\n",
              "  25,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  15,\n",
              "  15,\n",
              "  14,\n",
              "  16],\n",
              " [11,\n",
              "  12,\n",
              "  0,\n",
              "  16,\n",
              "  19,\n",
              "  12,\n",
              "  11,\n",
              "  25,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  15,\n",
              "  15,\n",
              "  14,\n",
              "  16,\n",
              "  19,\n",
              "  16,\n",
              "  0,\n",
              "  26,\n",
              "  10],\n",
              " [12,\n",
              "  11,\n",
              "  25,\n",
              "  16,\n",
              "  26,\n",
              "  11,\n",
              "  15,\n",
              "  15,\n",
              "  14,\n",
              "  16,\n",
              "  19,\n",
              "  16,\n",
              "  0,\n",
              "  26,\n",
              "  10,\n",
              "  14,\n",
              "  12,\n",
              "  26,\n",
              "  20,\n",
              "  20],\n",
              " [11,\n",
              "  15,\n",
              "  15,\n",
              "  14,\n",
              "  16,\n",
              "  19,\n",
              "  16,\n",
              "  0,\n",
              "  26,\n",
              "  10,\n",
              "  14,\n",
              "  12,\n",
              "  26,\n",
              "  20,\n",
              "  20,\n",
              "  16,\n",
              "  14,\n",
              "  12,\n",
              "  13,\n",
              "  23],\n",
              " [19, 16, 0, 26, 10, 14, 12, 26, 20, 20, 16, 14, 12, 13, 23, 18, 2, 0, 16, 10],\n",
              " [14, 12, 26, 20, 20, 16, 14, 12, 13, 23, 18, 2, 0, 16, 10, 23, 0, 15, 16, 6],\n",
              " [16, 14, 12, 13, 23, 18, 2, 0, 16, 10, 23, 0, 15, 16, 6, 12, 0, 20, 18, 26],\n",
              " [18, 2, 0, 16, 10, 23, 0, 15, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 16, 21],\n",
              " [23, 0, 15, 16, 6, 12, 0, 20, 18, 26, 0, 15, 21, 16, 21, 12, 17, 25, 6, 16],\n",
              " [12, 0, 20, 18, 26, 0, 15, 21, 16, 21, 12, 17, 25, 6, 16, 14, 15, 15, 11, 17],\n",
              " [0, 15, 21, 16, 21, 12, 17, 25, 6, 16, 14, 15, 15, 11, 17, 15, 13, 0, 26, 16],\n",
              " [12,\n",
              "  17,\n",
              "  25,\n",
              "  6,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  15,\n",
              "  11,\n",
              "  17,\n",
              "  15,\n",
              "  13,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  26],\n",
              " [14,\n",
              "  15,\n",
              "  15,\n",
              "  11,\n",
              "  17,\n",
              "  15,\n",
              "  13,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  26,\n",
              "  0,\n",
              "  13,\n",
              "  18,\n",
              "  20,\n",
              "  18],\n",
              " [15,\n",
              "  13,\n",
              "  0,\n",
              "  26,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  26,\n",
              "  0,\n",
              "  13,\n",
              "  18,\n",
              "  20,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  21,\n",
              "  11],\n",
              " [23, 18, 20, 16, 26, 0, 13, 18, 20, 18, 11, 15, 16, 21, 11, 16, 6, 17, 1, 1],\n",
              " [0, 13, 18, 20, 18, 11, 15, 16, 21, 11, 16, 6, 17, 1, 1, 16, 21, 12, 11, 11],\n",
              " [11, 15, 16, 21, 11, 16, 6, 17, 1, 1, 16, 21, 12, 11, 11, 6, 20, 16, 19, 12],\n",
              " [16, 6, 17, 1, 1, 16, 21, 12, 11, 11, 6, 20, 16, 19, 12, 11, 25, 16, 15, 11],\n",
              " [16,\n",
              "  21,\n",
              "  12,\n",
              "  11,\n",
              "  11,\n",
              "  6,\n",
              "  20,\n",
              "  16,\n",
              "  19,\n",
              "  12,\n",
              "  11,\n",
              "  25,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  12],\n",
              " [6, 20, 16, 19, 12, 11, 25, 16, 15, 11, 12, 21, 23, 0, 12, 15, 16, 20, 8, 12],\n",
              " [11,\n",
              "  25,\n",
              "  16,\n",
              "  15,\n",
              "  11,\n",
              "  12,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  12,\n",
              "  15,\n",
              "  16,\n",
              "  20,\n",
              "  8,\n",
              "  12,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  23,\n",
              "  18],\n",
              " [12,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  12,\n",
              "  15,\n",
              "  16,\n",
              "  20,\n",
              "  8,\n",
              "  12,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  13,\n",
              "  12,\n",
              "  18],\n",
              " [15,\n",
              "  16,\n",
              "  20,\n",
              "  8,\n",
              "  12,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  13,\n",
              "  12,\n",
              "  18,\n",
              "  21,\n",
              "  18,\n",
              "  13,\n",
              "  20,\n",
              "  16],\n",
              " [18,\n",
              "  14,\n",
              "  16,\n",
              "  23,\n",
              "  18,\n",
              "  20,\n",
              "  16,\n",
              "  13,\n",
              "  12,\n",
              "  18,\n",
              "  21,\n",
              "  18,\n",
              "  13,\n",
              "  20,\n",
              "  16,\n",
              "  18,\n",
              "  25,\n",
              "  25,\n",
              "  0,\n",
              "  26],\n",
              " [20, 16, 13, 12, 18, 21, 18, 13, 20, 16, 18, 25, 25, 0, 26, 18, 14, 21, 0, 1],\n",
              " [21, 18, 13, 20, 16, 18, 25, 25, 0, 26, 18, 14, 21, 0, 1, 8, 16, 10, 14, 12],\n",
              " [18, 25, 25, 0, 26, 18, 14, 21, 0, 1, 8, 16, 10, 14, 12, 15, 0, 26, 16, 21],\n",
              " [18, 14, 21, 0, 1, 8, 16, 10, 14, 12, 15, 0, 26, 16, 21, 23, 14, 21, 16, 21],\n",
              " [8, 16, 10, 14, 12, 15, 0, 26, 16, 21, 23, 14, 21, 16, 21, 23, 0, 16, 25, 11],\n",
              " [15, 0, 26, 16, 21, 23, 14, 21, 16, 21, 23, 0, 16, 25, 11, 2, 0, 16, 10, 11],\n",
              " [23, 14, 21, 16, 21, 23, 0, 16, 25, 11, 2, 0, 16, 10, 11, 17, 1, 26, 16, 6],\n",
              " [23, 0, 16, 25, 11, 2, 0, 16, 10, 11, 17, 1, 26, 16, 6, 14, 2, 0, 16, 21],\n",
              " [2, 0, 16, 10, 11, 17, 1, 26, 16, 6, 14, 2, 0, 16, 21, 23, 0, 16, 10, 14],\n",
              " [17, 1, 26, 16, 6, 14, 2, 0, 16, 21, 23, 0, 16, 10, 14, 8, 16, 19, 11, 12],\n",
              " [14, 2, 0, 16, 21, 23, 0, 16, 10, 14, 8, 16, 19, 11, 12, 16, 14, 16, 21, 17],\n",
              " [23,\n",
              "  0,\n",
              "  16,\n",
              "  10,\n",
              "  14,\n",
              "  8,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  21,\n",
              "  17,\n",
              "  12,\n",
              "  24,\n",
              "  18,\n",
              "  20,\n",
              "  23],\n",
              " [8,\n",
              "  16,\n",
              "  19,\n",
              "  11,\n",
              "  12,\n",
              "  16,\n",
              "  14,\n",
              "  16,\n",
              "  21,\n",
              "  17,\n",
              "  12,\n",
              "  24,\n",
              "  18,\n",
              "  20,\n",
              "  23,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  19,\n",
              "  0],\n",
              " [16, 14, 16, 21, 17, 12, 24, 18, 20, 23, 16, 11, 19, 19, 0, 15, 20, 18, 2, 0],\n",
              " [12, 24, 18, 20, 23, 16, 11, 19, 19, 0, 15, 20, 18, 2, 0, 16, 10, 18, 21, 23],\n",
              " [16, 11, 19, 19, 0, 15, 20, 18, 2, 0, 16, 10, 18, 21, 23, 16, 6, 11, 21, 0],\n",
              " [15, 20, 18, 2, 0, 16, 10, 18, 21, 23, 16, 6, 11, 21, 0, 15, 21, 18, 14, 1],\n",
              " [16, 10, 18, 21, 23, 16, 6, 11, 21, 0, 15, 21, 18, 14, 1, 1, 8, 16, 13, 14],\n",
              " [16, 6, 11, 21, 0, 15, 21, 18, 14, 1, 1, 8, 16, 13, 14, 21, 14, 20, 21, 12],\n",
              " [15, 21, 18, 14, 1, 1, 8, 16, 13, 14, 21, 14, 20, 21, 12, 11, 6, 23, 18, 13],\n",
              " [1, 8, 16, 13, 14, 21, 14, 20, 21, 12, 11, 6, 23, 18, 13, 16, 12, 0, 6, 0],\n",
              " [21, 14, 20, 21, 12, 11, 6, 23, 18, 13, 16, 12, 0, 6, 0, 12, 13, 17, 20, 20],\n",
              " [11, 6, 23, 18, 13, 16, 12, 0, 6, 0, 12, 13, 17, 20, 20, 18, 11, 15, 20, 20],\n",
              " [16, 12, 0, 6, 0, 12, 13, 17, 20, 20, 18, 11, 15, 20, 20, 21, 14, 21, 0, 16],\n",
              " [12, 13, 17, 20, 20, 18, 11, 15, 20, 20, 21, 14, 21, 0, 16, 26, 0, 6, 14, 12],\n",
              " [18, 11, 15, 20, 20, 21, 14, 21, 0, 16, 26, 0, 6, 14, 12, 21, 25, 0, 15, 21],\n",
              " [21, 14, 21, 0, 16, 26, 0, 6, 14, 12, 21, 25, 0, 15, 21, 16, 11, 19, 19, 18],\n",
              " [26, 0, 6, 14, 12, 21, 25, 0, 15, 21, 16, 11, 19, 19, 18, 13, 18, 14, 1, 20],\n",
              " [21,\n",
              "  25,\n",
              "  0,\n",
              "  15,\n",
              "  21,\n",
              "  16,\n",
              "  11,\n",
              "  19,\n",
              "  19,\n",
              "  18,\n",
              "  13,\n",
              "  18,\n",
              "  14,\n",
              "  1,\n",
              "  20,\n",
              "  16,\n",
              "  20,\n",
              "  10,\n",
              "  18,\n",
              "  19],\n",
              " [16, 11, 19, 19, 18, 13, 18, 14, 1, 20, 16, 20, 10, 18, 19, 21, 1, 8, 16, 26],\n",
              " [13, 18, 14, 1, 20, 16, 20, 10, 18, 19, 21, 1, 8, 16, 26, 0, 15, 18, 0, 26],\n",
              " [16, 20, 10, 18, 19, 21, 1, 8, 16, 26, 0, 15, 18, 0, 26, 16, 21, 23, 14, 21],\n",
              " [21, 1, 8, 16, 26, 0, 15, 18, 0, 26, 16, 21, 23, 14, 21, 16, 21, 12, 17, 25],\n",
              " [0, 15, 18, 0, 26, 16, 21, 23, 14, 21, 16, 21, 12, 17, 25, 6, 16, 20, 17, 6],\n",
              " [16, 21, 23, 14, 21, 16, 21, 12, 17, 25, 6, 16, 20, 17, 6, 6, 11, 12, 21, 0],\n",
              " [16, 21, 12, 17, 25, 6, 16, 20, 17, 6, 6, 11, 12, 21, 0, 26, 16, 21, 23, 0],\n",
              " [6, 16, 20, 17, 6, 6, 11, 12, 21, 0, 26, 16, 21, 23, 0, 16, 21, 17, 12, 24],\n",
              " [6, 11, 12, 21, 0, 26, 16, 21, 23, 0, 16, 21, 17, 12, 24, 18, 20, 23, 16, 18],\n",
              " [26,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  21,\n",
              "  17,\n",
              "  12,\n",
              "  24,\n",
              "  18,\n",
              "  20,\n",
              "  23,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  13,\n",
              "  17,\n",
              "  12,\n",
              "  20],\n",
              " [16,\n",
              "  21,\n",
              "  17,\n",
              "  12,\n",
              "  24,\n",
              "  18,\n",
              "  20,\n",
              "  23,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  13,\n",
              "  17,\n",
              "  12,\n",
              "  20,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  25],\n",
              " [18,\n",
              "  20,\n",
              "  23,\n",
              "  16,\n",
              "  18,\n",
              "  15,\n",
              "  13,\n",
              "  17,\n",
              "  12,\n",
              "  20,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  25,\n",
              "  0,\n",
              "  14,\n",
              "  15,\n",
              "  10,\n",
              "  23],\n",
              " [15, 13, 17, 12, 20, 18, 11, 15, 16, 25, 0, 14, 15, 10, 23, 18, 1, 0, 16, 21],\n",
              " [18, 11, 15, 16, 25, 0, 14, 15, 10, 23, 18, 1, 0, 16, 21, 12, 17, 25, 6, 16],\n",
              " [0, 14, 15, 10, 23, 18, 1, 0, 16, 21, 12, 17, 25, 6, 16, 14, 6, 6, 0, 14],\n",
              " [18, 1, 0, 16, 21, 12, 17, 25, 6, 16, 14, 6, 6, 0, 14, 12, 0, 26, 16, 13],\n",
              " [12, 17, 25, 6, 16, 14, 6, 6, 0, 14, 12, 0, 26, 16, 13, 11, 15, 2, 18, 15],\n",
              " [14, 6, 6, 0, 14, 12, 0, 26, 16, 13, 11, 15, 2, 18, 15, 13, 0, 26, 16, 21],\n",
              " [12, 0, 26, 16, 13, 11, 15, 2, 18, 15, 13, 0, 26, 16, 21, 23, 14, 21, 16, 23],\n",
              " [11, 15, 2, 18, 15, 13, 0, 26, 16, 21, 23, 14, 21, 16, 23, 0, 16, 23, 14, 26],\n",
              " [13, 0, 26, 16, 21, 23, 14, 21, 16, 23, 0, 16, 23, 14, 26, 16, 25, 14, 26, 0],\n",
              " [23, 14, 21, 16, 23, 0, 16, 23, 14, 26, 16, 25, 14, 26, 0, 16, 21, 23, 0, 16],\n",
              " [0, 16, 23, 14, 26, 16, 25, 14, 26, 0, 16, 21, 23, 0, 16, 12, 18, 3, 23, 21],\n",
              " [16, 25, 14, 26, 0, 16, 21, 23, 0, 16, 12, 18, 3, 23, 21, 16, 13, 23, 11, 18],\n",
              " [16, 21, 23, 0, 16, 12, 18, 3, 23, 21, 16, 13, 23, 11, 18, 13, 0, 21, 17, 12],\n",
              " [12, 18, 3, 23, 21, 16, 13, 23, 11, 18, 13, 0, 21, 17, 12, 24, 0, 8, 16, 0],\n",
              " [16, 13, 23, 11, 18, 13, 0, 21, 17, 12, 24, 0, 8, 16, 0, 17, 12, 11, 6, 0],\n",
              " [13, 0, 21, 17, 12, 24, 0, 8, 16, 0, 17, 12, 11, 6, 0, 16, 20, 8, 12, 18],\n",
              " [24, 0, 8, 16, 0, 17, 12, 11, 6, 0, 16, 20, 8, 12, 18, 14, 16, 18, 12, 14],\n",
              " [17, 12, 11, 6, 0, 16, 20, 8, 12, 18, 14, 16, 18, 12, 14, 15, 16, 18, 12, 14],\n",
              " [16,\n",
              "  20,\n",
              "  8,\n",
              "  12,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  18,\n",
              "  12,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  18,\n",
              "  12,\n",
              "  14,\n",
              "  5,\n",
              "  16,\n",
              "  12,\n",
              "  17,\n",
              "  20],\n",
              " [14,\n",
              "  16,\n",
              "  18,\n",
              "  12,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  18,\n",
              "  12,\n",
              "  14,\n",
              "  5,\n",
              "  16,\n",
              "  12,\n",
              "  17,\n",
              "  20,\n",
              "  20,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  14],\n",
              " [15,\n",
              "  16,\n",
              "  18,\n",
              "  12,\n",
              "  14,\n",
              "  5,\n",
              "  16,\n",
              "  12,\n",
              "  17,\n",
              "  20,\n",
              "  20,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  23],\n",
              " [5,\n",
              "  16,\n",
              "  12,\n",
              "  17,\n",
              "  20,\n",
              "  20,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  24,\n",
              "  17,\n",
              "  12],\n",
              " [20,\n",
              "  18,\n",
              "  14,\n",
              "  16,\n",
              "  14,\n",
              "  15,\n",
              "  26,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  24,\n",
              "  17,\n",
              "  12,\n",
              "  26,\n",
              "  20,\n",
              "  16,\n",
              "  10,\n",
              "  18],\n",
              " [15, 26, 16, 21, 23, 0, 16, 24, 17, 12, 26, 20, 16, 10, 18, 1, 1, 16, 15, 11],\n",
              " [0, 16, 24, 17, 12, 26, 20, 16, 10, 18, 1, 1, 16, 15, 11, 10, 16, 23, 14, 2],\n",
              " [26, 20, 16, 10, 18, 1, 1, 16, 15, 11, 10, 16, 23, 14, 2, 0, 16, 21, 11, 16],\n",
              " [1, 1, 16, 15, 11, 10, 16, 23, 14, 2, 0, 16, 21, 11, 16, 19, 18, 3, 17, 12],\n",
              " [10, 16, 23, 14, 2, 0, 16, 21, 11, 16, 19, 18, 3, 17, 12, 0, 16, 21, 23, 0],\n",
              " [0, 16, 21, 11, 16, 19, 18, 3, 17, 12, 0, 16, 21, 23, 0, 16, 20, 18, 21, 17],\n",
              " [19, 18, 3, 17, 12, 0, 16, 21, 23, 0, 16, 20, 18, 21, 17, 14, 21, 18, 11, 15],\n",
              " [0,\n",
              "  16,\n",
              "  21,\n",
              "  23,\n",
              "  0,\n",
              "  16,\n",
              "  20,\n",
              "  18,\n",
              "  21,\n",
              "  17,\n",
              "  14,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16],\n",
              " [16,\n",
              "  20,\n",
              "  18,\n",
              "  21,\n",
              "  17,\n",
              "  14,\n",
              "  21,\n",
              "  18,\n",
              "  11,\n",
              "  15,\n",
              "  16,\n",
              "  11,\n",
              "  17,\n",
              "  21,\n",
              "  16,\n",
              "  21,\n",
              "  12,\n",
              "  17,\n",
              "  25,\n",
              "  6],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-8sI4cQv6V"
      },
      "source": [
        "`dctk.create_char_sequences()` first joins the text strings of the corpus of 136 documents into into a single text string, then splits that string into overlapping 20-character sequences, where the starting positions of the sequences are multiples of 5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51eJlIJWlWT4"
      },
      "source": [
        "`dctk.create_char_sequences()` <br>\n",
        "* produces a list `dctk.sequences` which contains 168985 20-character sequences from the input data, with each character encoded by the integer position in the character dictionary.<br>\n",
        "* produces a list `dctk.next_char` which contains the next character for each of the 168985 20-character sequences, encoded as its index in the character vocabulary.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "xJ929OX5h_l9",
        "outputId": "c759ba9a-4772-4788-b8c8-2026b3bf6204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The  27  unique characters are  ['e', 'l', 'v', 'g', 'j', 'q', 'p', 'z', 'y', 'x', 'w', 'o', 'r', 'c', 'a', 'n', ' ', 'u', 'i', 'f', 's', 't', 'b', 'h', 'k', 'm', 'd']\n",
            "<class 'list'>\n",
            "There are  168985 sequences\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[[13,\n",
              "  11,\n",
              "  15,\n",
              "  21,\n",
              "  12,\n",
              "  18,\n",
              "  22,\n",
              "  17,\n",
              "  21,\n",
              "  18,\n",
              "  15,\n",
              "  3,\n",
              "  16,\n",
              "  13,\n",
              "  11,\n",
              "  1,\n",
              "  17,\n",
              "  25,\n",
              "  15,\n",
              "  18],\n",
              " [18, 22, 17, 21, 18, 15, 3, 16, 13, 11, 1, 17, 25, 15, 18, 20, 21, 21, 23, 0]]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('The ',len(dctk.unique_chars),' unique characters are ',dctk.unique_chars)\n",
        "print(type(dctk.sequences))\n",
        "print('There are ',len(dctk.sequences),'sequences')\n",
        "display(dctk.sequences[:2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOZ4jcXfnQJl"
      },
      "source": [
        "For each sequence, `dctk.next_char` contains the integer encoding for the next character we are trying to predict. Here are the values of `next_char` for the first 10 sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8WFHJMTmO88",
        "outputId": "ff77320f-daf4-49a2-8bce-48c54949d8ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "168985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20, 16, 0, 11, 12, 26, 23, 23, 20, 26]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "print(len(dctk.next_char))\n",
        "dctk.next_char[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlmVXzV5nkHQ"
      },
      "source": [
        "The `dctk.create_X_and_Y` method produces X and y, which are the 1-hot encodings for the `sequence` and `next_char`.<br>\n",
        "The dimension of X will be (168985, 20, 27) and the dimension of y will be (168985, 27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "LlA1J_28hvKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c577adc1-b680-4335-8e52-1f35c0a8bd48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/data_cleaning_toolkit_class.py:163: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  x = np.zeros(x_dims, dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-6cf4783806be>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create X and y split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdctk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_X_and_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/data_cleaning_toolkit_class.py\u001b[0m in \u001b[0;36mcreate_X_and_Y\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# default values will all be zero ( i.e. look up docs for np.zeros() )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# recall that a value of zero is equivalent to False in Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'testing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "# create X and y split\n",
        "X, y = dctk.create_X_and_Y()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzYuQI60YWnG"
      },
      "source": [
        "Each character is represented as a one-hot encoded vector of length 27, with <br>\n",
        "positions corresponding to the \"vocabulary\" of all the possible characters. <br>\n",
        "There are 27 possible characters, including the space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufh4culCPqSm",
        "outputId": "3209da98-f736-4b3b-d852-673d71f98a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(168985, 20, 27)\n"
          ]
        }
      ],
      "source": [
        "print(type(X))\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgZVK4satU8_"
      },
      "source": [
        "Here is the one-hot encoding of the first character in the first sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMkNvNWQtT7b",
        "outputId": "f955be7e-023b-4c35-ab86-dd8380d61240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False  True False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(X[0,0,:])\n",
        "np.argmax(X[0,0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-FzGr7_x5ujx",
        "outputId": "f7976185-90c0-4a9d-aca1-4224c23f8341"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'c'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dctk.int_char[np.argmax(X[0,0,:])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kshRsHRgtwO-"
      },
      "source": [
        "The rows of y are the one-hot encodings of `next_char`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NprE_erXqQR",
        "outputId": "ef2be14f-bf39-43c0-c5b0-c1076957aca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(168985, 27)\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False  True False False False False False\n",
            " False False False]\n",
            "18\n"
          ]
        }
      ],
      "source": [
        "print(type(y))\n",
        "print(y.shape)\n",
        "print(y[0,:])\n",
        "print(np.argmax(y[0,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZhgxBrJ86Cen",
        "outputId": "4534944d-e15c-4c4d-c19c-788e5c17c71b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'s'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dctk.int_char[np.argmax(y[0,:])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IOK_p3U9uCL",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6a39513d81d87f1b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "9c3baedd-f380-496b-92cc-9bb3550a7b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "168985\n",
            "20\n",
            "[26, 3, 12, 8, 9, 11, 4, 24, 8, 11, 12, 5, 10, 26, 3, 25, 24, 20, 12, 11]\n"
          ]
        }
      ],
      "source": [
        "# dctk.sequences is our encoded doc-term matrix\n",
        "print(len(dctk.sequences))\n",
        "\n",
        "# each doc is maxlen values long\n",
        "print(len(dctk.sequences[0]))\n",
        "\n",
        "# want to know what this encoded document actually says?\n",
        "# you'll need to the char-int look up dictionaries\n",
        "print(dctk.sequences[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oufq8xNKz3T_"
      },
      "source": [
        "`dctm` also produces character-to-integer and integer-to-character dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laJUQImBSVJI",
        "outputId": "be371184-58aa-4de0-a619-2bae71e93a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'y': 0, 'h': 1, 'e': 2, 'o': 3, 'b': 4, 'g': 5, 'd': 6, 'w': 7, 't': 8, 'r': 9, ' ': 10, 'i': 11, 'n': 12, 'f': 13, 'k': 14, 'q': 15, 'z': 16, 'j': 17, 's': 18, 'p': 19, 'm': 20, 'v': 21, 'a': 22, 'x': 23, 'u': 24, 'l': 25, 'c': 26}\n",
            "{0: 'y', 1: 'h', 2: 'e', 3: 'o', 4: 'b', 5: 'g', 6: 'd', 7: 'w', 8: 't', 9: 'r', 10: ' ', 11: 'i', 12: 'n', 13: 'f', 14: 'k', 15: 'q', 16: 'z', 17: 'j', 18: 's', 19: 'p', 20: 'm', 21: 'v', 22: 'a', 23: 'x', 24: 'u', 25: 'l', 26: 'c'}\n"
          ]
        }
      ],
      "source": [
        "# character to index dictionary\n",
        "# keys are chars\n",
        "# vlaues are ints\n",
        "print(dctk.char_int)\n",
        "\n",
        "# index to char dictionary\n",
        "# keys are ints\n",
        "# values are chars\n",
        "print(dctk.int_char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUOiUSCuVyrS"
      },
      "source": [
        "#### Check that the character encoding works properly\n",
        "Use the integer-to-character dictionary to map the integer character encodings back to the characters they represent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed-GMMsU9uCL",
        "outputId": "aeee3ff7-81c8-438e-e4e8-58d9634d46be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(168985, 20, 27)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# (num_seqs, seq length, num features)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jb_oqtoSKY9",
        "outputId": "f755d6f3-87b0-4fbf-f64a-5c3efa3f4495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "i\n",
            "b\n",
            "u\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "c\n",
            "o\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "i\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "# now we can check to see that our encoding is correct\n",
        "for ind in dctk.sequences[0]:\n",
        "    print (dctk.int_char[ind])\n",
        "\n",
        "# number of features is the total number of unique chars in our corpus\n",
        "print(dctk.n_features)\n",
        "\n",
        "# (num_seqs, num features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9hrvWPun6xw"
      },
      "source": [
        "Each successive sequence (after the first) starts with the 6th character of the previous sequence. <br>\n",
        "By using overlapping sequences, we get more sequences to train with.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QN7InnwnnAJ",
        "outputId": "a06687b5-1086-4274-9a55-ce2537402fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i\n",
            "b\n",
            "u\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "c\n",
            "o\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "i\n",
            "s\n",
            "t\n",
            "t\n",
            "h\n",
            "e\n"
          ]
        }
      ],
      "source": [
        "for ind in dctk.sequences[1]:\n",
        "    print (dctk.int_char[ind])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkopT0P2dycm"
      },
      "source": [
        "We are building a language model to predict the next character in a sequence, <br>\n",
        "so each target y is the character following the 20th character of that sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Jxlm53Go4e",
        "outputId": "e740e881-fca5-4d43-df19-1bb06bfb4c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(168985, 27)\n",
            "[False False False  True False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False]\n",
            "3\n",
            "s\n"
          ]
        }
      ],
      "source": [
        "print(y.shape)\n",
        "print(y[0])\n",
        "print(np.argmax(y[0]))\n",
        "print (dctk.int_char[np.argmax(y[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bbhYydZpd_v"
      },
      "source": [
        "The code that generates `X` and `y` is in `data_cleaning_toolkit` method `create_X_and_Y()`.<br><br>\n",
        "For the sequence in the $i\\text{th}$ row of `X`, the character the language model is trying to predict should be the character that comes after the 20th character. If there were no overlap between rows, this would be the first character in the next row. But each row starts with the 5th character in the previous row. So the 21st character is actually the 16th character in the next row, i.e. at index 15! <br><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKDU1JaneiyL",
        "outputId": "14c85e1a-efe3-49e2-a4cc-10ebfb6b6b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11, 4, 24, 8, 11, 12, 5, 10, 26, 3, 25, 24, 20, 12, 11, 18, 8, 8, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "print( [np.argmax(X[1,i,:]) for i in range(20) ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQtxBVBupByq",
        "outputId": "f493b4cb-a77e-4d19-c4a2-3dd48fd14221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n",
            "[26, 18, 15, 1, 10, 12, 25, 19, 26, 11, 3, 24, 24, 21, 13, 15, 21, 10, 25, 3]\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(y[1]))\n",
        "print( [np.argmax(X[2,i,:]) for i in range(20) ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEeMZQPJpNi_",
        "outputId": "dc869b4f-22a4-436c-edd0-3bb34ea2968e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n",
            "[1, 17, 12, 5, 0, 16, 18, 18, 6, 7, 26, 6, 19, 17, 16, 7, 26, 0, 16, 26]\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(y[2]))\n",
        "print( [np.argmax(x[3,i,:]) for i in range(20) ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7vh28iwo8wJ"
      },
      "source": [
        "### Callback function `on_epoch_end`\n",
        "Provides feedback at the end of each epoch to help you gauge how your model is progressing:<br>\n",
        "Takes a sequence of 20 consecutive characters starting at a _randomly chosen_ position <br>\n",
        "in the articles corpus, predicts the next 20 characters using the current version <br>\n",
        "of the trained model, and prints these results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3y8ePgRz_Ov"
      },
      "source": [
        "`sample` is a helper function that generates a character by drawing a sample from a predicted probability distribution.<br>\n",
        "`temperature` is a hyper-parameter that, if different from 1, warps (narrows or broadens) the predicted probability distribution. <br>\n",
        "This can add some variety to the generated characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xgk-JomzwGX"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Helper function to generate a sample character\n",
        "    Input is a predictions vector from our model, for example a set of 27 character probabilities\n",
        "    Output is the index of the generated character\n",
        "    \"\"\"\n",
        "    # convert predictions to an array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "\n",
        "    # use the temperature hyper-parameter to \"warp\" (sharpen or spread out) the probability distribution\n",
        "    preds = np.log(preds) / temperature\n",
        "\n",
        "    # use the softmax activation function to create a new list of probabilities\n",
        "    #   corresponding to the \"warped\" probability distribution\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    # Draw a single sample from a multinomial distribution, given these probabilities\n",
        "    #   The sample will be a one-hot encoded character\n",
        "    \"\"\" Notes on the np.random.multinomial() function\n",
        "       The first argument is the number of \"trials\" we want: 1 in this case\n",
        "       The second argument is the list of probabilities for each character\n",
        "       The third argument is number of sets of \"trials\" we want: again, 1 in this case\n",
        "       By analogy with a dice-rolling experiment:\n",
        "          A \"trial\" consists of generating a single \"throw\" of a die with 27 faces;\n",
        "             each face corresponds to a character and its associated probability\n",
        "    \"\"\"\n",
        "\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "    # return the index that corresponds to the max probability\n",
        "    return np.argmax(probas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPhu860ZEd3g"
      },
      "source": [
        "Create the `on_epoch_end` function to be passed into `LambdaCallback()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn8EUXe29uCL"
      },
      "outputs": [],
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    \"\"\"\"\n",
        "    Function invoked at end of each epoch.\n",
        "    Prints the text generated by the current version of the model at this point\n",
        "    \"\"\"\n",
        "\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "\n",
        "    # randomly draw a starting position in the corpus\n",
        "    start_index = random.randint(0, len(text) - dctk.maxlen - 1)\n",
        "\n",
        "    # Initialize the \"seed\" string with maxlen consecutive characters beginning at start_index\n",
        "    seed = text[start_index: start_index + dctk.maxlen]\n",
        "\n",
        "    # number of consecutive characters to generate to follow the seed text\n",
        "    n_characters = 20\n",
        "\n",
        "    print('----- Generating with seed: \"' + seed + '\"')\n",
        "    sys.stdout.write(seed)\n",
        "\n",
        "    # generate n_characters predicted by the model to follow the seed string\n",
        "    for _ in range(n_characters):\n",
        "\n",
        "        # initialize an array to hold the current seed string\n",
        "        #    in numerical form (i.e. one-hot encoded)\n",
        "        # so the seed string is represented by an array of size (1, maxlen, 27)\n",
        "        x_seed = np.zeros((1, dctk.maxlen, dctk.n_features))\n",
        "\n",
        "        # create the one-hot encoded numerical representation of the seed string,\n",
        "        for index, char in enumerate(seed):\n",
        "            x_seed[0, index, dctk.char_int[char]] = 1\n",
        "\n",
        "        # get the predicted probability distribution (for the next character\n",
        "        #    after the seed string) from the current model\n",
        "        preds = model.predict(x_seed, verbose=0)[0]\n",
        "\n",
        "        # generate the character _index_ of the next character from a probability distribution based on the predicted probabilities\n",
        "        char_index = sample(preds)\n",
        "        # convert the character _index_ to the corresponding _character_ using the index-to-character dictionary\n",
        "        char = dctk.int_char[char_index]\n",
        "\n",
        "        # update the seed string by _dropping_ the first character and _adding_ the generated character at the end,\n",
        "        #   thus forming the 20 character sequence for the next prediction\n",
        "        seed = seed[1:] + char\n",
        "\n",
        "        # use the flush() function to prepare to write the next character\n",
        "        sys.stdout.write(char)\n",
        "        sys.stdout.flush()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O8868cBUy_2"
      },
      "source": [
        "Create the `print_callback`, usingn the `LambdaCallback` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0BFtoKUIM2x"
      },
      "outputs": [],
      "source": [
        "# create callback object that will print out text generation at the end of each epoch\n",
        "# use for real-time monitoring of model performance\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qIO5ZCcT-nV"
      },
      "source": [
        " Join all the news articles into one long text string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYl_K89k9uCM",
        "outputId": "0fe6dad7-2eb2-47a7-9932-0fd665225664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "844942\n"
          ]
        }
      ],
      "source": [
        "# join all the news articles into one long text string\n",
        "# need this for on_epoch_end()\n",
        "text = \" \".join(data)\n",
        "print(len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53AGJKhk9uCM"
      },
      "source": [
        "---------\n",
        "### Build a Text Generating Model from the News Articles Corpus\n",
        "We see that within 50 epochs, the model has begun to learn to form intelligible words, <br>and it's still slowly training, i.e. the loss function is decreasing at each epoch. <br>\n",
        "By 150 epochs, the generated text usually includes one or more recognizable words per 20 characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Ql4CF896Vc"
      },
      "source": [
        "Set up the Adam optimizer to allow changing the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7XeGd0a2MKi",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0b9d84be1c960668",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "2282e9fb-ce68-4080-8838-ad2a517a7933",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1308/1321 [============================>.] - ETA: 0s - loss: 2.4393\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"you hadnt noticed be\"\n",
            "you hadnt noticed begece d doplity fred \n",
            "1321/1321 [==============================] - 7s 5ms/step - loss: 2.4377\n",
            "Epoch 2/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 2.1494\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"o conquer it startin\"\n",
            "o conquer it startinateo bo reringont ya\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 2.1492\n",
            "Epoch 3/150\n",
            "1308/1321 [============================>.] - ETA: 0s - loss: 2.0270\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"y have to be treated\"\n",
            "y have to be treated oh praiss to ccunce\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 2.0268\n",
            "Epoch 4/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.9387\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \" life sentencesthen \"\n",
            " life sentencesthen tropms ther whiled f\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.9383\n",
            "Epoch 5/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.8672\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"gfor medical treatme\"\n",
            "gfor medical treatmest this in rejranyav\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.8672\n",
            "Epoch 6/150\n",
            "1321/1321 [==============================] - ETA: 0s - loss: 1.8083\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"ontent and computer \"\n",
            "ontent and computer are for pomicadil to\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.8083\n",
            "Epoch 7/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.7576\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"st order from morton\"\n",
            "st order from mortone of ha drohis in th\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.7576\n",
            "Epoch 8/150\n",
            "1308/1321 [============================>.] - ETA: 0s - loss: 1.7142\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"en freea tip on the \"\n",
            "en freea tip on the service worhord or t\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.7143\n",
            "Epoch 9/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 1.6764\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"en people hear that \"\n",
            "en people hear that hallomactagtom molts\n",
            "1321/1321 [==============================] - 6s 5ms/step - loss: 1.6761\n",
            "Epoch 10/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.6414\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \" upper hand in this \"\n",
            " upper hand in this impeans enforgation \n",
            "1321/1321 [==============================] - 6s 5ms/step - loss: 1.6414\n",
            "Epoch 11/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.6110\n",
            "----- Generating text after Epoch: 10\n",
            "----- Generating with seed: \"associated pressone \"\n",
            "associated pressone take llawerliesnay r\n",
            "1321/1321 [==============================] - 6s 5ms/step - loss: 1.6108\n",
            "Epoch 12/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.5831\n",
            "----- Generating text after Epoch: 11\n",
            "----- Generating with seed: \"d two touchdowns one\"\n",
            "d two touchdowns onerder elfogesties in \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.5831\n",
            "Epoch 13/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.5574\n",
            "----- Generating text after Epoch: 12\n",
            "----- Generating with seed: \" letters threatening\"\n",
            " letters threatening by hamos presidents\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.5576\n",
            "Epoch 14/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 1.5335\n",
            "----- Generating text after Epoch: 13\n",
            "----- Generating with seed: \"and obliterate the e\"\n",
            "and obliterate the eft your sealtneddam \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.5338\n",
            "Epoch 15/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.5125\n",
            "----- Generating text after Epoch: 14\n",
            "----- Generating with seed: \"le numbers that grow\"\n",
            "le numbers that growing the bax innotize\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.5126\n",
            "Epoch 16/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.4922\n",
            "----- Generating text after Epoch: 15\n",
            "----- Generating with seed: \"we needed that famil\"\n",
            "we needed that family meeling sturts woo\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.4922\n",
            "Epoch 17/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.4727\n",
            "----- Generating text after Epoch: 16\n",
            "----- Generating with seed: \"te frequently during\"\n",
            "te frequently during the jenw howing in \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.4727\n",
            "Epoch 18/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.4556\n",
            "----- Generating text after Epoch: 17\n",
            "----- Generating with seed: \"or stepped forward a\"\n",
            "or stepped forward at meluson edeagreecs\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.4553\n",
            "Epoch 19/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.4375\n",
            "----- Generating text after Epoch: 18\n",
            "----- Generating with seed: \" pointyoure making m\"\n",
            " pointyoure making mahnalapea go vick pe\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.4375\n",
            "Epoch 20/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.4217\n",
            "----- Generating text after Epoch: 19\n",
            "----- Generating with seed: \"when i got the first\"\n",
            "when i got the first publom here the cig\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.4217\n",
            "Epoch 21/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.4058\n",
            "----- Generating text after Epoch: 20\n",
            "----- Generating with seed: \"orhoods we dont care\"\n",
            "orhoods we dont care officians the endug\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.4058\n",
            "Epoch 22/150\n",
            "1309/1321 [============================>.] - ETA: 0s - loss: 1.3901\n",
            "----- Generating text after Epoch: 21\n",
            "----- Generating with seed: \"players for the rare\"\n",
            "players for the rare liblors are clear l\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.3905\n",
            "Epoch 23/150\n",
            "1308/1321 [============================>.] - ETA: 0s - loss: 1.3773\n",
            "----- Generating text after Epoch: 22\n",
            "----- Generating with seed: \"h you agree to keep \"\n",
            "h you agree to keep at que think they sa\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.3772\n",
            "Epoch 24/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.3625\n",
            "----- Generating text after Epoch: 23\n",
            "----- Generating with seed: \"for detailed informa\"\n",
            "for detailed information lookenists logu\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.3627\n",
            "Epoch 25/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 1.3497\n",
            "----- Generating text after Epoch: 24\n",
            "----- Generating with seed: \" such as manuel anto\"\n",
            " such as manuel antouse and brtantter ba\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.3497\n",
            "Epoch 26/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 1.3360\n",
            "----- Generating text after Epoch: 25\n",
            "----- Generating with seed: \"isk approach with hi\"\n",
            "isk approach with his will you welt on t\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.3364\n",
            "Epoch 27/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.3246\n",
            "----- Generating text after Epoch: 26\n",
            "----- Generating with seed: \"rces you to hold and\"\n",
            "rces you to hold and you intel jungures \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.3245\n",
            "Epoch 28/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.3124\n",
            "----- Generating text after Epoch: 27\n",
            "----- Generating with seed: \"ss to the digital pr\"\n",
            "ss to the digital probab surverty zefrom\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.3118\n",
            "Epoch 29/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.3000\n",
            "----- Generating text after Epoch: 28\n",
            "----- Generating with seed: \" and every departmen\"\n",
            " and every department whone wouldan the \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.3004\n",
            "Epoch 30/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.2887\n",
            "----- Generating text after Epoch: 29\n",
            "----- Generating with seed: \"one defender to beat\"\n",
            "one defender to beationed any thanphare \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2890\n",
            "Epoch 31/150\n",
            "1309/1321 [============================>.] - ETA: 0s - loss: 1.2781\n",
            "----- Generating text after Epoch: 30\n",
            "----- Generating with seed: \" with each rss excer\"\n",
            " with each rss excerative is shaws video\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2782\n",
            "Epoch 32/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.2670\n",
            "----- Generating text after Epoch: 31\n",
            "----- Generating with seed: \"chefsit is shipped f\"\n",
            "chefsit is shipped from recond the caple\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2675\n",
            "Epoch 33/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 1.2570\n",
            "----- Generating text after Epoch: 32\n",
            "----- Generating with seed: \"but now the rapidly \"\n",
            "but now the rapidly twiently and adminge\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2571\n",
            "Epoch 34/150\n",
            "1321/1321 [==============================] - ETA: 0s - loss: 1.2472\n",
            "----- Generating text after Epoch: 33\n",
            "----- Generating with seed: \"s history under the \"\n",
            "s history under the critic wheseles on t\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2472\n",
            "Epoch 35/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.2378\n",
            "----- Generating text after Epoch: 34\n",
            "----- Generating with seed: \"tour area farmspharo\"\n",
            "tour area farmspharo so our adfereas bil\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2379\n",
            "Epoch 36/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 1.2276\n",
            "----- Generating text after Epoch: 35\n",
            "----- Generating with seed: \"ping them with homew\"\n",
            "ping them with homewerd twieted to endec\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2276\n",
            "Epoch 37/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 1.2206\n",
            "----- Generating text after Epoch: 36\n",
            "----- Generating with seed: \"uch content on the s\"\n",
            "uch content on the sease of the kids sha\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2206\n",
            "Epoch 38/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 1.2119\n",
            "----- Generating text after Epoch: 37\n",
            "----- Generating with seed: \" dysfunction micronu\"\n",
            " dysfunction micronusiness you fave your\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2119\n",
            "Epoch 39/150\n",
            "1315/1321 [============================>.] - ETA: 0s - loss: 1.2025\n",
            "----- Generating text after Epoch: 38\n",
            "----- Generating with seed: \" united states trump\"\n",
            " united states trump jost neck to the co\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.2028\n",
            "Epoch 40/150\n",
            "1321/1321 [==============================] - ETA: 0s - loss: 1.1968\n",
            "----- Generating text after Epoch: 39\n",
            "----- Generating with seed: \"uld previously have \"\n",
            "uld previously have deachtold some chung\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1968\n",
            "Epoch 41/150\n",
            "1309/1321 [============================>.] - ETA: 0s - loss: 1.1881\n",
            "----- Generating text after Epoch: 40\n",
            "----- Generating with seed: \"ury morrogh said it \"\n",
            "ury morrogh said it enday more screebsly\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1880\n",
            "Epoch 42/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.1810\n",
            "----- Generating text after Epoch: 41\n",
            "----- Generating with seed: \"information shared i\"\n",
            "information shared indeminituicy is or p\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1810\n",
            "Epoch 43/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 1.1746\n",
            "----- Generating text after Epoch: 42\n",
            "----- Generating with seed: \"nd inspired awe and \"\n",
            "nd inspired awe and we chested to loats \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1749\n",
            "Epoch 44/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.1679\n",
            "----- Generating text after Epoch: 43\n",
            "----- Generating with seed: \"a new world for the \"\n",
            "a new world for the think to the prompti\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1678\n",
            "Epoch 45/150\n",
            "1309/1321 [============================>.] - ETA: 0s - loss: 1.1618\n",
            "----- Generating text after Epoch: 44\n",
            "----- Generating with seed: \"d a suicide pill in \"\n",
            "d a suicide pill in his was childrem new\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1622\n",
            "Epoch 46/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.1571\n",
            "----- Generating text after Epoch: 45\n",
            "----- Generating with seed: \"ease the barrier of \"\n",
            "ease the barrier of those leay to make t\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1574\n",
            "Epoch 47/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.1492\n",
            "----- Generating text after Epoch: 46\n",
            "----- Generating with seed: \"ing fibromyalgiather\"\n",
            "ing fibromyalgiathere unnishemeniingly p\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1493\n",
            "Epoch 48/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.1449\n",
            "----- Generating text after Epoch: 47\n",
            "----- Generating with seed: \" the forecast throug\"\n",
            " the forecast throughouts tweeted includ\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1451\n",
            "Epoch 49/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.1396\n",
            "----- Generating text after Epoch: 48\n",
            "----- Generating with seed: \" assisted the resear\"\n",
            " assisted the research inlected from whe\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1395\n",
            "Epoch 50/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 1.1336\n",
            "----- Generating text after Epoch: 49\n",
            "----- Generating with seed: \"rol of the washingto\"\n",
            "rol of the washington postwooking again \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1336\n",
            "Epoch 51/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.1296\n",
            "----- Generating text after Epoch: 50\n",
            "----- Generating with seed: \"e game lived down to\"\n",
            "e game lived down to continue about the \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1296\n",
            "Epoch 52/150\n",
            "1309/1321 [============================>.] - ETA: 0s - loss: 1.1239\n",
            "----- Generating text after Epoch: 51\n",
            "----- Generating with seed: \"scribe or unsubscrib\"\n",
            "scribe or unsubscribes injuttiors again \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1244\n",
            "Epoch 53/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.1192\n",
            "----- Generating text after Epoch: 52\n",
            "----- Generating with seed: \"ent deficiency insul\"\n",
            "ent deficiency insul kenoonced shootings\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1191\n",
            "Epoch 54/150\n",
            "1315/1321 [============================>.] - ETA: 0s - loss: 1.1157\n",
            "----- Generating text after Epoch: 53\n",
            "----- Generating with seed: \"an fox a professor o\"\n",
            "an fox a professor of produces helps not\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1156\n",
            "Epoch 55/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.1122\n",
            "----- Generating text after Epoch: 54\n",
            "----- Generating with seed: \"tedheckleradadit was\"\n",
            "tedheckleradadit was sochisl bedilg the \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1122\n",
            "Epoch 56/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.1078\n",
            "----- Generating text after Epoch: 55\n",
            "----- Generating with seed: \"k according to censu\"\n",
            "k according to censury of the united sta\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1079\n",
            "Epoch 57/150\n",
            "1315/1321 [============================>.] - ETA: 0s - loss: 1.1033\n",
            "----- Generating text after Epoch: 56\n",
            "----- Generating with seed: \"ns he still cant exp\"\n",
            "ns he still cant explisa blavkries somal\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.1034\n",
            "Epoch 58/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.0995\n",
            "----- Generating text after Epoch: 57\n",
            "----- Generating with seed: \" at any point in his\"\n",
            " at any point in historigg an inferent f\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0994\n",
            "Epoch 59/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.0970\n",
            "----- Generating text after Epoch: 58\n",
            "----- Generating with seed: \"st yearfrom the sovi\"\n",
            "st yearfrom the soviely as his accepting\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0969\n",
            "Epoch 60/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0924\n",
            "----- Generating text after Epoch: 59\n",
            "----- Generating with seed: \" and sentenced her t\"\n",
            " and sentenced her the battley to is a b\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0924\n",
            "Epoch 61/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0900\n",
            "----- Generating text after Epoch: 60\n",
            "----- Generating with seed: \"eighborhood which is\"\n",
            "eighborhood which isngwing jomesed sight\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0899\n",
            "Epoch 62/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.0862\n",
            "----- Generating text after Epoch: 61\n",
            "----- Generating with seed: \"rcetin and boswellia\"\n",
            "rcetin and boswellia had spicking on the\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0863\n",
            "Epoch 63/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 1.0841\n",
            "----- Generating text after Epoch: 62\n",
            "----- Generating with seed: \"wers died septatseth\"\n",
            "wers died septatsethe crassions now have\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0844\n",
            "Epoch 64/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.0823\n",
            "----- Generating text after Epoch: 63\n",
            "----- Generating with seed: \"elays omissions inte\"\n",
            "elays omissions interrislactrowe surport\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0823\n",
            "Epoch 65/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 1.0796\n",
            "----- Generating text after Epoch: 64\n",
            "----- Generating with seed: \"lack faces brown fac\"\n",
            "lack faces brown facters secontifiess se\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0798\n",
            "Epoch 66/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.0760\n",
            "----- Generating text after Epoch: 65\n",
            "----- Generating with seed: \"rite it the address \"\n",
            "rite it the address the caurt news he sa\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0761\n",
            "Epoch 67/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0731\n",
            "----- Generating text after Epoch: 66\n",
            "----- Generating with seed: \"black person paints \"\n",
            "black person paints terrs bread is make \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0729\n",
            "Epoch 68/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.0718\n",
            "----- Generating text after Epoch: 67\n",
            "----- Generating with seed: \" conspiracy to claim\"\n",
            " conspiracy to claim from disputity and \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0718\n",
            "Epoch 69/150\n",
            "1321/1321 [==============================] - ETA: 0s - loss: 1.0687\n",
            "----- Generating text after Epoch: 68\n",
            "----- Generating with seed: \" oversight of his co\"\n",
            " oversight of his convertny had services\n",
            "1321/1321 [==============================] - 6s 5ms/step - loss: 1.0687\n",
            "Epoch 70/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 1.0648\n",
            "----- Generating text after Epoch: 69\n",
            "----- Generating with seed: \"ll and i walk in and\"\n",
            "ll and i walk in and dutoy of grade to r\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0651\n",
            "Epoch 71/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.0631\n",
            "----- Generating text after Epoch: 70\n",
            "----- Generating with seed: \"r leonov took that s\"\n",
            "r leonov took that suntab know laty play\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0630\n",
            "Epoch 72/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0617\n",
            "----- Generating text after Epoch: 71\n",
            "----- Generating with seed: \"ned with aew earlier\"\n",
            "ned with aew earlier head fallo the rudi\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0618\n",
            "Epoch 73/150\n",
            "1308/1321 [============================>.] - ETA: 0s - loss: 1.0616\n",
            "----- Generating text after Epoch: 72\n",
            "----- Generating with seed: \"rsadon day four fifi\"\n",
            "rsadon day four fifi if a repecting than\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0618\n",
            "Epoch 74/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.0583\n",
            "----- Generating text after Epoch: 73\n",
            "----- Generating with seed: \"taff and the space a\"\n",
            "taff and the space askadd condept to ope\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0584\n",
            "Epoch 75/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.0543\n",
            "----- Generating text after Epoch: 74\n",
            "----- Generating with seed: \" democratic leaders \"\n",
            " democratic leaders with the suppress if\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0545\n",
            "Epoch 76/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.0529\n",
            "----- Generating text after Epoch: 75\n",
            "----- Generating with seed: \"ation in ain issa ab\"\n",
            "ation in ain issa about the photoo their\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0532\n",
            "Epoch 77/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.0506\n",
            "----- Generating text after Epoch: 76\n",
            "----- Generating with seed: \"he book with differe\"\n",
            "he book with different brock for are slo\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0506\n",
            "Epoch 78/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.0514\n",
            "----- Generating text after Epoch: 77\n",
            "----- Generating with seed: \"nday in florida the \"\n",
            "nday in florida the president to serft l\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0518\n",
            "Epoch 79/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.0476\n",
            "----- Generating text after Epoch: 78\n",
            "----- Generating with seed: \"ith canned food and \"\n",
            "ith canned food and that they freled mid\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0476\n",
            "Epoch 80/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.0480\n",
            "----- Generating text after Epoch: 79\n",
            "----- Generating with seed: \"rsonal lawyer for sc\"\n",
            "rsonal lawyer for science for the game k\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0484\n",
            "Epoch 81/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0451\n",
            "----- Generating text after Epoch: 80\n",
            "----- Generating with seed: \"adium for two hours \"\n",
            "adium for two hours training a blating t\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0455\n",
            "Epoch 82/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.0421\n",
            "----- Generating text after Epoch: 81\n",
            "----- Generating with seed: \"area and there are r\"\n",
            "area and there are reading obs to lougg \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0420\n",
            "Epoch 83/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.0419\n",
            "----- Generating text after Epoch: 82\n",
            "----- Generating with seed: \" the text you may no\"\n",
            " the text you may not videos seoticame f\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0420\n",
            "Epoch 84/150\n",
            "1309/1321 [============================>.] - ETA: 0s - loss: 1.0396\n",
            "----- Generating text after Epoch: 83\n",
            "----- Generating with seed: \"n vocally underminin\"\n",
            "n vocally undermining the next who was t\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0397\n",
            "Epoch 85/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0386\n",
            "----- Generating text after Epoch: 84\n",
            "----- Generating with seed: \"borsin the dallas ar\"\n",
            "borsin the dallas areas with a mother bo\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0388\n",
            "Epoch 86/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 1.0357\n",
            "----- Generating text after Epoch: 85\n",
            "----- Generating with seed: \"e for his widow elai\"\n",
            "e for his widow elaivn for turgial addit\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0360\n",
            "Epoch 87/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 1.0346\n",
            "----- Generating text after Epoch: 86\n",
            "----- Generating with seed: \"th the proper workin\"\n",
            "th the proper working exapted news from \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0345\n",
            "Epoch 88/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.0349\n",
            "----- Generating text after Epoch: 87\n",
            "----- Generating with seed: \"educing the amount o\"\n",
            "educing the amount of abided to teams al\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0354\n",
            "Epoch 89/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.0330\n",
            "----- Generating text after Epoch: 88\n",
            "----- Generating with seed: \"er when we tried to \"\n",
            "er when we tried to deficise of the rsla\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0330\n",
            "Epoch 90/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 1.0344\n",
            "----- Generating text after Epoch: 89\n",
            "----- Generating with seed: \"ove upon fragging ki\"\n",
            "ove upon fragging kighter to despina lif\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0343\n",
            "Epoch 91/150\n",
            "1308/1321 [============================>.] - ETA: 0s - loss: 1.0298\n",
            "----- Generating text after Epoch: 90\n",
            "----- Generating with seed: \" of a struggle or fo\"\n",
            " of a struggle or fortion sair cherifies\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0298\n",
            "Epoch 92/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.0284\n",
            "----- Generating text after Epoch: 91\n",
            "----- Generating with seed: \"kless rollouts of em\"\n",
            "kless rollouts of emresing defense of th\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0285\n",
            "Epoch 93/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.0259\n",
            "----- Generating text after Epoch: 92\n",
            "----- Generating with seed: \" partnershipyou agre\"\n",
            " partnershipyou agrea opens ootsing them\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0262\n",
            "Epoch 94/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 1.0273\n",
            "----- Generating text after Epoch: 93\n",
            "----- Generating with seed: \"affiliates and partn\"\n",
            "affiliates and partn gove nft trump gamb\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0279\n",
            "Epoch 95/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.0243\n",
            "----- Generating text after Epoch: 94\n",
            "----- Generating with seed: \" dropping everything\"\n",
            " dropping everything be the ambe sandle \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0243\n",
            "Epoch 96/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 1.0265\n",
            "----- Generating text after Epoch: 95\n",
            "----- Generating with seed: \"explanation of your \"\n",
            "explanation of your batif in was drenn a\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0265\n",
            "Epoch 97/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.0231\n",
            "----- Generating text after Epoch: 96\n",
            "----- Generating with seed: \"ice of the president\"\n",
            "ice of the president but how came to the\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0232\n",
            "Epoch 98/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 1.0235\n",
            "----- Generating text after Epoch: 97\n",
            "----- Generating with seed: \"iving so many scanda\"\n",
            "iving so many scandarbualthey and and jo\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0237\n",
            "Epoch 99/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.0202\n",
            "----- Generating text after Epoch: 98\n",
            "----- Generating with seed: \" an authoritarian to\"\n",
            " an authoritarian to relalins or pone of\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0201\n",
            "Epoch 100/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.0192\n",
            "----- Generating text after Epoch: 99\n",
            "----- Generating with seed: \" senator was critica\"\n",
            " senator was critical punts and person o\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0194\n",
            "Epoch 101/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 1.0169\n",
            "----- Generating text after Epoch: 100\n",
            "----- Generating with seed: \"rs have put shoppers\"\n",
            "rs have put shoppers do some on the now \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0172\n",
            "Epoch 102/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.0174\n",
            "----- Generating text after Epoch: 101\n",
            "----- Generating with seed: \"lso felt an incredib\"\n",
            "lso felt an incredibed lost be condinies\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0175\n",
            "Epoch 103/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.0175\n",
            "----- Generating text after Epoch: 102\n",
            "----- Generating with seed: \"ely on private inves\"\n",
            "ely on private investivals help hallsm f\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0174\n",
            "Epoch 104/150\n",
            "1321/1321 [==============================] - ETA: 0s - loss: 1.0178\n",
            "----- Generating text after Epoch: 103\n",
            "----- Generating with seed: \"ess the washington p\"\n",
            "ess the washington post pregianters breh\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0178\n",
            "Epoch 105/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 1.0136\n",
            "----- Generating text after Epoch: 104\n",
            "----- Generating with seed: \"ry asked him to make\"\n",
            "ry asked him to make the of play who spe\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0137\n",
            "Epoch 106/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.0148\n",
            "----- Generating text after Epoch: 105\n",
            "----- Generating with seed: \"he house transportat\"\n",
            "he house transportatcy and waschent a co\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0148\n",
            "Epoch 107/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 1.0146\n",
            "----- Generating text after Epoch: 106\n",
            "----- Generating with seed: \"epublicans pelosi bu\"\n",
            "epublicans pelosi but heads are otterty \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0144\n",
            "Epoch 108/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.0151\n",
            "----- Generating text after Epoch: 107\n",
            "----- Generating with seed: \"d on mondayeuropean \"\n",
            "d on mondayeuropean other the fake its o\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0149\n",
            "Epoch 109/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 1.0117\n",
            "----- Generating text after Epoch: 108\n",
            "----- Generating with seed: \"hat we can do better\"\n",
            "hat we can do better from these sendenca\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0117\n",
            "Epoch 110/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 1.0102\n",
            "----- Generating text after Epoch: 109\n",
            "----- Generating with seed: \" she drove to pittsb\"\n",
            " she drove to pittsbuld and really the r\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0101\n",
            "Epoch 111/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.0106\n",
            "----- Generating text after Epoch: 110\n",
            "----- Generating with seed: \"at began as a bipart\"\n",
            "at began as a bipartout scortbut the bar\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0107\n",
            "Epoch 112/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0101\n",
            "----- Generating text after Epoch: 111\n",
            "----- Generating with seed: \" were redeployed two\"\n",
            " were redeployed two nctiontle things th\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0104\n",
            "Epoch 113/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.0081\n",
            "----- Generating text after Epoch: 112\n",
            "----- Generating with seed: \"thought you could ke\"\n",
            "thought you could kere up to playing he \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0081\n",
            "Epoch 114/150\n",
            "1309/1321 [============================>.] - ETA: 0s - loss: 1.0057\n",
            "----- Generating text after Epoch: 113\n",
            "----- Generating with seed: \"er fellow at the ope\"\n",
            "er fellow at the opener should gree may \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0058\n",
            "Epoch 115/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.0060\n",
            "----- Generating text after Epoch: 114\n",
            "----- Generating with seed: \"cription has autoren\"\n",
            "cription has autorentiate consilited by \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0064\n",
            "Epoch 116/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0059\n",
            "----- Generating text after Epoch: 115\n",
            "----- Generating with seed: \"to question through \"\n",
            "to question through tack in the amplieme\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0060\n",
            "Epoch 117/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 1.0042\n",
            "----- Generating text after Epoch: 116\n",
            "----- Generating with seed: \"actual experience of\"\n",
            "actual experience of the decide out a wh\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0041\n",
            "Epoch 118/150\n",
            "1312/1321 [============================>.] - ETA: 0s - loss: 1.0037\n",
            "----- Generating text after Epoch: 117\n",
            "----- Generating with seed: \"the attacks have bee\"\n",
            "the attacks have been being standally fu\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0036\n",
            "Epoch 119/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.0029\n",
            "----- Generating text after Epoch: 118\n",
            "----- Generating with seed: \"hat will step down f\"\n",
            "hat will step down for a biller is a wer\n",
            "1321/1321 [==============================] - 6s 5ms/step - loss: 1.0028\n",
            "Epoch 120/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0049\n",
            "----- Generating text after Epoch: 119\n",
            "----- Generating with seed: \"lev parnas and igor \"\n",
            "lev parnas and igor tokights would payph\n",
            "1321/1321 [==============================] - 6s 5ms/step - loss: 1.0051\n",
            "Epoch 121/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 0.9998\n",
            "----- Generating text after Epoch: 120\n",
            "----- Generating with seed: \"anchise and starskyh\"\n",
            "anchise and starskyhead regures for the \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9998\n",
            "Epoch 122/150\n",
            "1319/1321 [============================>.] - ETA: 0s - loss: 1.0016\n",
            "----- Generating text after Epoch: 121\n",
            "----- Generating with seed: \"oats in a welllighte\"\n",
            "oats in a welllightedecroon frestiver tr\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0017\n",
            "Epoch 123/150\n",
            "1315/1321 [============================>.] - ETA: 0s - loss: 1.0013\n",
            "----- Generating text after Epoch: 122\n",
            "----- Generating with seed: \"liberate new steps i\"\n",
            "liberate new steps inslived by they trau\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0016\n",
            "Epoch 124/150\n",
            "1316/1321 [============================>.] - ETA: 0s - loss: 1.0005\n",
            "----- Generating text after Epoch: 123\n",
            "----- Generating with seed: \"us and changing trum\"\n",
            "us and changing trump has howe rucjinion\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0009\n",
            "Epoch 125/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 1.0008\n",
            "----- Generating text after Epoch: 124\n",
            "----- Generating with seed: \"rvicesinformation fr\"\n",
            "rvicesinformation from from tamily dile \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 1.0012\n",
            "Epoch 126/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 0.9986\n",
            "----- Generating text after Epoch: 125\n",
            "----- Generating with seed: \"in the shortest way \"\n",
            "in the shortest way could people latt mi\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9995\n",
            "Epoch 127/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 0.9997\n",
            "----- Generating text after Epoch: 126\n",
            "----- Generating with seed: \"ly damage the brand \"\n",
            "ly damage the brand we haver workingesas\n",
            "1321/1321 [==============================] - 6s 5ms/step - loss: 0.9996\n",
            "Epoch 128/150\n",
            "1321/1321 [==============================] - ETA: 0s - loss: 0.9983\n",
            "----- Generating text after Epoch: 127\n",
            "----- Generating with seed: \"ime sinceand bring a\"\n",
            "ime sinceand bring a verysor afffired by\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9983\n",
            "Epoch 129/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 0.9978\n",
            "----- Generating text after Epoch: 128\n",
            "----- Generating with seed: \"ssec octoberthe vide\"\n",
            "ssec octoberthe video and kurdistor an a\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9978\n",
            "Epoch 130/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 0.9962\n",
            "----- Generating text after Epoch: 129\n",
            "----- Generating with seed: \" deep state also wit\"\n",
            " deep state also with a chreaz of our fe\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9961\n",
            "Epoch 131/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 0.9940\n",
            "----- Generating text after Epoch: 130\n",
            "----- Generating with seed: \"lear is that the us \"\n",
            "lear is that the us a sans rulaffiriatis\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9942\n",
            "Epoch 132/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 0.9962\n",
            "----- Generating text after Epoch: 131\n",
            "----- Generating with seed: \"tionalsad chronic pa\"\n",
            "tionalsad chronic paty of trump and diso\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9961\n",
            "Epoch 133/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 0.9957\n",
            "----- Generating text after Epoch: 132\n",
            "----- Generating with seed: \" our sole discretion\"\n",
            " our sole discretion pair is a doft a ke\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9955\n",
            "Epoch 134/150\n",
            "1309/1321 [============================>.] - ETA: 0s - loss: 0.9928\n",
            "----- Generating text after Epoch: 133\n",
            "----- Generating with seed: \" to the ebbs and flo\"\n",
            " to the ebbs and floures happenic lyanum\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9931\n",
            "Epoch 135/150\n",
            "1310/1321 [============================>.] - ETA: 0s - loss: 0.9943\n",
            "----- Generating text after Epoch: 134\n",
            "----- Generating with seed: \"isms of the video po\"\n",
            "isms of the video podationsmapar countr \n",
            "1321/1321 [==============================] - 6s 5ms/step - loss: 0.9949\n",
            "Epoch 136/150\n",
            "1320/1321 [============================>.] - ETA: 0s - loss: 0.9935\n",
            "----- Generating text after Epoch: 135\n",
            "----- Generating with seed: \"they each told me th\"\n",
            "they each told me the knyan his creat st\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9935\n",
            "Epoch 137/150\n",
            "1313/1321 [============================>.] - ETA: 0s - loss: 0.9965\n",
            "----- Generating text after Epoch: 136\n",
            "----- Generating with seed: \"mpt status httpstcoi\"\n",
            "mpt status httpstcoingloanactneccopher z\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9968\n",
            "Epoch 138/150\n",
            "1317/1321 [============================>.] - ETA: 0s - loss: 0.9942\n",
            "----- Generating text after Epoch: 137\n",
            "----- Generating with seed: \"tip all the people h\"\n",
            "tip all the people home with untan be on\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9944\n",
            "Epoch 139/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 0.9970\n",
            "----- Generating text after Epoch: 138\n",
            "----- Generating with seed: \"ting msnbc host rach\"\n",
            "ting msnbc host rach as a which mate bee\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9970\n",
            "Epoch 140/150\n",
            "1315/1321 [============================>.] - ETA: 0s - loss: 0.9903\n",
            "----- Generating text after Epoch: 139\n",
            "----- Generating with seed: \"rica narratives abou\"\n",
            "rica narratives about the office may com\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9904\n",
            "Epoch 141/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 0.9909\n",
            "----- Generating text after Epoch: 140\n",
            "----- Generating with seed: \"mapepisodes featured\"\n",
            "mapepisodes featured between the eneve y\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9913\n",
            "Epoch 142/150\n",
            "1315/1321 [============================>.] - ETA: 0s - loss: 0.9924\n",
            "----- Generating text after Epoch: 141\n",
            "----- Generating with seed: \" faced criticism for\"\n",
            " faced criticism for a moch the game ago\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9924\n",
            "Epoch 143/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 0.9895\n",
            "----- Generating text after Epoch: 142\n",
            "----- Generating with seed: \"ch stimulates milk l\"\n",
            "ch stimulates milk least stoklamad effor\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9893\n",
            "Epoch 144/150\n",
            "1318/1321 [============================>.] - ETA: 0s - loss: 0.9911\n",
            "----- Generating text after Epoch: 143\n",
            "----- Generating with seed: \" forth and sliced th\"\n",
            " forth and sliced through agame when you\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9912\n",
            "Epoch 145/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 0.9903\n",
            "----- Generating text after Epoch: 144\n",
            "----- Generating with seed: \"hack to starbucks th\"\n",
            "hack to starbucks they trake were the wa\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9904\n",
            "Epoch 146/150\n",
            "1315/1321 [============================>.] - ETA: 0s - loss: 0.9911\n",
            "----- Generating text after Epoch: 145\n",
            "----- Generating with seed: \"ustomsboth were driv\"\n",
            "ustomsboth were drivizing todmpeas crals\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9913\n",
            "Epoch 147/150\n",
            "1315/1321 [============================>.] - ETA: 0s - loss: 0.9867\n",
            "----- Generating text after Epoch: 146\n",
            "----- Generating with seed: \"president trumps com\"\n",
            "president trumps comment to want to tver\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9869\n",
            "Epoch 148/150\n",
            "1311/1321 [============================>.] - ETA: 0s - loss: 0.9895\n",
            "----- Generating text after Epoch: 147\n",
            "----- Generating with seed: \" the dolphins had on\"\n",
            " the dolphins had one of the washington \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9896\n",
            "Epoch 149/150\n",
            "1308/1321 [============================>.] - ETA: 0s - loss: 0.9889\n",
            "----- Generating text after Epoch: 148\n",
            "----- Generating with seed: \"can develop bad habi\"\n",
            "can develop bad habing pither as a from \n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9889\n",
            "Epoch 150/150\n",
            "1314/1321 [============================>.] - ETA: 0s - loss: 0.9864\n",
            "----- Generating text after Epoch: 149\n",
            "----- Generating with seed: \"nd i started to lose\"\n",
            "nd i started to lose fovewseccent in add\n",
            "1321/1321 [==============================] - 6s 4ms/step - loss: 0.9868\n",
            "CPU times: user 18min 13s, sys: 2min 14s, total: 20min 27s\n",
            "Wall time: 14min 17s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "## Takes about 4.5 minutes to train the entire corpus for 50 epochs on a colab GPU (1 LSTM layer, 128 neurons)\n",
        "\n",
        "# build a 1 layer LSTM language model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# hidden layer 1\n",
        "model.add(LSTM(128,\n",
        "               input_shape=(dctk.maxlen, dctk.n_features), # input_shape is (20,27)\n",
        "               return_sequences=False)) # whenever using 2 or more LSTM layers, set return_sequences= True for all but the last LSTM layer\n",
        "\n",
        "# this is our output layer\n",
        "# recall that n_features = number of characters in the dictionary = 27\n",
        "model.add(Dense(dctk.n_features,\n",
        "                activation='softmax'))\n",
        "\n",
        "# notice that we are using categorical_crossentropy this time around - why?\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt)\n",
        "\n",
        "# fit the model\n",
        "# X and y are pretty large, consider sub-sampling\n",
        "model.fit(X, y,\n",
        "          batch_size=128,\n",
        "          epochs=150,\n",
        "          callbacks=[print_callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBt5ugHKIM21"
      },
      "source": [
        "-------------\n",
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ger33u0CIM22"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - Machine Translation\n",
        "        - Time Series Forecasting (like Stock Prices, Weather, etc.)\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs generally use 1 or 2 hidden layers.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply LSTMs to a text classification problem and to a text generation problem using TensorFlow/Keras\n",
        "    * The shape of the input data for an LSTM is important\n",
        "    * LSTMs can take a while to train\n",
        "    * You can use LSTMs to write movie scripts. :P"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Create Assignment",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "py37  (Python3)",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}